{"pages":[{"title":"Hello 2023","text":"绩效评分并不理想，上年度Q4产出实在是差，分配的任务，属于那种谁做谁死型的难度，用V8引擎执行webgl代码，再用原生的OpengGL的API对接对应的webgl的API，从而实现将webgl的小游戏，在原生上运行的目的。但是实际上，对接远不是想象的那样顺利，本身J2V8使用不熟悉，而且相关生态真的很差，没有太多参考资料，官方连调试都没有实现，有太多的坑需要自己去边踩边解，这还只是V8这边的坑，webgl与OpenGL对接的坑就更多了，双坑合璧，绝世无敌。","link":"/draft/2023-02-05-Hello-2023.html"}],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2023/02/04/hello-world/"},{"title":"ARouter源码分析","text":"在阅读源码前，请先下载源码：ARouter 最近阅读ARouter源码，发现这真的是一个非常优秀的框架。激发出兴趣来读一下他的源码，实际上，这个框架的结构非常简单。这个框架可以分为主流程和辅助流程来拆开分析。 主流程包含编译时和运行时两个部分，其中编译时主要做的是路由路径表的构建，运行时主要做的是路由路径表的加载； 辅助流程主要就是做启动优化。 主流程1. 编译时这部分主要涉及到的是路由路径表的构建，其实现原理是APT，即注解处理器。 使用ARouter时候，需要在目标类上，通过**@Route注解进行标记，注解处理器处理的就是这个注解。打开源码路径下的arouter-compiler这个module，找到RouteProcessor，这个类就是用来处理@Route**注解的类。这里需要了解的知识，除了APT，还有java-poet，请自行了解这些。 Processor类的入口方法是process方法，这个方法返回true，则这个处理器已经完成了自己的任务，不会被重复调用。其他比较重要的方法有getSupportedSourceVersion，getSupportedAnnotationTypes等。 1Set&lt;? extends Element&gt; routeElements = roundEnv.getElementsAnnotatedWith(Route.class); 通过这个方法，获取所有被**@Route**标记的元素。 获取到routeElements后，在parseRoutes方法进行处理。我们以最常用的Activity为例，进行分析。 1234567rootMap.clear(); //用来分类存储标记元素// 用来检测元素是否为对应的类型，通过Types.isSubtype()方法来检测。TypeMirror type_Activity = elementUtils.getTypeElement(ACTIVITY).asType();TypeMirror type_Service = elementUtils.getTypeElement(SERVICE).asType();TypeMirror fragmentTm = elementUtils.getTypeElement(FRAGMENT).asType();TypeMirror fragmentTmV4 = elementUtils.getTypeElement(Consts.FRAGMENT_V4).asType(); 最后将分类号的元素信息，存储在成员变量groupMap中去。 1private Map&lt;String, Set&lt;RouteMeta&gt;&gt; groupMap = new HashMap&lt;&gt;(); 然后再通过这个groupMap，借助java-poet，来生成真实的类。如下： 1234567891011public class ARouter$$Group$$test implements IRouteGroup { @Override public void loadInto(Map&lt;String, RouteMeta&gt; atlas) { atlas.put(&quot;/test/activity1&quot;, RouteMeta.build(RouteType.ACTIVITY, Test1Activity.class, &quot;/test/activity1&quot;, &quot;test&quot;, new java.util.HashMap&lt;String, Integer&gt;(){{put(&quot;ser&quot;, 9); put(&quot;ch&quot;, 5); put(&quot;fl&quot;, 6); put(&quot;dou&quot;, 7); put(&quot;boy&quot;, 0); put(&quot;url&quot;, 8); put(&quot;pac&quot;, 10); put(&quot;obj&quot;, 11); put(&quot;name&quot;, 8); put(&quot;objList&quot;, 11); put(&quot;map&quot;, 11); put(&quot;age&quot;, 3); put(&quot;height&quot;, 3); }}, -1, -2147483648)); atlas.put(&quot;/test/activity2&quot;, RouteMeta.build(RouteType.ACTIVITY, Test2Activity.class, &quot;/test/activity2&quot;, &quot;test&quot;, new java.util.HashMap&lt;String, Integer&gt;(){{put(&quot;key1&quot;, 8); }}, -1, -2147483648)); atlas.put(&quot;/test/activity3&quot;, RouteMeta.build(RouteType.ACTIVITY, Test3Activity.class, &quot;/test/activity3&quot;, &quot;test&quot;, new java.util.HashMap&lt;String, Integer&gt;(){{put(&quot;name&quot;, 8); put(&quot;boy&quot;, 0); put(&quot;age&quot;, 3); }}, -1, -2147483648)); atlas.put(&quot;/test/activity4&quot;, RouteMeta.build(RouteType.ACTIVITY, Test4Activity.class, &quot;/test/activity4&quot;, &quot;test&quot;, null, -1, -2147483648)); atlas.put(&quot;/test/fragment&quot;, RouteMeta.build(RouteType.FRAGMENT, BlankFragment.class, &quot;/test/fragment&quot;, &quot;test&quot;, new java.util.HashMap&lt;String, Integer&gt;(){{put(&quot;obj&quot;, 11); put(&quot;name&quot;, 8); }}, -1, -2147483648)); atlas.put(&quot;/test/webview&quot;, RouteMeta.build(RouteType.ACTIVITY, TestWebview.class, &quot;/test/webview&quot;, &quot;test&quot;, null, -1, -2147483648)); }} 2. 运行时这部分主要做的是，在*ARouter.init()*时候，将上过程生成的路径表加载到内存中。 如果你以官方demo程序验证这一步，需要将app/build.gradle中的apply plugin: 'com.alibaba.arouter'这一行代码注释掉。 我们以ARouter.init方法为入口，实际上最终实现init流程的是LogisticsCenter类的init方法。 123456789101112131415161718192021222324public synchronized static void init(Context context, ThreadPoolExecutor tpe) throws HandlerException { ... if (registerByPlugin) { //这是在辅助流程需要去讲的 logger.info(TAG, &quot;Load router map by arouter-auto-register plugin.&quot;); } else { Set&lt;String&gt; routerMap; // It will rebuild router map every times when debuggable. if (ARouter.debuggable() || PackageUtils.isNewVersion(context)) { logger.info(TAG, &quot;Run with debug mode or new install, rebuild router map.&quot;); // These class was generated by arouter-compiler. routerMap = ClassUtils.getFileNameByPackageName(mContext, ROUTE_ROOT_PAKCAGE); if (!routerMap.isEmpty()) { context.getSharedPreferences(AROUTER_SP_CACHE_KEY, Context.MODE_PRIVATE).edit().putStringSet(AROUTER_SP_KEY_MAP, routerMap).apply(); } PackageUtils.updateVersion(context); // Save new version name when router map update finishes. } else { logger.info(TAG, &quot;Load router map from cache.&quot;); routerMap = new HashSet&lt;&gt;(context.getSharedPreferences(AROUTER_SP_CACHE_KEY, Context.MODE_PRIVATE).getStringSet(AROUTER_SP_KEY_MAP, new HashSet&lt;String&gt;())); } }} 这里需要着重看的是这一句： 1routerMap = ClassUtils.getFileNameByPackageName(mContext, ROUTE_ROOT_PAKCAGE); 我们查看这个方法: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public static Set&lt;String&gt; getFileNameByPackageName(Context context, final String packageName) throws PackageManager.NameNotFoundException, IOException, InterruptedException { final Set&lt;String&gt; classNames = new HashSet&lt;&gt;(); List&lt;String&gt; paths = getSourcePaths(context); final CountDownLatch parserCtl = new CountDownLatch(paths.size()); for (final String path : paths) { Log.v(TAG, &quot;getFileNameByPackageName path=&quot; + path); DefaultPoolExecutor.getInstance().execute(new Runnable() { @Override public void run() { DexFile dexfile = null; try { if (path.endsWith(EXTRACTED_SUFFIX)) { //NOT use new DexFile(path), because it will throw &quot;permission error in /data/dalvik-cache&quot; dexfile = DexFile.loadDex(path, path + &quot;.tmp&quot;, 0); } else { dexfile = new DexFile(path); } Enumeration&lt;String&gt; dexEntries = dexfile.entries(); while (dexEntries.hasMoreElements()) { String className = dexEntries.nextElement(); if (className.startsWith(packageName)) { Log.v(TAG, &quot;find CLASS NAME &quot; + className); classNames.add(className); } } } catch (Throwable ignore) { Log.e(&quot;ARouter&quot;, &quot;Scan map file in dex files made error.&quot;, ignore); } finally { if (null != dexfile) { try { dexfile.close(); } catch (Throwable ignore) { } } parserCtl.countDown(); } } }); } parserCtl.await(); Log.d(Consts.TAG, &quot;Filter &quot; + classNames.size() + &quot; classes by packageName &lt;&quot; + packageName + &quot;&gt;&quot;); return classNames;} 注意其中的getSourcePaths方法，这是从代码目录，来获取所有代码目录，然后在 getFileNameByPackageName找出以com.alibaba.android.arouter.routes为开头包名的类，这些就是我们在步骤1中生成的辅助类。 这个方法结束后，回到LogisticsCenter#init方法，接下来要做的就是，把加载到的辅助类，通过反射生成对象，再调用其loadTo方法，将路由路径表加载到Warehouse类中去，方便以后的查询。 辅助流程在以上的流程中，有一个严重的问题，那就是执行ARouter#init方法的时间过长，以源码的demo为例，在InstantRun的情况下，OnePlus5T需要100多毫秒才能初始化完，这对于程序启动优化来说，是一个不可忽视的时间了。那么如何解决这个问题呢？ 1MainActivity: init cost 134 这就是在上一步中，要求你注释掉的代码起作用了，将apply plugin: 'com.alibaba.arouter'解除注释，让其发挥作用。 这里需要关注的module是arouter-gradle-plugin。 先来看一下，使用了apply plugin: 'com.alibaba.arouter'的神奇效果。 1MainActivity: init cost 19 通过优化，让ARouter#init消耗时间直接降低了一个数量级，那么arouter-gradle-plugin是怎么做到的呢？ 这需要你先了解一下[ASM](/android/ASM.md)。简单来说，这是一种字节码编程技术，通过修改编译后的字节码的方式，来对原始逻辑增强。 我们再来看ARouter#init的最终实现类和方法LogisticsCenter#init： 1234567891011121314151617public synchronized static void init(Context context, ThreadPoolExecutor tpe) throws HandlerException { .... try { long startInit = System.currentTimeMillis(); //billy.qi modified at 2017-12-06 //load by plugin first loadRouterMap(); if (registerByPlugin) { logger.info(TAG, &quot;Load router map by arouter-auto-register plugin.&quot;); } else { .... } ..... } catch (Exception e) { throw new HandlerException(TAG + &quot;ARouter init logistics center exception! [&quot; + e.getMessage() + &quot;]&quot;); }} 我们可以看到，当registerByPlugin为true的时候，则只是打印了一句日志，我们再看loadRouterMap()这个方法： 1234567private static void loadRouterMap() { registerByPlugin = false; //auto generate register code by gradle plugin: arouter-auto-register // looks like below: // registerRouteRoot(new ARouter..Root..modulejava()); // registerRouteRoot(new ARouter..Root..modulekotlin());} 这里的逻辑非常简单，到底在哪里去加载的路由路径表呢？我们看这个方法的注释，发现，这个方法是被arouter-auto-register自动生成的。 我们打开arouter-gradle-plugin/resources/META-INF/gradle-plugins这个目录，可以看到，有一个com.alibaba.arouter.properties文件，查看其内容： 1implementation-class=com.alibaba.android.arouter.register.launch.PluginLaunch 这个PluginLaunch便是此gradle plugin的入口类。查看此类： 1234567891011121314151617181920212223242526public class PluginLaunch implements Plugin&lt;Project&gt; { @Override public void apply(Project project) { def isApp = project.plugins.hasPlugin(AppPlugin) //only application module needs this plugin to generate register code if (isApp) { Logger.make(project) Logger.i('Project enable arouter-register plugin') def android = project.extensions.getByType(AppExtension) def transformImpl = new RegisterTransform(project) //init arouter-auto-register settings ArrayList&lt;ScanSetting&gt; list = new ArrayList&lt;&gt;(3) list.add(new ScanSetting('IRouteRoot')) list.add(new ScanSetting('IInterceptorGroup')) list.add(new ScanSetting('IProviderGroup')) RegisterTransform.registerList = list //register this plugin android.registerTransform(transformImpl) } }} 我们查看其代码，可以发现，这里一共做了三件事： 判断是否为app module，如果不是，则不做任何事，在app module下做2和3两步； 生成了一个RegisterTransform，并为其静态变量registerList赋值，注意此处赋值的registerList中包含的三个对象； 注册此RegisterTransform。 接下来，就轮到RegisterTransform来执行了。 Transform类，简单来说，就是可以在编译时，扫描所有的jar和class，包括引用类库中的。在扫描过程中，就可以借助ASM技术对目标类进行更改。 我们看其入口方法transform： 1234567891011121314151617181920212223@Overridevoid transform(Context context, Collection&lt;TransformInput&gt; inputs, Collection&lt;TransformInput&gt; referencedInputs, TransformOutputProvider outputProvider, boolean isIncremental) throws IOException, TransformException, InterruptedException { inputs.each { TransformInput input -&gt; // scan all jars input.jarInputs.each { JarInput jarInput -&gt; ... if (ScanUtil.shouldProcessPreDexJar(src.absolutePath)) { ScanUtil.scanJar(src, dest) } ... } } input.directoryInputs.each { DirectoryInput directoryInput -&gt; ... directoryInput.file.eachFileRecurse { File file -&gt; ... if(file.isFile() &amp;&amp; ScanUtil.shouldProcessClass(path)){ ScanUtil.scanClass(file) } } ... }} 省去了一些细节，只保留了主线逻辑，我们可以看到，其扫描到的jar和class都经过了ScanUtils的方法来处理，我们继续跟踪下去，会发现，scanJar也是循环调用的scanClass，这样我们直接看scanClass方法： 12345678910111213141516171819202122232425262728293031static void scanClass(InputStream inputStream) { ClassReader cr = new ClassReader(inputStream) ClassWriter cw = new ClassWriter(cr, 0) ScanClassVisitor cv = new ScanClassVisitor(Opcodes.ASM5, cw) cr.accept(cv, ClassReader.EXPAND_FRAMES) inputStream.close()}static class ScanClassVisitor extends ClassVisitor { ScanClassVisitor(int api, ClassVisitor cv) { super(api, cv) } void visit(int version, int access, String name, String signature, String superName, String[] interfaces) { super.visit(version, access, name, signature, superName, interfaces) RegisterTransform.registerList.each { ext -&gt; if (ext.interfaceName &amp;&amp; interfaces != null) { interfaces.each { itName -&gt; if (itName == ext.interfaceName) { //fix repeated inject init code when Multi-channel packaging if (!ext.classList.contains(name)) { ext.classList.add(name) } } } } } }} 这里就又涉及到了ASM的知识，ScanClassVisitor是访问某个类的内部结构。 version：类的版本； access：表示类的访问权限，public，private，protected等； name：类的名字； signature：有无泛型； superName：其父类； interfaces：其实现的接口； 在ScanClassVisitor中，并没有对类做修改，只是从遍历过的类中，把我们关心的类挑出来。那么，我们关心哪些类呢？ 在PluginLaunch类中，我们注册了三个ScanSettings类，分别是IRouteRoot、IInterceptorGroup和IProviderGroup，也就是说，我们把实现了这三个接口的类，挑出来，加入到各自对应的ScanSettings类中记录起来。这三个接口是不是很熟悉？就是通过APT生成的用来记录路由路径表的类。 等收集好了这些记录的路径表信息后，就可以对LogisticsCenter通过ASM进行修改了。我们接着看RegisterTransform#transform方法中剩下的逻辑。 1234567891011121314if (fileContainsInitClass) { registerList.each { ext -&gt; Logger.i('Insert register code to file ' + fileContainsInitClass.absolutePath) if (ext.classList.isEmpty()) { Logger.e(&quot;No class implements found for interface:&quot; + ext.interfaceName) } else { ext.classList.each { Logger.i(it) } RegisterCodeGenerator.insertInitCodeTo(ext) } }} 注意此处的insertInitCodeTo方法，这就是ASM修改的入口了。这里不对修改过程进行详细解释了。我们直接对比看LogisticsCenter修改前后关键代码的对比。 在app/build目录下，找到生成的apk文件，通过AndroidStudio来查看其中的class，找到关键LogisticsCenter关键方法loadRouterMap。 具体过程如下： app/build/outputs/apk/debug/app-debug.apk -&gt; classes.dex(双击) -&gt; 找到LogisticsCenter#loadRouterMap方法 -&gt; 右键: show Bytecode。 123456789101112// 不使用apply plugin: 'com.alibaba.arouter'.method private static loadRouterMap()V .registers 1 .line 64 const/4 v0, 0x0 sput-boolean v0, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;registerByPlugin:Z .line 69 return-void.end method 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 使用apply plugin: 'com.alibaba.arouter'.method private static loadRouterMap()V .registers 1 .line 64 const/4 v0, 0x0 sput-boolean v0, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;registerByPlugin:Z .line 69 const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Root$$modulejava&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Root$$modulekotlin&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Root$$arouterapi&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Root$$app&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Interceptors$$modulejava&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Interceptors$$app&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Providers$$modulejava&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Providers$$modulekotlin&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Providers$$arouterapi&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V const-string v0, &quot;com.alibaba.android.arouter.routes.ARouter$$Providers$$app&quot; invoke-static {v0}, Lcom/alibaba/android/arouter/core/LogisticsCenter;-&gt;register(Ljava/lang/String;)V return-void.end method 对比发现，使用apply plugin: 'com.alibaba.arouter'后，这个方法增加了很多代码，基本上就是在加载路由路径表。使用这个gradle插件的基本思想就是，将查找路由路径表的过程，从运行时提前到了编译时，这算是一种AOT(Ahead of time)思想。 将最耗时的查找过程提前，也就解决了ARouter初始化时间过长的问题。","link":"/2020/11/28/2022-09-17-ARouter%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Glide源码分析与自我实现(一)——数据加载主流程","text":"本文基于Glide 4.11.0 阅读前请参考Glide 源码分析解读-基于最新版Glide 4.9.0一文，该文章中，将Glide中各个部分的作用分析的非常好了。 Glide几乎是现在做Android图片加载的最佳选择了。如此优秀的一个框架是如何实现的呢？如果让我们自己来实现该怎么做呢？我们就通过自己实现一个低配版Glide的方式，来探究Glide中是如何实现的。 我们就称我们自己低配版Glide为Slide。那么Slide要实现哪些功能呢？简单来说，就是获取图片+界面显示。我们通过先构架大体框架，再分步丰富其中细节的方式，来构建Slide的整体结构。 12flowchart LR;A[获取图片] --&gt; C[Slide] --&gt; B[界面显示]; 1Glide.with(xxx).load(url).into(iv); 这是Glide一个典型的最为简单的调用过程。那么在这个过程中发生了哪些事情呢？ 我们可以通过这个链式调用的返回值发现，有如下过程： 1234graph LR;style A fill:#aaffccstyle D fill:#ffaa99A(Glide) --&gt;|&quot;with(xxx)&quot;| B(RequestManager) --&gt;|&quot;load(xxx)&quot;| C(RequestBuilder) --&gt;|&quot;into(iv)&quot;| D(Target); Glide.with(xxx)发生了什么事？阅读源码发现，Glide.with(xxx)的最终实现类是RequestManagerRetriever.java类。继续跟踪，我们在这个类中，看到这样一个方法。 12345678910111213@NonNullprivate RequestManager supportFragmentGet( @NonNull Context context, @NonNull FragmentManager fm, @Nullable Fragment parentHint, boolean isParentVisible) { SupportRequestManagerFragment current = getSupportRequestManagerFragment(fm, parentHint); RequestManager requestManager = current.getRequestManager(); ..... return requestManager;} 重点关注这个getSupportRequestManagerFragment方法。 123456789101112131415161718//getSupportRequestManagerFragment@NonNullprivate SupportRequestManagerFragment getSupportRequestManagerFragment( @NonNull final FragmentManager fm, @Nullable Fragment parentHint) { SupportRequestManagerFragment current = (SupportRequestManagerFragment) fm.findFragmentByTag(FRAGMENT_TAG); if (current == null) { current = pendingSupportRequestManagerFragments.get(fm); if (current == null) { current = new SupportRequestManagerFragment(); current.setParentFragmentHint(parentHint); pendingSupportRequestManagerFragments.put(fm, current); fm.beginTransaction().add(current, FRAGMENT_TAG).commitAllowingStateLoss(); handler.obtainMessage(ID_REMOVE_SUPPORT_FRAGMENT_MANAGER, fm).sendToTarget(); } } return current;} 其实，这里是一个Glide检测到界面生命周期的关键了。Glide就是通过像当前Activity添加一个一个无UI的Fragment来探测生命周期的。 注意：在执行了添加fragment的语句fm.beginTransaction().add(current, FRAGMENT_TAG).commitAllowingStateLoss()后，又马上通过handler发送了一个一个message，这里需要熟悉Handler机制才能理解，简单来说，就是添加fragment操作，实际上也是通过handler执行的，这是一个异步的过程，如何检测到fragment已经添加完成了呢？就是在commitAllowingStateLoss后，马上去发送一条指定的消息，利用handler处理message的顺序性，来获知fragment已经添加完成。 经过添加SupportRequestManagerFragment后，我们获得了探测当前界面生命周期的能力。 继续阅读supportFragmentGet方法代码，RequestManager是从SupportRequestManagerFragment拿到的，如果拿到的是空，则创建一个，设置到该fragment当中去。 RequestManager.load(xxx)发生了什么？我们以load(url)为例，来探究这部分代码。 这个方法，返回的是RequestBuilder这个类，看名字就知道，这是一个构建者模式中的Builder类，主要是在添加各种配置项，比如RequestOptions、RequestListener等。 RequestBuilder.into(iv)发生了什么？其实，这里才是真正开始触发发起请求的地方。 RequestBuilder我们把into(ImageView)方法作为入口，一路跟踪，可以发现最终的实现是如下方法。 12345678910111213141516171819202122232425262728293031323334private &lt;Y extends Target&lt;TranscodeType&gt;&gt; Y into( @NonNull Y target, @Nullable RequestListener&lt;TranscodeType&gt; targetListener, BaseRequestOptions&lt;?&gt; options, Executor callbackExecutor) { Preconditions.checkNotNull(target); if (!isModelSet) { throw new IllegalArgumentException(&quot;You must call #load() before calling #into()&quot;); } Request request = buildRequest(target, targetListener, options, callbackExecutor); Request previous = target.getRequest(); if (request.isEquivalentTo(previous) &amp;&amp; !isSkipMemoryCacheWithCompletePreviousRequest(options, previous)) { // If the request is completed, beginning again will ensure the result is re-delivered, // triggering RequestListeners and Targets. If the request is failed, beginning again will // restart the request, giving it another chance to complete. If the request is already // running, we can let it continue running without interruption. if (!Preconditions.checkNotNull(previous).isRunning()) { // Use the previous request rather than the new one to allow for optimizations like skipping // setting placeholders, tracking and un-tracking Targets, and obtaining View dimensions // that are done in the individual Request. previous.begin(); } return target; } requestManager.clear(target); target.setRequest(request); requestManager.track(target, request); return target;} 这个方法主要是做了以下事情： 是否已经有一个request在处理相同的请求，如果有，则判断是否正在运行，没有正在运行则开始运行； 如果没有一个request在处理此请求，则对target做一些清理操作，与之前的请求解绑，为当前target设置新的请求，然后requestManager开始追踪这个请求。 接下来我们就按照requestManager.track(target, request)这段代码继续追踪。来到RequestManager的track方法。 RequestManager1234synchronized void track(@NonNull Target&lt;?&gt; target, @NonNull Request request) { targetTracker.track(target); requestTracker.runRequest(request);} 这个方法很简单，只有两个方法。 TargetTracker123456private final Set&lt;Target&lt;?&gt;&gt; targets = Collections.newSetFromMap(new WeakHashMap&lt;Target&lt;?&gt;, Boolean&gt;());public void track(@NonNull Target&lt;?&gt; target) { targets.add(target);} 这里把一个target存放在WeakHashMap中，因为target是与生命周期有关的东西，比如ImageView对应的ImageViewTarget，所以这么做是为了防止内存泄漏。 RequestTracker12345678910111213/** Starts tracking the given request. */public void runRequest(@NonNull Request request) { requests.add(request); if (!isPaused) { request.begin(); } else { request.clear(); if (Log.isLoggable(TAG, Log.VERBOSE)) { Log.v(TAG, &quot;Paused, delaying request&quot;); } pendingRequests.add(request); }} 这里是将暂停的request加入到pendingRequests中去，如果不是暂停的request，则调用其begin方法。 我们查看Request类的子类，可以看到下图。 可以看到一共有4个类实现了Request类，其中FakeRequest类是用于测试的，不去考虑。其他三个类的作用如下： ThumbnailRequestCoordinator: 用来加载thumbnail； ErrorRequestCoordinator: 用来加载错误时候，展示错误状态； SingleRequest: 这才是用来加载目标图片的request。 我们重点去看SingleRequest的begin方法。 SingleRequest12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public void begin() { synchronized (requestLock) { assertNotCallingCallbacks(); stateVerifier.throwIfRecycled(); startTime = LogTime.getLogTime(); if (model == null) { if (Util.isValidDimensions(overrideWidth, overrideHeight)) { width = overrideWidth; height = overrideHeight; } // Only log at more verbose log levels if the user has set a fallback drawable, because // fallback Drawables indicate the user expects null models occasionally. int logLevel = getFallbackDrawable() == null ? Log.WARN : Log.DEBUG; onLoadFailed(new GlideException(&quot;Received null model&quot;), logLevel); return; } if (status == Status.RUNNING) { throw new IllegalArgumentException(&quot;Cannot restart a running request&quot;); } // If we're restarted after we're complete (usually via something like a notifyDataSetChanged // that starts an identical request into the same Target or View), we can simply use the // resource and size we retrieved the last time around and skip obtaining a new size, starting // a new load etc. This does mean that users who want to restart a load because they expect // that the view size has changed will need to explicitly clear the View or Target before // starting the new load. if (status == Status.COMPLETE) { onResourceReady( resource, DataSource.MEMORY_CACHE, /* isLoadedFromAlternateCacheKey= */ false); return; } // Restarts for requests that are neither complete nor running can be treated as new requests // and can run again from the beginning. status = Status.WAITING_FOR_SIZE; if (Util.isValidDimensions(overrideWidth, overrideHeight)) { onSizeReady(overrideWidth, overrideHeight); } else { target.getSize(this); } if ((status == Status.RUNNING || status == Status.WAITING_FOR_SIZE) &amp;&amp; canNotifyStatusChanged()) { target.onLoadStarted(getPlaceholderDrawable()); } if (IS_VERBOSE_LOGGABLE) { logV(&quot;finished run method in &quot; + LogTime.getElapsedMillis(startTime)); } }} 代码虽长，但是结构简单。主要做了以下事情： 检查model是否是空，model就是要加载的数据来源，比如url、resourceId、File等； 判断request状态，不能重新开始一个正在运行的请求； 判断request状态，如果是已经完成的请求，则说明资源已经存在，直接调用onResourceReady方法并返回； 接下来就来到判断target尺寸的过程了，如果target尺寸已经确定，比如view尺寸measure结束后，则调用onSizeReady方法，注意：实际的网络请求就在这个onSizeReady方法中，因为只有target的尺寸确定了，才能进行请求并处理图片； 如果尺寸未确定，则调用target.getSize方法去监听尺寸事件，具体可以参考ViewTarget#getSize方法，这是一个通过onPreDrawListener来监听尺寸的； 接下来回调onLoadStarted方法，并且显示加载过程状态。 我们着重看网络请求那个分支，也就是onSizeReady方法。 1234567891011121314151617181920212223242526@Overridepublic void onSizeReady(int width, int height) { ...... loadStatus = engine.load( glideContext, model, requestOptions.getSignature(), this.width, this.height, requestOptions.getResourceClass(), transcodeClass, priority, requestOptions.getDiskCacheStrategy(), requestOptions.getTransformations(), requestOptions.isTransformationRequired(), requestOptions.isScaleOnlyOrNoTransform(), requestOptions.getOptions(), requestOptions.isMemoryCacheable(), requestOptions.getUseUnlimitedSourceGeneratorsPool(), requestOptions.getUseAnimationPool(), requestOptions.getOnlyRetrieveFromCache(), this, callbackExecutor ); ...} 关键代码来了！这个engine就是Glide的核心。这个engine是在Glide初始化时候生成的一个实例。 EngineEngine不只是用于加载图片，而是一个任务执行核心引擎，它要执行的不只是请求远程图片的任务，包括解码任务等，它执行的实际上是一个个的job。 跟踪上一阶段中的engine.load方法，来到是这个方法的关键部分——调用waitForExistingOrStartNewJob。 在这个方法中，主要做了以下事情： 123graph TD;A{{是否有一个job执行相同操作}} --&gt; |有|B[为此job添加新的回调];A --&gt; |无|C[添加并执行一个EngineJob]; EngineJob.start(decodeJob)123456public synchronized void start(DecodeJob&lt;R&gt; decodeJob) { this.decodeJob = decodeJob; GlideExecutor executor = decodeJob.willDecodeFromCache() ? diskCacheExecutor : getActiveSourceExecutor(); executor.execute(decodeJob);} 这里执行的是decodeJob。 这里需要着重关注一点，就是executor.execute(decodeJob)的时候，就已经通过GlideExecutor的sourceExecutor.Builder创建了一个ThreadPoolExecutor，也就是在这里实现线程池异步执行任务。ThreadPoolExecutor并不是Glide提供的实现，而是在java.util.concurrent包下。 DecodeJobDecodeJob是一个Runnable类，所以，我们查看其run方法。 接下来的调用路径参考下图。 12345678910graph TD;subgraph DecodeJob;A(run) --&gt; B[runWrapped] --&gt; C[runGenerators] --&gt; D[getNextGenerator];end;subgraph SourceGeneratorD --&gt; E[startNext] --&gt; F[startNextLoad];end;subgraph HttpUrlFetcherF --&gt; G[loadData] --&gt; H[loadDataWithRedirects];end; 经过这么长的调用链，我们终于来到了网络请求的部分，我们可以看到Glide原生使用的HttpURLConnection进行网络请求的。获取到InputStream后，在SourceGenerator中的cacheData方法进行缓存处理。 获取到数据后的处理通过DataFetcherGenerator.FetcherReadyCallback可以探知到数据获取成功或者失败，如果获取成功，则在DecodeJob#onDataFetcherReady中处理。关键代码如下： 12345678910public void onDataFetcherReady( Key sourceKey, Object data, DataFetcher&lt;?&gt; fetcher, DataSource dataSource, Key attemptedKey) { ..... if (Thread.currentThread() != currentThread) { runReason = RunReason.DECODE_DATA; callback.reschedule(this); } else { ..... }} 更改任务状态，重新执行此任务，则重新执行到getNextGenerator方法，此时则会返回DataCacheGenerator来处理从Disk缓存加载的任务。 获取图片首先，图片来源有哪些？ 资源图片：drawable, assets, raw, mipmap这些程序中自带的图片； 本地图片：本地存储设备上的图片； 远端图片：我们服务器或者来自第三方服务器的图片，通过URL来获取。这就需要异步网络请求，请求结束以后，要缓存图片，避免重复请求远端图片，造成时间、网络的浪费。 12345678graph LR;A[Slide];B([1. 资源图片]) --&gt; A;C([2. 本地图片]) --&gt; A;E{缓存是否存在} --&gt; |是,交给Slide|A;E --&gt; |否,网络请求|D([3. 远端图片]);D -.-&gt; |获取到图片并缓存|E; 那么接下来，要丰富的细节，就来到了网络请求和缓存了。 网络请求缓存","link":"/2020/12/16/2022-09-17-Glide%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%8E%E8%87%AA%E6%88%91%E5%AE%9E%E7%8E%B01/"},{"title":"Glide源码分析与自我实现(二)——缓存与BitmapPool","text":"本文基于Glide 4.11.0 参考文章：Glide 源码分析解读-缓存模块-基于最新版Glide 4.9.0 注意：由于版本差异问题，本文有些部分与参考文章有差异。 缓存模块是Glide中非常重要的部分，Glide图片加载的高效性，几乎有一半功劳都在这里了。 一般来说，Glide有三级缓存，就是内存缓存、磁盘缓存和网络缓存。 先来看缓存流程图，如下： 1234567graph TD;style A fill:#99ccffstyle B1 fill:#aaffaaA(发起请求) --&gt; B{1. 通过&lt;br&gt;ActiveResources&lt;br&gt;获取资源} --&gt; |命中|B1([加载完成]);B --&gt; |未命中|C{2. 通过&lt;br&gt;MemoryCache&lt;br&gt;获取资源} --&gt; |命中|C1[缓存至&lt;br&gt;ActiveResources] --&gt; B1;C --&gt; |未命中|D{3. 通过&lt;br&gt;DiskCache&lt;br&gt;获取资源} --&gt; |命中|D1[缓存至&lt;br&gt;MemoryCache] --&gt; C1;D --&gt; |未命中|E[&quot;4. 通过数据源(网络、文件等)&lt;br&gt;加载数据&quot;] --&gt; E1[缓存至&lt;br&gt;DiskCache] --&gt; D1; 内存缓存内存缓存主要靠三个部分组成：ActiveResources、MemoryCache和BitmapPool。 ActiveResourcesActiveResources表示当前正在活动中的资源。ActiveResources通过一个Map&lt;Key, ResourceWeakReference&gt;来保存活动中的资源，其中的ResourceWeakReference就是资源数据，在构建这个ResourceWeakReference的时候必须传入一个ReferenceQueue用来检测资源是否被回收。 Q1：如何探知WeakReference中的值被回收了呢？ 12ReferenceQueue queue = ...;WeakReference wr = new WeakReference(value, queue); 当构建WeakReference的时候，如果传入了queue参数，则在value被回收的时候，wr会被加入到queue中去，这样，通过检测queue中是否有值，就可以探知value是否被回收了。 那么，在何时去探知ReferenceQueue中的值呢？我们查看ActiveResources的关键代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/*构造方法中，通过monitorClearedResourcesExecutor执行了cleanReferenceQueue()方法。*/ActiveResources(boolean isActiveResourceRetentionAllowed) { this( isActiveResourceRetentionAllowed, java.util.concurrent.Executors.newSingleThreadExecutor( new ThreadFactory() { @Override public Thread newThread(@NonNull final Runnable r) { return new Thread( new Runnable() { @Override public void run() { Process.setThreadPriority(Process.THREAD_PRIORITY_BACKGROUND); r.run(); } }, &quot;glide-active-resources&quot;); } }));}@VisibleForTestingActiveResources( boolean isActiveResourceRetentionAllowed, Executor monitorClearedResourcesExecutor) { this.isActiveResourceRetentionAllowed = isActiveResourceRetentionAllowed; this.monitorClearedResourcesExecutor = monitorClearedResourcesExecutor; monitorClearedResourcesExecutor.execute( new Runnable() { @Override public void run() { cleanReferenceQueue(); } });}void cleanReferenceQueue() { while (!isShutdown) { try { ResourceWeakReference ref = (ResourceWeakReference) resourceReferenceQueue.remove(); cleanupActiveReference(ref); // This section for testing only. DequeuedResourceCallback current = cb; if (current != null) { current.onResourceDequeued(); } // End for testing only. } catch (InterruptedException e) { Thread.currentThread().interrupt(); } }} 我们通过代码可以看出，cleanReferenceQueue是一个靠isShutdown变量控制的死循环方法，这个方法执行在一个优先级为THREAD_PRIORITY_BACKGROUND的线程上。 Q2：那么，既然是死循环方法，会不会过多的占用CPU资源呢？ 其实不会的，因为ReferenceQueue#remove是一个阻塞式的方法，如果没有元素可以被remove，则等待至有元素可以remove的时候，等待期间释放CPU。 注意：此处与参考文章中的说法不同，这是因为版本差异。查看Glide update log hsitory，可以看出出于避免在主线程做清理的原因，将清理任务放在了后台线程，而不是放在IdleHandler中。 那么被回收了的资源去哪里了呢？ 我们查看cleanupActiveReference方法，得知，通过ResourceListener#onResourceReleased回调，交给了Engine来处理，我们查看Engine的onResourceReleased方法。 123456789@Overridepublic void onResourceReleased(Key cacheKey, EngineResource&lt;?&gt; resource) { activeResources.deactivate(cacheKey); if (resource.isMemoryCacheable()) { cache.put(cacheKey, resource); } else { resourceRecycler.recycle(resource, /*forceNextFrame=*/ false); }} 从这里我们发现，这里出现了两种情况： 如果资源是MemoryCacheable的，则缓存在MemoryCache； 如果资源不是MemoryCacheable的，则交给ResourceRecycler调用Resource的recycle()方法来回收，如果此Resource为BitmapResource，则会将Bitmap回收到BitmapPool中去。 在开始MemoryCache和BitmapPool前，需要先了解一下MemorySizeCalculator这个类，这个类是用来计算 BitmapPool 、ArrayPool 以及 MemoryCache 大小的。 MemoryCacheMemoryCache的具体实现类是LruResourceCache，而实际的逻辑方法，都在其父类LruCache中，以put方法为例。 1234567891011121314151617181920212223@Nullablepublic synchronized Y put(@NonNull T key, @Nullable Y item) { final int itemSize = getSize(item); if (itemSize &gt;= maxSize) { onItemEvicted(key, item); return null; } if (item != null) { currentSize += itemSize; } @Nullable Entry&lt;Y&gt; old = cache.put(key, item == null ? null : new Entry&lt;&gt;(item, itemSize)); if (old != null) { currentSize -= old.size; if (!old.value.equals(item)) { onItemEvicted(key, old.value); } } evict(); return old != null ? old.value : null;} 当有一个新的item被put进去以后，会替换出一个老的值old，如果old非为空，则需要将当前容量减去old的大小，如果old并非新的item，则需要通过onItemEvicted进行回调，通知有老值被“驱逐”了。最后还要执行一次evict方法，按照LRU算法，将超出maxSize的item“驱逐”出去，以确保在maxSize范围内。 1234567891011121314151617protected synchronized void trimToSize(long size) { Map.Entry&lt;T, Entry&lt;Y&gt;&gt; last; Iterator&lt;Map.Entry&lt;T, Entry&lt;Y&gt;&gt;&gt; cacheIterator; while (currentSize &gt; size) { cacheIterator = cache.entrySet().iterator(); last = cacheIterator.next(); final Entry&lt;Y&gt; toRemove = last.getValue(); currentSize -= toRemove.size; final T key = last.getKey(); cacheIterator.remove(); onItemEvicted(key, toRemove.value); }}private void evict() { trimToSize(maxSize);} 被**”驱逐”*的值去哪里了呢？我们查看MemoryCache类的源码，可以知道是通过ResourceRemovedListener回调给了Engine，在Engine中我们查看onResourceRemoved*方法。 123456@Overridepublic void onResourceRemoved(@NonNull final Resource&lt;?&gt; resource) { // Avoid deadlock with RequestManagers when recycling triggers recursive clear() calls. // See b/145519760. resourceRecycler.recycle(resource, /*forceNextFrame=*/ true);} 我们可以看到，这里同样是通过resourceRecycler进行了回收。在这里，则是交给resource自己的recycle()方法来处理，比如，BitmapResource是交给了BitmapPool进行处理。 BitmapPool这里是专门用来存放被回收的Bitmap的，其中BitmapDrawableResource、BitmapResource都持有一个BitmapPool变量，在执行recycle()方法时候，调用*BitmapPool#put()*方法。我们来看一下这个BitmapPool的默认实现类LruBitmapPool的方法实现。 12345678910111213141516171819202122232425262728293031@Overridepublic synchronized void put(Bitmap bitmap) { if (bitmap == null) { throw new NullPointerException(&quot;Bitmap must not be null&quot;); } if (bitmap.isRecycled()) { throw new IllegalStateException(&quot;Cannot pool recycled bitmap&quot;); } if (!bitmap.isMutable() || strategy.getSize(bitmap) &gt; maxSize || !allowedConfigs.contains(bitmap.getConfig())) { if (Log.isLoggable(TAG, Log.VERBOSE)) { Log.v( TAG, &quot;Reject bitmap from pool&quot; + &quot;, bitmap: &quot; + strategy.logBitmap(bitmap) + &quot;, is mutable: &quot; + bitmap.isMutable() + &quot;, is allowed config: &quot; + allowedConfigs.contains(bitmap.getConfig())); } bitmap.recycle(); return; } final int size = strategy.getSize(bitmap); strategy.put(bitmap); tracker.add(bitmap); ...} 这里我们可以看出，当Bitmap在三种情况下是不会被BitmapPool缓存起来的： 这个bitmap是非mutable的，也就是说是不允许被复用的； 这一个bitmap的字节数大小已经超过了可以容纳的总大小； BitmapPool中不允许的Config类型。 在这种情况，bitmap就被直接recycle掉，而不是放入缓存等待下次使用。 如果不满足这三种情况，则会被strategy缓存起来，等待下次使用。 我们再看LruBitmapPool#get()方法。 1234567891011@Override@NonNullpublic Bitmap get(int width, int height, Bitmap.Config config) { Bitmap result = getDirtyOrNull(width, height, config); if (result != null) { result.eraseColor(Color.TRANSPARENT); } else { result = createBitmap(width, height, config); } return result;} 我们可以看到，当能够查询到符合条件的Bitmap的时候，会先通过eraseColor方法，将其变成透明图片，然后再交给调用者来使用；如果查询不到，则创建一个新图交给调用者来使用。 LruBitmapPool的LruPoolStrategy变量，在KITKAT以及以上，是SizeConfigStrategy，在以下是AttributeStrategy，这是因为在KITKAT版本以下，Bitmap的复用需要尺寸的严格匹配，但是KITKAT及以上没有这个问题，只要被复用的图片尺寸比目标尺寸大就可以。 ArrayPoolArrayPool主要用在ThumbnailStreamOpener和ByteBufferGifDecoder中，具体的实现类为LruArrayPool。 在LruArrayPool中，通过groupedMap来缓存数据，而缓存数据的byte字节数是通过ArrayAdapterInterface来计算的，ArrayAdapterInterface是一个接口，实现类有两个：IntegerArrayAdapter和ByteArrayAdapter，分别对应缓存int[].class和byte[].class。 StreamGifDecoder和StreamBitmapDecoder都有一个ArrayPool成员。解码过程中需要用到byte[]，但不是直接new byte[]，而是调用ArrayPool.get()从对象池中拿，用完了归还。 DiskCache在上一章[Glide源码分析与自我实现(一)——数据加载主流程](/源码分析系列/Glide源码分析与自我实现2.md)中，提到过数据加载的主流程，其中一个非常重要的类是 DecodeJob，在这个类的getNextGenerator方法中，返回的SourceGenerator会用来加载远程数据，但是这个方法不止返回这一个DataFetcherGenerator类，这是一个通过条件判断，返回不同DataFetcherGenerator类的方法。 1234567891011121314private DataFetcherGenerator getNextGenerator() { switch (stage) { case RESOURCE_CACHE: return new ResourceCacheGenerator(decodeHelper, this); case DATA_CACHE: return new DataCacheGenerator(decodeHelper, this); case SOURCE: return new SourceGenerator(decodeHelper, this); case FINISHED: return null; default: throw new IllegalStateException(&quot;Unrecognized stage: &quot; + stage); }} 实际上，这是依次递进的有限状态机设计模式，当一个获取数据请求到来时候，此时是默认状态INITIALIZE，然后通过getNextStage方法判断下一个状态是什么，再按照新的状态获取DataFetcherGenerator，然后随着任务的执行，不断改变状态。 1234567891011121314151617181920private Stage getNextStage(Stage current) { switch (current) { case INITIALIZE: return diskCacheStrategy.decodeCachedResource() ? Stage.RESOURCE_CACHE : getNextStage(Stage.RESOURCE_CACHE); case RESOURCE_CACHE: return diskCacheStrategy.decodeCachedData() ? Stage.DATA_CACHE : getNextStage(Stage.DATA_CACHE); case DATA_CACHE: // Skip loading from source if the user opted to only retrieve the resource from cache. return onlyRetrieveFromCache ? Stage.FINISHED : Stage.SOURCE; case SOURCE: case FINISHED: return Stage.FINISHED; default: throw new IllegalArgumentException(&quot;Unrecognized stage: &quot; + current); }} 其状态变更顺序为INITIALIZE -&gt; RESOURCE_CACHE -&gt; DATA_CACHE -&gt; SOURCE，代表着ResourceCacheGenerator、DataCacheGenerator和SourceGenerator，当从ResourceCahce中拿不到数据，则向DataCacheGenerator请求数据，如果还是拿不到，则通过SourceGenerator去请求数据了。 在这个过程中，SourceGenerator向DiskCache中写入数据，ResourceCacheGenerator和DataCacheGenerator从DiskCache中读取数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class ResourceCacheGenerator implements DataFetcherGenerator, @Override public boolean startNext() { ... currentKey = new ResourceCacheKey(sourceId, helper.getSignature(), helper.getWidth(), helper.getHeight(), transformation, resourceClass, helper.getOptions()); cacheFile = helper.getDiskCache().get(currentKey); if (cacheFile != null) { this.sourceKey = sourceId; modelLoaders = helper.getModelLoaders(cacheFile); modelLoaderIndex = 0; } } }}class DataCacheGenerator implements DataFetcherGenerator, @Override public boolean startNext() { while (modelLoaders == null || !hasNextModelLoader()) { ... Key sourceId = cacheKeys.get(sourceIdIndex); Key originalKey = new DataCacheKey(sourceId, helper.getSignature()); cacheFile = helper.getDiskCache().get(originalKey); if (cacheFile != null) { this.sourceKey = sourceId; modelLoaders = helper.getModelLoaders(cacheFile); modelLoaderIndex = 0; } }}class SourceGenerator implements DataFetcherGenerator { @Override public boolean startNext() { if (dataToCache != null) { Object data = dataToCache; dataToCache = null; cacheData(data); } ... } private void cacheData(Object dataToCache) { long startTime = LogTime.getLogTime(); try { Encoder&lt;Object&gt; encoder = helper.getSourceEncoder(dataToCache); DataCacheWriter&lt;Object&gt; writer = new DataCacheWriter&lt;&gt;(encoder, dataToCache, helper.getOptions()); originalKey = new DataCacheKey(loadData.sourceKey, helper.getSignature()); helper.getDiskCache().put(originalKey, writer); ... } finally { loadData.fetcher.cleanup(); } sourceCacheGenerator = new DataCacheGenerator(Collections.singletonList(loadData.sourceKey), helper, this); }} DiskCache的默认实现类是DiskLruCacheWrapper，其内部通过DiskLruCache来管理磁盘缓存。 总结到现在，Glide主要部分已经分析的差不多了，实际上这个优秀的框架可挖的地方还有很多，比如通过[APT来实现很好的扩展](/源码分析系列/Glide源码分析与自我实现3.md)，框架中涉及多种涉及模式等。 其中涉及到的涉及模式，比如无处不在的构建者模式和工厂模式，DecodeJob中的有限状态机模式，还有BitmapPool和ArrayPool中的享元模式，DiskLruCacheWrapper中的代理模式等。 参考文章Glide缓存分析","link":"/2020/12/27/2022-09-17-Glide%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%8E%E8%87%AA%E6%88%91%E5%AE%9E%E7%8E%B02/"},{"title":"Glide源码分析与自我实现(三)——APT的使用与GIF的优化","text":"项目Demo地址：GifHelper 什么是APT？ APT是Annotation Processing Tool的简称，即编译时注解处理器。它是一个javac的工具，在编译时，通过注解，按照规则自动生成相关代码的工具。 APT与Glide什么关系？ 我们通常通过在build.gradle加入这样一段代码来引入Glide库。 123456789repositories { google() jcenter()}dependencies { implementation 'com.github.bumptech.glide:glide:4.11.0' annotationProcessor 'com.github.bumptech.glide:compiler:4.11.0'} 这里有一个annotationProcessor，这就是对Glide提供的APT进行引用。我们查看Glide的源码结构，可以看到一个名为annotation的文件夹，这里就是与APT有关的部分。 接下来我们先通过GIF优化，看一看Glide的APT能实现的神奇效果，在这之后，再来分析Glide是如何通过APT实现的。 注意：如果使用kotlin需要先加入apply plugin: 'kotlin-kapt'插件，并且将annotationProcessor改成kapt。 GIF优化为什么要优化GIF？ 有人可能会有疑问，Glide相比其他图片加载框架的优势之一，就是支持GIF，为什么还要做优化呢？ 先看两个截图来对比优化前后的CPU和内存使用情况。 我们可以看出，优化后，CPU和内存状况都好了很多，那么我们是怎么做的呢？这就需要用到谷歌官方的两个库——giflib和FrameSequence，这两个库需要我们自己编译成.so文件，具体可以参考示例项目GifHelper。 我们查看GifHolder中的代码。 1234567891011121314class GifHolder(v: View) : AbsHolder&lt;GifItem&gt;(v) { ... private val gifIV = view&lt;ImageView&gt;(R.id.gifIV) override fun onBind(item: GifItem, position: Int, absAdapter: AnyAdapter) { if (item.useGifX) { // 优化后的加载方式 GlideApp.with(itemView).asGifX().load(item.source()).into(gifIV) } else { // 优化前的加载方式 Glide.with(itemView).asGif().load(item.source()).into(gifIV) } .... }} 我们可以看到，加载后有这样一条语句：GlideApp.with(itemView).asGifX().load(item.source()).into(gifIV)，也许你会懵逼，哪里有GlideApp？哪里有asGifX()方法？我引入Glide后怎么没有看到这两个东西？这就涉及到了APT的内容了。想要看Glide官方文档的可以看这里。 一切的起因，要从**@GlideModule**这个注解说起，我们打开demo中的MyAppGlideModule类，可以看到这个类有一个@GlideModule注解。 12345678@GlideModuleclass MyAppGlideModule : AppGlideModule() { override fun registerComponents(context: Context, glide: Glide, registry: Registry) { super.registerComponents(context, glide, registry) registry.append(Registry.BUCKET_GIF, InputStream::class.java, FrameSequenceDrawable::class.java, GifDecoder(glide.bitmapPool)) }} 我们再点开这个注解的源码，如下： 123456789@Target(ElementType.TYPE)@Retention(RetentionPolicy.CLASS)public @interface GlideModule { /** * Returns the name of the class that will be used as a replacement for {@code * com.bumptech.glide.Glide} in Applications that depend on Glide's generated code. */ String glideName() default &quot;GlideApp&quot;;} 我们现在看到“GlideApp”了，是glideName这个注解属性的默认值。我们来逐条分析一下这个注解类的相关信息： @Target(ElementType.TYPE)：指明这个注解的作用对象——只对类生效； @Retention(RetentionPolicy.CLASS)：指明了这个注解的作用阶段——编译时记录在class文件中； public @interface GlideModule：这是一个注解接口，接口名GlideModule； String glideName() default &quot;GlideApp&quot;：这个注解接口需要一个名为glideName的属性，属性默认值为“GlideApp”。 RetentionPolicy： SOURCE：这样的注解会被编译器擦除，只在编码阶段生效，目的是为了提示开发者，比如**@IntDef、@StringDef、@Visibility、@NonNull**； CLASS：记录在class文件中，编译时对编译器可见，运行时对VM不可见，这是RetentionPolicy的默认值，比如**@NotNull**; RUNTIME：记录在class文件中，在运行时需要反射获取其属性值，比如**@Column**。 就是这个**@GlideModule**属性，为我们生成了GlideApp类，这其中的生成过程，我们稍后再说，先把Gif优化的流程说完。 添加**@GlideModule**后，再次编译看，是否有了GlideApp这个类了。 我们再来看MyAppGlideModule中的代码，registry.append方法，这是为Glide添加一种解析类型。 1234567891011121314151617/* * @param bucket 要添加的类型id.* @param dataClass 要从什么数据进行解析。 ({@link java.io.InputStream}, {@link* java.io.FileDescriptor} etc).* @param resourceClass 要解析成什么数据。 ({@link android.graphics.Bitmap},* {@link com.bumptech.glide.load.resource.gif.GifDrawable} etc).* @param decoder 用什么解码器进行解析 {@link ResourceDecoder}。*/@NonNullpublic &lt;Data, TResource&gt; Registry append( @NonNull String bucket, @NonNull Class&lt;Data&gt; dataClass, @NonNull Class&lt;TResource&gt; resourceClass, @NonNull ResourceDecoder&lt;Data, TResource&gt; decoder) { decoderRegistry.append(bucket, decoder, dataClass, resourceClass); return this;} 接下来就要引入谷歌官方的两个类库了，FrameSquence和giflib。大家可以根据需要下载对应版本的库，不过这两个库的版本最好要对应。 下载后需要编译，项目结构参考GifHelper项目中的framesequence/src/main/jni文件夹。注意，需要将FrameSequence_gif.h中的include部分进行修改。 12345- #include &quot;config.h&quot;- #include &quot;gif_lib.h&quot;改成+ #include &quot;giflib/config.h&quot;+ #include &quot;giflib/gif_lib.h&quot; 然后执行ndk-build，则会在jni同级的目录下，生成一个libs文件夹，.so文件就在这里。 接下来需要去自定义GifDecoder.java了，直接上代码： 12345678910111213141516171819202122232425262728class GifDecoder(private val bmpPool: BitmapPool) : ResourceDecoder&lt;InputStream, FrameSequenceDrawable&gt; { private val headerParser = DefaultImageHeaderParser() override fun handles(source: InputStream, options: Options): Boolean { return !(options.get(GifOptions.DISABLE_ANIMATION) ?: true) &amp;&amp; headerParser.getType(source) == ImageHeaderParser.ImageType.GIF } override fun decode( source: InputStream, width: Int, height: Int, options: Options ): Resource&lt;FrameSequenceDrawable&gt;? { val fs = FrameSequence.decodeStream(source) val fsd = FrameSequenceDrawable(fs, object : FrameSequenceDrawable.BitmapProvider { override fun acquireBitmap(minWidth: Int, minHeight: Int): Bitmap { return bmpPool.get(minWidth, minHeight, Bitmap.Config.ARGB_8888) } override fun releaseBitmap(bitmap: Bitmap?) { bmpPool.put(bitmap) } }) return GifResource(fsd) }} 这个类里只需要实现两个方法：handles和decode： handles：能否解析该输入源，能则返回true； decode：如果handles返回true，则执行此方法，返回一个Resource对象包裹住目标类型对象。 我们通过Glide自带的ImageHeaderParser来检测该输入流是否是gif图像的输入流，如果是且可以执行动画，则进行decode操作。 我们着重看decode方法，这里需要重点看的是，在构建FrameSequenceDrawable时候，传入了一个BitmapProvider对象，这就是提高Gif效率的关键，在这个BitmapProvider里面，我们通过BitmapPool，去寻找可用尺寸的Bitmap，通过池化的方式，减小了内存开销，增加里Bitmap利用率。 接下来看，如何添加asGifX方法。我们都知道，传统的Glide调用方式如下图： Glide.with(itemView).asGif().load(item.source()).into(gifIV) 12graph LR;A[Glide] --&gt;|&quot;with(xxx)&quot;| B[RequestManager] --&gt;|&quot;asGif&quot;| C[RequestBuilder]; 而新的方式却不同，如下图： GlideApp.with(itemView).asGifX().load(item.source()).into(gifIV) 12graph LR;A[GlideApp] --&gt;|&quot;with(xxx)&quot;| B[GlideRequests] --&gt;|asGifX| C[GlideRequest]; 这其中的GlideRequest和GlideRequest，同样都是生成的类，其中GlideRequests继承自RequestManager，GlideRequest继承自RequestBuilder。 这两个类的生成，同样是**@GlideModule**的作用，但是asGifX这个方法是什么时候定义的呢？我们去查看asGifX这个方法的代码： 12345678/*** @see GifExtension#asGifX(RequestBuilder)*/@NonNull@CheckResultpublic GlideRequest&lt;FrameSequenceDrawable&gt; asGifX() { return (GlideRequest&lt;FrameSequenceDrawable&gt;) GifExtension.asGifX(this.as(FrameSequenceDrawable.class));} 我们看到实际上这个类的具体实现，是依靠GifExtension类，我们去看这个类的代码： 1234567891011@GlideExtensionpublic class GifExtension { @NonNull @GlideType(FrameSequenceDrawable.class) public static RequestBuilder&lt;FrameSequenceDrawable&gt; asGifX(RequestBuilder&lt;FrameSequenceDrawable&gt; requestBuilder) { return requestBuilder.apply(RequestOptions .decodeTypeOf(FrameSequenceDrawable.class) .lock()); } private GifExtension(){}} 这个类需要我们自己实现，并且需要标记**@GlideExtension**注解，又是注解的功劳。 到此为止，Gif优化的主流程就全部讲完了，接下来就要看这两个注解——**@GlideModule和@GlideExtension**到底做了什么？ @GlideModule和@GlideExtension源码在Glide项目的annotation/compiler内，这种APT项目的入口文件标记在src/main/resources/META-INF/gradle内，这其中有一个incremental.annotation.processors文件，我们查看其内容： 1com.bumptech.glide.annotation.compiler.GlideAnnotationProcessor,aggregating 可以得知，程序入口在GlideAnnotationProcessor这个类，查看这个类的源码，我只提取了关键部分： 12345678910111213141516171819202122232425262728293031323334public final class GlideAnnotationProcessor extends AbstractProcessor { ... private LibraryModuleProcessor libraryModuleProcessor; private AppModuleProcessor appModuleProcessor; private boolean isGeneratedAppGlideModuleWritten; private ExtensionProcessor extensionProcessor; ... @Override public Set&lt;String&gt; getSupportedAnnotationTypes() { Set&lt;String&gt; result = new HashSet&lt;&gt;(); result.addAll(libraryModuleProcessor.getSupportedAnnotationTypes()); result.addAll(extensionProcessor.getSupportedAnnotationTypes()); return result; } @Override public boolean process(Set&lt;? extends TypeElement&gt; set, RoundEnvironment env) { processorUtil.process(); boolean newModulesWritten = libraryModuleProcessor.processModules(env); boolean newExtensionWritten = extensionProcessor.processExtensions(env); appModuleProcessor.processModules(set, env); if (newExtensionWritten || newModulesWritten) { if (isGeneratedAppGlideModuleWritten) { throw new IllegalStateException(&quot;Cannot process annotations after writing AppGlideModule&quot;); } return false; } if (!isGeneratedAppGlideModuleWritten) { isGeneratedAppGlideModuleWritten = appModuleProcessor.maybeWriteAppModule(); } return false; }} getSupportedAnnotationTypes方法中标记了，支持哪些注解的解析，其中libraryModuleProcessor.getSupportedAnnotationTypes()中返回了**@GlideModule，extensionProcessor.getSupportedAnnotationTypes()中返回了@GlideExtension**。 process方法中开始了对注解的处理。 注解的处理，需要你对javapoet有一点点了解，如果暂时不想去了解，你只需要知道，这个类库是通过字符串和占位符来生成Java代码的工具类库，因为接下来的生成代码工作，Glide就是通过这个类库来实现的。 具体的生成过程不再赘述，从入口类GlideAnnotationProcessor追踪下去，就能看到。 为什么优化能提高效率？Glide默认Gif加载方案，是通过GifDrawable来实现的，而GifDrawable是通过GifFrameLoader来加载帧数据的。具体代码分析可以看参考文章，我这里简单来说一下原因： 默认方案是串行执行的，比如在加载显示第N帧，这一帧显示完毕，再去解析第N+1帧，当播放第N+1帧的时间窗口到了以后，如果已经解析完毕，则能正常显示，如果不能解析完毕，则会卡顿了； GifFrameLoader内部是用了一个mainLooper的handler来进行流程控制，具体可以看GifFrameLoader里的代码，这种方式本身在时间上就不是准时的，与应用内其他各种系统共享mainLooper，如果其他事件执行占用时间较长，也会影响这里的效率了。 我们再来说说优化方案，优化的原因也简单说一下： 优化方案是并行+双缓冲执行的，在显示第N帧的BitmapA同时，会有一个后台线程在解析第N+1帧的BitmapB，当需要显示第N+1帧BitmapB的时候，两帧的Bitmap交换，BitmapA则进入后台线程去解析第N+2帧了； 在native去解析数据，效率更高； 通过BitmapPool提高了内存利用率。 借用参考文章里的一张图 参考文章Glide加载Gif的卡顿优化思路分析","link":"/2020/12/27/2022-09-17-Glide%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%8E%E8%87%AA%E6%88%91%E5%AE%9E%E7%8E%B03/"},{"title":"Jetpack之Lifecycle源码分析","text":"这是一篇解析jetpack库中的Lifecycle库的分析文章。 12345def lifecycle_version = &quot;2.2.0&quot;// Lifecycles only (without ViewModel or LiveData)implementation &quot;androidx.lifecycle:lifecycle-runtime-ktx:$lifecycle_version&quot;// Annotation processorkapt &quot;androidx.lifecycle:lifecycle-compiler:$lifecycle_version&quot; 1234567891011class MyObserver : LifecycleObserver { @OnLifecycleEvent(Lifecycle.Event.ON_CREATE) fun onCreate() { } @OnLifecycleEvent(Lifecycle.Event.ON_PAUSE) fun onPause() { }} 12345678class MainActivity : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) lifecycle.addObserver(MyObserver()) }} 这是一个很典型的Lifecycle库的使用过程，通过注解的方式，在MyObserver中声明对应的生命周期函数，然后将这个MyObserver实例添加到MainActivity的lifecycle中去。 看到与注解相关，熟悉框架源码的朋友可能已经知道如何去分析了，很可能用到注解处理器，与ARouter类似，Lifecycle的工作流程也分成两部分——编译时和运行时。 简要的说，在编译时，生成LifecycleObserver的辅助类；在运行时，addObserver方法被调用后，解析出对应observer的辅助类。 生命周期探知在正式详解这两个过程前，我们需要先要了解Lifecycle库是如何感知生命周期的呢？ 读过Glide源码(附上Glide源码解读)的同学可能知道，Glide感知生命周期是通过一个无UI的fragment来实现的，其实，Lifecycle也是这么做的。 对外提供生命周期的类，需要实现LifecycleOwner接口。 123456789public interface LifecycleOwner { /** * Returns the Lifecycle of the provider. * * @return The lifecycle of the provider. */ @NonNull Lifecycle getLifecycle();} 我们以AppCompatActivity为例去查看它是如何实现的这个接口，我们查看其父类中有一个ComponentActivity类(AppCompatActivity -&gt; FragmentActivity -&gt; ComponentActivity)。 123456789101112131415public class ComponentActivity extends androidx.core.app.ComponentActivity implements LifecycleOwner, ViewModelStoreOwner, SavedStateRegistryOwner, OnBackPressedDispatcherOwner { @Override protected void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); mSavedStateRegistryController.performRestore(savedInstanceState); ReportFragment.injectIfNeededIn(this); if (mContentLayoutId != 0) { setContentView(mContentLayoutId); } }} 注意此处，有一个ReportFragment执行了injectIfNeededIn方法，在这个方法中，就是检测是否已经添加了这个ReportFragment，如果没添加则添加一个。继续查看这个ReportFragment的源码，可以在其生命周期函数中，执行了分发生命周期的流程。 1234567891011121314151617181920212223242526272829303132333435363738public class ReportFragment extends Fragment { static void dispatch(@NonNull Activity activity, @NonNull Lifecycle.Event event) { if (activity instanceof LifecycleRegistryOwner) { ((LifecycleRegistryOwner) activity).getLifecycle().handleLifecycleEvent(event); return; } if (activity instanceof LifecycleOwner) { // 3 Lifecycle lifecycle = ((LifecycleOwner) activity).getLifecycle(); if (lifecycle instanceof LifecycleRegistry) { ((LifecycleRegistry) lifecycle).handleLifecycleEvent(event); } } } private void dispatchCreate(ActivityInitializationListener listener) { if (listener != null) { listener.onCreate(); } } @Override public void onActivityCreated(Bundle savedInstanceState) { super.onActivityCreated(savedInstanceState); dispatchCreate(mProcessListener); dispatch(Lifecycle.Event.ON_CREATE); // 1 } private void dispatch(@NonNull Lifecycle.Event event) { if (Build.VERSION.SDK_INT &lt; 29) { // Only dispatch events from ReportFragment on API levels prior // to API 29. On API 29+, this is handled by the ActivityLifecycleCallbacks // added in ReportFragment.injectIfNeededIn dispatch(getActivity(), event); // 2 } }} 看代码中我标注的注释顺序onActivityCreated -&gt; dispatch(Lifecycle.Event) -&gt; dispatch(Activity, Lifecycle.Event)，我们看到最后一个流程中，拿到Lifecycle对象后，判断是否为LifecycleRegistry类，如果是，则调用handleLifecycleEvent方法。这里，ComponentActivity提供的Lifecycle对象就是LifecycleRegistry类。 经过这样一个流程，我们就将感知生命周期的无UI的ReportFragment与执行事件的LifecycleRegistry进行了连接。这样我们就获得了感知生命周期的能力了。 那么具体是如何执行到MyObserver对应的生命周期的方法的呢？ 或许你看到这里，会觉得很简单，在LifecycleRegistry维护一个observer队列，然后在执行handleLifecycleEvent方法的时候，通过反射从MyObserver中筛选出带有**@OnLifecycleEvent**注解的方法，如果注解中的值与事件event相等，则通过method.invoke()来调用。 可是谷歌工程师并没有这么做，因为在执行事件时候，经过这么多反射，效率会很低。那么正确的流程是怎么样的？这就需要我们关注上面提到的两个流程了——编译时和运行时。 编译时参考Lifecycle-compiler源码。 通过注解处理器，AS为我们生成了MyObserver的辅助类——MyObserver_LifecycleAdapter。 12345678910111213141516171819202122232425262728public class MyObserver_LifecycleAdapter implements GeneratedAdapter { final MyObserver mReceiver; MyObserver_LifecycleAdapter(MyObserver receiver) { this.mReceiver = receiver; } @Override public void callMethods(LifecycleOwner owner, Lifecycle.Event event, boolean onAny, MethodCallsLogger logger) { boolean hasLogger = logger != null; if (onAny) { return; } if (event == Lifecycle.Event.ON_CREATE) { if (!hasLogger || logger.approveCall(&quot;onCreate&quot;, 1)) { mReceiver.onCreate(); } return; } if (event == Lifecycle.Event.ON_PAUSE) { if (!hasLogger || logger.approveCall(&quot;onPause&quot;, 1)) { mReceiver.onPause(); } return; } }} 我们可以看到，实际的生命周期事件分发是在这里完成的。那么这个辅助类是在哪里被使用到的呢？ 接下来就是运行时发挥作用的时候了。 运行时运行时的起点，是从addObserver开始的。 我们查看LifecycleRegistry#addObserver方法。 123456789private FastSafeIterableMap&lt;LifecycleObserver, ObserverWithState&gt; mObserverMap = new FastSafeIterableMap&lt;&gt;();@Overridepublic void addObserver(@NonNull LifecycleObserver observer) { State initialState = mState == DESTROYED ? DESTROYED : INITIALIZED; ObserverWithState statefulObserver = new ObserverWithState(observer, initialState); ObserverWithState previous = mObserverMap.putIfAbsent(observer, statefulObserver); ...} 我们可以看到，LifecycleRegistry中并不是直接维护observer对象，而是维护ObserverWithState对象。 12345678910111213141516static class ObserverWithState { State mState; LifecycleEventObserver mLifecycleObserver; ObserverWithState(LifecycleObserver observer, State initialState) { mLifecycleObserver = Lifecycling.lifecycleEventObserver(observer); mState = initialState; } void dispatchEvent(LifecycleOwner owner, Event event) { State newState = getStateAfter(event); mState = min(mState, newState); mLifecycleObserver.onStateChanged(owner, event); mState = newState; }} 在这个类的构造方法中，执行了一个mLifecycleObserver = Lifecycling.lifecycleEventObserver(observer); 在我们的案例中，这个方法返回了一个SingleGeneratedAdapterObserver类，我们查看这个类的代码。 1234567891011121314class SingleGeneratedAdapterObserver implements LifecycleEventObserver { private final GeneratedAdapter mGeneratedAdapter; SingleGeneratedAdapterObserver(GeneratedAdapter generatedAdapter) { mGeneratedAdapter = generatedAdapter; } @Override public void onStateChanged(@NonNull LifecycleOwner source, @NonNull Lifecycle.Event event) { mGeneratedAdapter.callMethods(source, event, false, null); mGeneratedAdapter.callMethods(source, event, true, null); }} 也就是在这里，调用了MyObserver_LifecycleAdapter的callMethods方法。 那么是如何找到MyObserver_LifecycleAdapter方法的呢？ 在Lifecycling类中，通过observer的类名来找的，我们看到有这样的一个方法： 123public static String getAdapterName(String className) { return className.replace(&quot;.&quot;, &quot;_&quot;) + &quot;_LifecycleAdapter&quot;;} 这样，整个流程就串起来了。 总结编译时：生成XXX_LifecycleAdapter类，用来分发不同的生命周期事件。 运行时：在addObserver时候，通过类名找到这个XXX_LifecycleAdapter类，生成对象在LifecycleRegistry中进行维护；在ReportFragment方法中触发生命周期时候，调用LifecycleRegistry的handleLifecycleEvent方法进行具体的生命周期事件分发。 总体来看，其整个流程并不复杂，我们可以看到ARouter、Glide的影子，读过其他源码后，理解这个并不难。","link":"/2021/03/12/2022-09-17-Jetpack%E4%B9%8BLifecycle%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Jetpack之LiveData源码分析","text":"在阅读这篇文章前，需要先对[**Lifecycle**](/源码分析系列/Jetpack之Lifecycle源码分析.md)有所了解。 Lifecycle是LiveData的根基，先有了生命周期的管理，才能进行安全不泄漏的数据观察。 先要引入LiveData： 12345implementation &quot;androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0&quot;def activity_version = &quot;1.1.0&quot;// Kotlin，引入这个扩展，可以使用by viewModels()方法implementation &quot;androidx.activity:activity-ktx:$activity_version&quot; 典型的用法如下： 12345678910111213141516class MainActivity : AppCompatActivity() { private val vm by viewModels&lt;MainVM&gt;() override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) vm.data.observe(this) { Toast.makeText(this@MainActivity, it, Toast.LENGTH_SHORT).show() } vm.start() }} 12345678910111213class MainVM : ViewModel() { val data = MutableLiveData&lt;String&gt;() fun start() { data.value = &quot;start&quot; Thread { Thread.sleep(2000) data.postValue(&quot;run after 2000ms&quot;) }.start() }} 从这两段代码中，我们就可以看出典型的用法，主要是在三个方法上，observe、setValue和postValue。我们就从这三个方法入手去探究LiveData的工作机制。 observe方法1234567891011121314151617181920// LiveData.java@MainThreadpublic void observe(@NonNull LifecycleOwner owner, @NonNull Observer&lt;? super T&gt; observer) { assertMainThread(&quot;observe&quot;); if (owner.getLifecycle().getCurrentState() == DESTROYED) { // ignore return; } LifecycleBoundObserver wrapper = new LifecycleBoundObserver(owner, observer); ObserverWrapper existing = mObservers.putIfAbsent(observer, wrapper); if (existing != null &amp;&amp; !existing.isAttachedTo(owner)) { throw new IllegalArgumentException(&quot;Cannot add the same observer&quot; + &quot; with different lifecycles&quot;); } if (existing != null) { return; } owner.getLifecycle().addObserver(wrapper);} 只允许在主线程中监听数据变化，并且如果LifecycleOwner已经处于DESTROYED状态，则忽略这次监听请求。 以LifecycleOwner和Observer创建一个LifecycleBoundObserver对象，这个对象继承了ObserverWrapper类，同时实现了LifecycleEventObserver接口，看到这个接口，我们便明白了LiveData能够生命周期安全的监听数据变化的原因了。 这个LifecycleBoundObserver对象需要存储在一个SafeIterableMap当中去，在存储时候，会通过observer判断是否已经存在一个ObserverWrapper对象existing，如果已经存在则分为两种：a. 如果existing没有attach在owner上，则说明，existing已经attach在另外一个LifecycleOwner上了，这是不允许的，此时需要抛出异常；b. 如果没有attach在另外一个LifecycleOwner上，则说明此时监听的就是当前的owner上，则不需要再次添加监听，直接返回。如果existing不存在，则向owner.getLifecycle()添加监听。 setValue和postValue方法在子线程中更新数据，需要调用postValue方法，实际上，这个方法就是通过一个MainHandler去post一个Runnable的方式切换到主线程中执行setValue方法。所以，我们重点看setValue方法即可。 123456789// LiveData.java@MainThreadprotected void setValue(T value) { assertMainThread(&quot;setValue&quot;); mVersion++; mData = value; dispatchingValue(null);} 这里需要注意到的是mVersion++这句话，LiveData就是通过版本号来记录新的值的。继续看dispatchingValue方法。 dispatchingValue123456789101112131415161718192021222324@SuppressWarnings(&quot;WeakerAccess&quot;) /* synthetic access */void dispatchingValue(@Nullable ObserverWrapper initiator) { if (mDispatchingValue) { // ① mDispatchInvalidated = true; return; } mDispatchingValue = true; do { mDispatchInvalidated = false; // ② if (initiator != null) { considerNotify(initiator); initiator = null; } else { for (Iterator&lt;Map.Entry&lt;Observer&lt;? super T&gt;, ObserverWrapper&gt;&gt; iterator = mObservers.iteratorWithAdditions(); iterator.hasNext(); ) { considerNotify(iterator.next().getValue()); if (mDispatchInvalidated) { // ③ break; } } } } while (mDispatchInvalidated); mDispatchingValue = false;} 在这里，涉及到两个方法，1. 第一个dispatchingValue —— 用来分发控制数据更新流程；2. considerNotify具体执行数据更新操作。 这个方法是双信号量控制分发流程，mDispatchingValue和mDispatchInvalidated，之所以这样设计，按照我的理解，是考虑到了dispatchingValue方法多线程重入的问题，但是依我看来，这样做没必要，因为这个方法的几处调用，都是在主线程上，不可能出现第一次调用没有执行完，就又被调用一次的可能，也可能是设计者考虑到未来的扩展或者在这个库涉及之初有多线程调用的情况才这样写的，先按照有重入可能来分析。 我们先要弄清这两个信号量的作用：mDispatchingValue表示是否正在执行分发数据更新的操作，mDispatchInvalidated表示是否中断正在进行的分发，开始新一轮分发。 这个方法是根据传入的参数，有两个执行流程，一个是执行具体某个ObserverWrapper的数据更新操作，另外一个就是批量更新所有observer的数据操作。我们以setValue触发的dispatchingValue(null)批量更新操作为例进行分析。 注意我在上段代码中的序号①②③注释，我们分步骤进行分析： 假设，此时我们有两个observer。 初始状态 mDispatchingValue = false, mDispatchInvalidated = false 当第一次调用开始后，会顺利通过①处判断，然后进入do - while循环，并且在②处先将mDispatchInvalidated信号量置为false，所以，一般情况下，这个while循环只会执行一次； 信号量：mDispatchingValue = true, mDispatchInvalidated = false 由于initiator参数为null，所以会进入到else分支中的for循环中，这里需要注意的是，每一次for循环结束时候，都判断一次mDispatchInvalidated信号量，也就是注释③处； 假设我们执行了第一个observer后，dispatchingValue方法进行了第二次调用，由于此时mDispatchingValue信号量为true，所以会进入①处if条件判断语句，将mDispatchInvalidated信号量置为true并且直接return了； 信号量：mDispatchingValue = true, mDispatchInvalidated = true 此时，第一次调用的for循环体就会因为mDispatchInvalidated变成了true，而退出for循环，while循环开始判断条件，同样因为mDispatchInvalidated为true，回再次执行while循环，执行新值更新； 最后退出dispatchingValue方法后，两个信号量都置为false。 这样做的目的，或许是为了及时抛弃旧值通知，开始新值通知。 considerNotify12345678910111213141516171819202122@SuppressWarnings(&quot;unchecked&quot;)private void considerNotify(ObserverWrapper observer) { if (!observer.mActive) { return; } // Check latest state b4 dispatch. Maybe it changed state but we didn't get the event yet. // // we still first check observer.active to keep it as the entrance for events. So even if // the observer moved to an active state, if we've not received that event, we better not // notify for a more predictable notification order. if (!observer.shouldBeActive()) { observer.activeStateChanged(false); return; } if (observer.mLastVersion &gt;= mVersion) { return; } observer.mLastVersion = mVersion; observer.mObserver.onChanged((T) mData);} 这个方法是具体执行通知观察者值变化的地方。 那么LiveData是如何判断新值和旧值的呢？ 在setValue方法中，有一个mVersion++语句，每次设置新值都会触发这个mVersion的自增，然后在considerNotify方法中，去校验observer是否处于active状态以及新值版本号与observer中的版本号，如果observer应当处于非active状态而仍然处于active状态(因为状态可能由于handler机制并没有及时变更)，则进行状态变更并返回，并且如果observer.mLastVersion &gt;= mVersion，则直接返回，因为此时observer已经更新过此值。也就是说，只有observer处于active状态且当前mVersion &gt; observer.mVersion的时候，才去通知observer更新值。 接下来，着重看一下LifecycleBoundObserver和ObserverWrapper这个两个类。 LifecycleBoundObserver和ObserverWrapperObserverWrapper是Observer的抽象包装类，代码很简单： 1234567891011121314151617181920212223242526272829303132333435363738private abstract class ObserverWrapper { final Observer&lt;? super T&gt; mObserver; boolean mActive; int mLastVersion = START_VERSION; ObserverWrapper(Observer&lt;? super T&gt; observer) { mObserver = observer; } abstract boolean shouldBeActive(); boolean isAttachedTo(LifecycleOwner owner) { return false; } void detachObserver() { } void activeStateChanged(boolean newActive) { if (newActive == mActive) { return; } // immediately set active state, so we'd never dispatch anything to inactive // owner mActive = newActive; boolean wasInactive = LiveData.this.mActiveCount == 0; LiveData.this.mActiveCount += mActive ? 1 : -1; if (wasInactive &amp;&amp; mActive) { onActive(); } if (LiveData.this.mActiveCount == 0 &amp;&amp; !mActive) { onInactive(); } if (mActive) { dispatchingValue(this); } }} 在activeStateChanged方法中，先判断是否是状态的改变，如果newActive == mActive说明激活状态未改变，则直接返回；然后判断按照激活的observer数目和mActive状态，来判断LiveData的状态，并调用其空回调函数；最后如果mActive为true，则进行针对这个ObserverWrapper的事件分发。 ObserverWrapper有两个子类，LifecycleBoundObserver和AlwaysActiveObserver，AlwaysActiveObserver是与生命周期无关的observer，需要谨慎使用，在适当的时候，通过removeObserver来删除，我们重点看LifecycleBoundObserver。 LifecycleBoundObserver同时实现了LifecycleEventObserver，这就使得这个类具备了生命周期关联性。 12345678910111213141516171819202122232425262728293031323334class LifecycleBoundObserver extends ObserverWrapper implements LifecycleEventObserver { @NonNull final LifecycleOwner mOwner; LifecycleBoundObserver(@NonNull LifecycleOwner owner, Observer&lt;? super T&gt; observer) { super(observer); mOwner = owner; } @Override boolean shouldBeActive() { return mOwner.getLifecycle().getCurrentState().isAtLeast(STARTED); } @Override public void onStateChanged(@NonNull LifecycleOwner source, @NonNull Lifecycle.Event event) { if (mOwner.getLifecycle().getCurrentState() == DESTROYED) { removeObserver(mObserver); return; } activeStateChanged(shouldBeActive()); } @Override boolean isAttachedTo(LifecycleOwner owner) { return mOwner == owner; } @Override void detachObserver() { mOwner.getLifecycle().removeObserver(this); }} 在onStateChanged方法中，当生命周期处于DESTROYED状态时候，则删除这个observer。除此以外，当mOwner的生命周期处于STARTED之后的状态，则认为shouldBeActive，当生命周期函数onStateChanged被触发时候，将设置是否active。 总结通过LiveData的这些特性，我们可以实现Activity - Fragment, Fragment - Fragment的通信，另外也可以做应用的事件总线，比如LiveEventBus。","link":"/2021/01/01/2022-09-17-Jetpack%E4%B9%8BLiveData%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"LeakCanary原理分析","text":"1234dependencies { // debugImplementation because LeakCanary should only run in debug builds. debugImplementation 'com.squareup.leakcanary:leakcanary-android:2.5'} 只需要这样简单配置，就能接入LeakCanary内存泄漏分析，到底是怎样做到的？ 我们将这个问题分成两个问题： 如何自动进行初始化的； 如何检测到内存泄漏的。 如何自动进行初始化的这部分，我们可以分成两部分去理解——自动和初始化。 自动这一切还要从ActivityThread说起。ActivityThread中，执行了一些应用启动的初始化工作，在ActivityThread源码中，我们可以看到其内部类class H extends Handler的handleMessage方法中，有很多与应用相关的一些基本操作，比如BIND_APPLICATION, EXIT_APPLICATION, CREATE_SERVICE, BIND_SERVICE等，其中需要我们关注的是BIND_APPLICATION。 12345678910111213public void handleMessage(Message msg) { .... switch (msg.what) { case BIND_APPLICATION: Trace.traceBegin(Trace.TRACE_TAG_ACTIVITY_MANAGER, &quot;bindApplication&quot;); AppBindData data = (AppBindData)msg.obj; handleBindApplication(data); Trace.traceEnd(Trace.TRACE_TAG_ACTIVITY_MANAGER); break; .... } ....} 我们可以看到，其中调用了handleBindApplication方法。进入这个方法查看。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@UnsupportedAppUsageprivate void handleBindApplication(AppBindData data) { .... Application app; final StrictMode.ThreadPolicy savedPolicy = StrictMode.allowThreadDiskWrites(); final StrictMode.ThreadPolicy writesAllowedPolicy = StrictMode.getThreadPolicy(); try { // If the app is being launched for full backup or restore, bring it up in // a restricted environment with the base application class. app = data.info.makeApplication(data.restrictedBackupMode, null); // Propagate autofill compat state app.setAutofillOptions(data.autofillOptions); // Propagate Content Capture options app.setContentCaptureOptions(data.contentCaptureOptions); mInitialApplication = app; // don't bring up providers in restricted mode; they may depend on the // app's custom Application class if (!data.restrictedBackupMode) { if (!ArrayUtils.isEmpty(data.providers)) { installContentProviders(app, data.providers); } } // Do this after providers, since instrumentation tests generally start their // test thread at this point, and we don't want that racing. try { mInstrumentation.onCreate(data.instrumentationArgs); } catch (Exception e) { throw new RuntimeException( &quot;Exception thrown in onCreate() of &quot; + data.instrumentationName + &quot;: &quot; + e.toString(), e); } try { mInstrumentation.callApplicationOnCreate(app); } catch (Exception e) { if (!mInstrumentation.onException(app, e)) { throw new RuntimeException( &quot;Unable to create application &quot; + app.getClass().getName() + &quot;: &quot; + e.toString(), e); } } } finally { // If the app targets &lt; O-MR1, or doesn't change the thread policy // during startup, clobber the policy to maintain behavior of b/36951662 if (data.appInfo.targetSdkVersion &lt; Build.VERSION_CODES.O_MR1 || StrictMode.getThreadPolicy().equals(writesAllowedPolicy)) { StrictMode.setThreadPolicy(savedPolicy); } } ....} 从这个方法中，我们可以找到这样一段代码，需要重点关注的是，ContentProvider的初始化是先于Application.onCreate的，且是被ActivityThread自动执行的。 接下来再看LeakCanary源码。找到AppWatcherInstaller.kt这个类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Content providers are loaded before the application class is created. [AppWatcherInstaller] is * used to install [leakcanary.AppWatcher] on application start. */internal sealed class AppWatcherInstaller : ContentProvider() { /** * [MainProcess] automatically sets up the LeakCanary code that runs in the main app process. */ internal class MainProcess : AppWatcherInstaller() /** * When using the `leakcanary-android-process` artifact instead of `leakcanary-android`, * [LeakCanaryProcess] automatically sets up the LeakCanary code */ internal class LeakCanaryProcess : AppWatcherInstaller() override fun onCreate(): Boolean { val application = context!!.applicationContext as Application AppWatcher.manualInstall(application) return true } override fun query( uri: Uri, strings: Array&lt;String&gt;?, s: String?, strings1: Array&lt;String&gt;?, s1: String? ): Cursor? { return null } override fun getType(uri: Uri): String? { return null } override fun insert( uri: Uri, contentValues: ContentValues? ): Uri? { return null } override fun delete( uri: Uri, s: String?, strings: Array&lt;String&gt;? ): Int { return 0 } override fun update( uri: Uri, contentValues: ContentValues?, s: String?, strings: Array&lt;String&gt;? ): Int { return 0 }} 我们可以看到，这个类是一个ContentProvider的子类，其query, insert等方法根本没有实际作用，有实际作用的只有onCreate方法，在这个方法中，执行了AppWatcher的install工作。 这里我们就可以看出来，LeakCanary就是利用ContentProvider的onCreate方法自动执行的特性，来自动“安装”这个类库的。 初始化通过追踪AppWatcher.manualInstall(application)这句代码，我们可以追踪到InternalLeakCanary.kt的install方法，如下： 123456789101112131415fun install(application: Application) { checkMainThread() if (this::application.isInitialized) { return } InternalAppWatcher.application = application if (isDebuggableBuild) { SharkLog.logger = DefaultCanaryLog() } val configProvider = { AppWatcher.config } ActivityDestroyWatcher.install(application, objectWatcher, configProvider) FragmentDestroyWatcher.install(application, objectWatcher, configProvider) onAppWatcherInstalled(application)} 我们可以看到，先后执行了ActivityDestroyWatcher.install,FragmentDestroyWatcher.install和onAppWatcherInstalled(application)方法。 其中在onAppWatcherInstalled创建了LeakCanary图标的快捷方式，用于方便查看内存泄漏的路径信息。最终实现的具体过程可以查看InternalLeakCanary.kt的addDynamicShortcut方法。 其他的两段代码——ActivityDestroyWatcher.install和FragmentDestroyWatcher.install，分别对应着两个类——ActivityDestroyWatcher和FragmentDestroyWatcher。这两个类相对来说比较简单，主要工作就是执行了application.registerActivityLifecycleCallbacks这段代码，目的是为了监听每个Activity的onDestroy事件。这也是判断该Activity是否泄漏的开端。 以ActivityDestroyWatcher为例，其ActivityLifecycleCallback中代码如下： 12345678910private val lifecycleCallbacks = object : Application.ActivityLifecycleCallbacks by noOpDelegate() { override fun onActivityDestroyed(activity: Activity) { if (configProvider().watchActivities) { objectWatcher.watch( activity, &quot;${activity::class.java.name} received Activity#onDestroy() callback&quot; ) } } } 我们可以看到，这其中，最终是objectWatcher来进行内存泄漏监控的。 如何检测到内存泄漏的这里涉及到两个关键的类：**ObjectWatcher和KeyedWeakReference**。 KeyedWeakReference是WeakReference的子类，添加了额外的属性，代码十分简单，如下： 123456789101112131415161718192021class KeyedWeakReference( referent: Any, val key: String, val description: String, val watchUptimeMillis: Long, referenceQueue: ReferenceQueue&lt;Any&gt;) : WeakReference&lt;Any&gt;( referent, referenceQueue) { /** * Time at which the associated object ([referent]) was considered retained, or -1 if it hasn't * been yet. */ @Volatile var retainedUptimeMillis = -1L companion object { @Volatile @JvmStatic var heapDumpUptimeMillis = 0L }} 接下来我们看ObjectWatcher中的watchObject方法。 123456789101112131415161718192021222324252627282930/** * Watches the provided [watchedObject]. * * @param description Describes why the object is watched. */@Synchronized fun watch( watchedObject: Any, description: String) { if (!isEnabled()) { return } removeWeaklyReachableObjects() val key = UUID.randomUUID() .toString() val watchUptimeMillis = clock.uptimeMillis() val reference = KeyedWeakReference(watchedObject, key, description, watchUptimeMillis, queue) SharkLog.d { &quot;Watching &quot; + (if (watchedObject is Class&lt;*&gt;) watchedObject.toString() else &quot;instance of ${watchedObject.javaClass.name}&quot;) + (if (description.isNotEmpty()) &quot; ($description)&quot; else &quot;&quot;) + &quot; with key $key&quot; } watchedObjects[key] = reference checkRetainedExecutor.execute { moveToRetained(key) }} 这里分为三步： 执行removeWeaklyReachableObjects()方法，这个方法之后讲到； 生成一个KeyedWeakReference对象，并将这个对象添加到watchedObjects去； 定时执行moveToRetained方法。 我们先看第二步，生成KeyedWeakReference对象时候，传入了一个一个ReferenceQueue对象，这是检测对象是否被回收的关键。假如一个对象O，被弱引用WR持有的时候，同时这个弱引用WR在构造时候传入了一个ReferenceQueue对象Q，则这个对象O被回收时候，WR将会被添加到Q中去，这样，通过检测Q中有没有值，便可以知道O有没有被回收掉。这也就是第一步做的事。 接下来我们查看removeWeaklyReachableObjects方法中做了什么。 1234567891011private fun removeWeaklyReachableObjects() { // WeakReferences are enqueued as soon as the object to which they point to becomes weakly // reachable. This is before finalization or garbage collection has actually happened. var ref: KeyedWeakReference? do { ref = queue.poll() as KeyedWeakReference? if (ref != null) { watchedObjects.remove(ref.key) } } while (ref != null)} 在这个方法中，从queue中取值，取出来ref，则说明被ref修饰的对象已经被回收了，则将这个弱引用ref从watchedObjects清除掉。 接下来到了第三步，这一步实际上是一个定时5秒(LeakCanary默认)去将watchedObjects中残留的引用，移入到retainedObjects中去。我们来看其中代码： 12345678@Synchronized private fun moveToRetained(key: String) { removeWeaklyReachableObjects() val retainedRef = watchedObjects[key] if (retainedRef != null) { retainedRef.retainedUptimeMillis = clock.uptimeMillis() onObjectRetainedListeners.forEach { it.onObjectRetained() } }} 执行这个任务的Executor实际实现在InternalAppWatcher.kt中，代码如下： 123private val checkRetainedExecutor = Executor { mainHandler.postDelayed(it, AppWatcher.config.watchDurationMillis)} 我们发现，在moveToRetained中，还是先执行了removeWeaklyReachableObjects这一方法。目的是再次清除已经被回收的对象。如果经过这一步，仍然有引用留在watchedObjects中，则可以认为，这些对象泄漏了。 12345678910111213141516171819/** * Returns the objects that are currently considered retained. Useful for logging purposes. * Be careful with those objects and release them ASAP as you may creating longer lived leaks * then the one that are already there. */val retainedObjects: List&lt;Any&gt;@Synchronized get() { removeWeaklyReachableObjects() val instances = mutableListOf&lt;Any&gt;() for (weakReference in watchedObjects.values) { if (weakReference.retainedUptimeMillis != -1L) { val instance = weakReference.get() if (instance != null) { instances.add(instance) } } } return instances} 总结不要在发行版本中使用LeakCanary，因为一系列初始化动作，可能会导致应用启动较慢。如果要用，请使用LeakCanary-Object-Watcher，或者直接使用Buggly这样的成熟框架。","link":"/2020/11/03/2022-09-17-LeakCanary%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/"},{"title":"LiveEventBus源码分析","text":"不再分析了，理解了LiveData后，不难理解这个框架。 阅读本文前，请先阅读[《Jetpack之LiveData源码分析》](/源码分析系列/LiveEventBus源码分析.md)。因为LiveEventBus是基于LiveData构建的。 源码地址：LiveEventBus 典型用法如下： 12345678// 监听消息LiveEventBus .get(&quot;some_key&quot;, String.class) .observe(this, new Observer&lt;String&gt;() { @Override public void onChanged(@Nullable String s) { } }); 1234// 发送消息LiveEventBus .get(&quot;some_key&quot;) .post(some_value); 其实，这三个方法就是最核心的，get、observe和post。通过get获取一个Observable对象，通过observe进行监听，通过post发送消息。我们就从这三个方法入手去分析其源码。 get方法分析跟踪get方法，不难发现，是由LiveEventBusCore单例提供的with()方法返回的Observable，LiveEventBusCore中有一个名为bus的Map&lt;String, LiveEvent&gt;的成员变量，就是在这个变量中，以key - value的形式，保存了Obserable对象。observe方法与post方法都是由Obserable提供的。Observable是一个接口，它有一个唯一的实现类：LiveEvent。也就是说，observe方法与post方法的具体实现，都是由LiveEvent类提供。 主要代码如下： ##LiveEvent 123456789101112131415161718192021222324252627282930313233343536373839404142private class LiveEvent&lt;T&gt; implements Observable&lt;T&gt; { @NonNull private final String key; private final LifecycleLiveData&lt;T&gt; liveData; // 继承自MutableLiveData，实现生命周期感知 private final Map&lt;Observer, ObserverWrapper&lt;T&gt;&gt; observerMap = new HashMap&lt;&gt;(); // 存储ObserverWrapper对象 private final Handler mainHandler = new Handler(Looper.getMainLooper()); // 便于切换到主线程 /** * 进程内发送消息 * * @param value 发送的消息 */ @Override public void post(T value) { if (ThreadUtils.isMainThread()) { postInternal(value); } else { mainHandler.post(new PostValueTask(value)); } } /** * 注册一个Observer，生命周期感知，自动取消订阅 * * @param owner LifecycleOwner * @param observer 观察者 */ @Override public void observe(@NonNull final LifecycleOwner owner, @NonNull final Observer&lt;T&gt; observer) { if (ThreadUtils.isMainThread()) { observeInternal(owner, observer); } else { mainHandler.post(new Runnable() { @Override public void run() { observeInternal(owner, observer); } }); } } } LiveEvent中通过一个成员变量Map&lt;Observer, ObserverWrapper&lt;T&gt;&gt; observerMap来存储ObserverWrapper。 ObserverWrapper是LiveData库中的Observer类的子类，","link":"/2021/01/03/2022-09-17-LiveEventBus%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"IRouter——自己手撸一个路由框架","text":"现在最流行的路由框架应该是阿里的ARouter，这几乎是组件化应用的必备了。但是ARouter用起来稍微有一点不爽，不爽在以下两点： 没有一个规范化的api式的调用方式：项目大了，调用路由的方法分布在项目各处，难以查找； 对startActivityForResult支持不够友好：按照传统方式，在onActivityResult中处理，比较分散。 基于以上问题，闲来无事，手撸一个自己的路由框架IRouter，基本使用方式如下： 1234567891011121314151617interface IRouterService { @RouteTo(&quot;topic/detail&quot;) fun topicDetail(@Key(&quot;topic&quot;) topic: Topic): Navigator}val iRouter = IRouter.Builder() .isDebug(BuildConfig.DEBUG) .errorActivity(ErrorActivity::class.java) .build() .create(IRouterService::class.java)iRouter.topicDetail(topic).startActivity(this@MainActivity)// ORiRouter.topicDetail(topic).startActivityForResult(this, 100) { requestCode, resultCode, data -&gt;} 具体的配置方式请参考IRouter，本文主要是解析源码。 如此调用方式，很像是Retrofit的方式，打开一个activity就像请求一个api一样。从这里可以体现出解决了上述的两个痛点： 类似API的调用方式，集中管理路由路径； startActivityForResult中添加回调，哪里调用，就在哪里处理结果，结构紧凑。 下面进入源码解析。 与ARouter源码分析这篇文章一样，我们分析时候要按照时态去分析这个框架在运行时和编译时做的事情。 运行时其实从上述调用的方式，有过热门开源框架源码阅读经验的，都能猜出个大概。 先从IRouter这个类创建IRouterService实例说起。使用过Retrofit的同学都知道，创建一个接口类，通过注解标注方法，不用提供具体的实现流程，就能完成网络请求。其实这并不难，这是通过动态代理实现的。我们来看IRouter.create的代码： 123456789public &lt;T&gt; T create(Class&lt;T&gt; tClass) { return (T) Proxy.newProxyInstance(tClass.getClassLoader(), new Class[]{tClass}, new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { return parseMethod(method, args); } });} 通过动态代理，我们创建了一个IRouterService的实现类，这个类在调用相关方法的时候，比如topicDetail这个方法，都会经由InvocationHandler的invoke方法来代理完成。 接下来，从invoke中调用了parseMethod方法，这个方法比较简单，主要是用于解析方法注解和参数注解，取出其中的值，比如跳转路径path和参数的key - value键值对，通过path查询出相对应的Activity的class，这些值最终汇总起来，返回一个Navigator对象，这个就是真正要执行跳转的地方。 上面提到通过path查询出Activity对应的class，既然要查询，肯定要事先存储后才能被查询到。这就涉及到编译时做的工作了。 编译时一、APT部分其实读过其他一些开源框架的人对这部分一定不会陌生。 这部分工作与ARouter类似，就是通过**@RoutePath**注解标记目标Activity，然后再通过注解处理器来获取到path - activity.class的对应关系，将这个对应关系，生成成一个类，我们查看一个生成的类的示例如下： 1234567891011121314151617package com.github.boybeak.irouter.loader;import com.github.boybeak.irouter.core.BaseLoader;import java.lang.Override;import java.lang.String;public class V2ex$Topic$Loader extends BaseLoader { @Override public String getHeader() { return &quot;topic&quot;; } @Override public void loadIntoMap() { load(&quot;detail&quot;, com.v2ex.activity.TopicActivity.class); }} 这些所有生成的类在一个包名com.github.boybeak.irouter.loader底下，这很重要，因为我们要在接下来的过程，通过这个包名去筛选生成的loader类。 理解这部分，需要对APT(注解处理器)和java poet比较了解。 二、ASM部分不太了解ASM的，可以通过这篇文章ASM库介绍与使用来了解，简单来说，ASM就是一款修改class文件的工具。能用来动态生成class文件，也可以修改已经存在的class文件。 有这样的利器，我们能做的事就太多了。 这部分，其实我就是参考了ARouter的做法，改成了自己的一些逻辑。 接下来我们要编写的是一个gradle plugin，我们主要是利用其中的Transform工具，官方解释在这里，其作用就是在编译时，会挨个遍历我们的源码、类库、jar包等。附上一个教程Gradle 学习之 Android 插件的 Transform API。 Path - activity.class的对应关系是通过LoaderManager来查询的，我们看一下这个类的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public final class LoaderManager { private static final LoaderManager sManager = new LoaderManager(); public static LoaderManager getInstance() { return sManager; } private final Map&lt;String, DelegateLoader&gt; loadersMap = new HashMap&lt;&gt;(); private boolean isInitialized = false; private LoaderManager() { init(); } private void init() { if (isInitialized) { return; } load(); isInitialized = true; } private void load() { } private void loadInto(BaseLoader loader) { String header = loader.getHeader(); obtainLoader(header).mergeOtherLoaders(loader); } private DelegateLoader obtainLoader(String header) { DelegateLoader delegateLoader = loadersMap.get(header); if (delegateLoader == null) { delegateLoader = new DelegateLoader(header); loadersMap.put(header, delegateLoader); } return delegateLoader; } public Class&lt;?&gt; get(String path) { String[] segments = path.split(&quot;/&quot;); final String header = segments[0]; final String tail = segments[1]; return loadersMap.get(header).getTargetClass(tail); }} 我们需要注意其中的一个方法——load，我们看到，这个类在构建方法里调用了init方法，init里又调用了load方法，但是这个load方法却是留白的。这样调用有什么用呢？ 其实这个留白方法是我们为ASM留的一个修改的入口。 1apply plugin: 'i-router-register' 在app.gradle中，使用这个插件，我们的transform就能顺利运行起来发挥作用了。 我们需要查看一下RegisterTransform的代码了： 12345678910public class RegisterTransform extends Transform { @Override public void transform(TransformInvocation transformInvocation) throws TransformException, InterruptedException, IOException { super.transform(transformInvocation); scanner.scan(transformInvocation, (loaderManagerJar, loaderManagerEntryName, loaders) -&gt; { Asm.getInstance().generateCode(loaderManagerJar, loaderManagerEntryName, loaders); }); }} 这里使用了Scanner来扫描TransformInvocation类，Scanner是我们自定义的类，主要作用就是通过包名和类名，查找我们的loader类和LoaderManager所在的jar包。我们查看其scan方法： 123456789for (TransformInput input : transformInvocation.getInputs()) { for (JarInput jarInput : input.getJarInputs()) { // 这里处理第三方类库，引用的module和jar文件 } for (DirectoryInput directoryInput : input.getDirectoryInputs()) { // 这里处理应用了这个plugin的module的相关class文件 }}onScanFinish.onScanFinish(loaderManagerJar, loaderManagerEntryName, loaderClzList); 通过回调，我们将查找到的loader类和LoaderManager所在jar返回给transform，并交由我们的asm工具来处理。 123456789101112131415161718192021222324public class ASM { private static class HackMethodVisitor extends MethodVisitor { private List&lt;String&gt; loaders = null; public HackMethodVisitor(int api, MethodVisitor methodVisitor, List&lt;String&gt; loaders) { super(api, methodVisitor); this.loaders = loaders; } @Override public void visitInsn(int opcode) { for (String loader : loaders) { mv.visitVarInsn(Opcodes.ALOAD, 0); mv.visitTypeInsn(Opcodes.NEW, loader); mv.visitInsn(Opcodes.DUP); mv.visitMethodInsn(Opcodes.INVOKESPECIAL, loader, &quot;&lt;init&gt;&quot;, &quot;()V&quot;, false); mv.visitMethodInsn(Opcodes.INVOKESPECIAL, &quot;com/github/boybeak/irouter/core/LoaderManager&quot;, &quot;loadInto&quot;, &quot;(Lcom/github/boybeak/irouter/core/BaseLoader;)V&quot;, false); } super.visitInsn(opcode); } }} 主要的修改逻辑就在HackMethodVisitor这个类中，注意其中的visitInsn方法，这就是ASM真正发挥作用的地方，这里的逻辑就是为loadInto方法添加加载loader的代码。 以demo中的v2ex为例，修改后的代码load代码如下： 最后一点细节到目前为止，主要的流程已经结束了，接下来是一些细节部分。 LoaderManager在加载loader的时候，会针对path做归并，比如同为app/main和app/user被归并为一组，这样在使用的时候，可以按组做实际载入。 用于跳转的Navigator是有缓存的，用来减少查询次数，因为path - activity.class的对应关系并不是动态变化的，如果缓存中有已经用过的，则清空其intent的参数部分重复利用即可。 对于startActivityForResult的集中调用，可以参考我的另外一个开源项目——Starter中的SAFR项目。这里在FragmentActivity中，通过一个fragment去代理了startActivityForResult的过程，从而拦截了回调结果；类似的，在非FragmentActivity中，通过了一个全透明的代理了此过程，这里学习了Glide通过一个fragment来探测生命周期的方式。 总结通过这样一个自己动手的过程，我们熟悉了的编写APT和gradle plugin的过程，学会了ASM的基本用法。 在这个项目中，学习了很多其他优秀开源项目的经验，比如： 主流程是参考了ARouter，但是去掉了应用启动时候，从codeDir找到apk来解析路由路径的过程； 集中的api式调用，参考了Retrofit的动态代理； 通过Fragment拦截startActivityForResult的结果，参考了Glide向宿主activity添加无UI的Fragment的方式。 因此，多读源码可以开拓思维，当自己想开发自己的工具框架时候，就可以信手拈来。","link":"/2021/03/08/2022-09-17-%E6%89%8B%E6%92%B8%E4%B8%80%E4%B8%AA%E8%B7%AF%E7%94%B1%E6%A1%86%E6%9E%B6IRouter/"},{"title":"AMS启动流程","text":"AMS是ActivityManagerService的简称，看名字，似乎是Activity的manager，实际上，它管理的可不只是Activity。 系统启动流程123456789graph TD; style A fill:#fff style F fill:#5befb9 Z{{Boot ROM}} --&gt; A([Boot Loader]); A --&gt; B(Kernel); B --&gt; C(&quot;init(pid=1)/C++ Framework Native&quot;); C --&gt; D(Zygote/Android Runtime); D --&gt; E(System Server/Java Framework); E --&gt; F(Apps); 面试题：一个应用启动，为什么不从init进程或者SystemServer进程fork，而是从Zygote进程fork。 Zygote作为一个孵化器，可以提前加载一些资源，这样fork时给予Copy-on-Write机制创建的其他进程能够直接利用这些资源，而不用重新加载。比如system_server就可以直接使用Zygote中的JNI函数、共享库、常用的类以及主题资源。 SystemServer相比Zygote多运行了AMS、WMS等服务，这些对于一个应用程序来说是不需要的，另外fork对多线程不友好，仅会将发起调用的线程拷贝到子进程，这可能会导致死锁，而SystemServer中肯定是有很多多线程的。 如何导致死锁的？ 在POSIX标准中，fork行为是这样的：赋值整个用户空间的数据（通常使用copy-on-write的策略，所以可以实现速度很快）以及所有系统对象，然后仅复制当前线程到子进程。这里：所有父进程中别的线程，到了子进程都是突然蒸发掉的。 对于锁来说，从OS看，每个锁都有一个所有者，即最后依次lock它的线程。假设这样一个环境，在fork之前，有一个子线程lock了某个锁，获得了对锁的所有权，fork以后，在子进程中，所有的额外线程都人间蒸发了，而锁却被正常赋值了，在子进程看来，这个锁没有主人，所以没有任何人可以对它解锁，当子进程中的某个线程想lock这个锁时候，不再有任何手段可以解开了，程序发生死锁。 Zygote集成启动123456graph TD; A[&quot;init.cpp - main()&quot;] --&gt; B[解析init.zygote.rc]; B --&gt; C[&quot;启动main类型服务 do_class_start()&quot;]; C --&gt; D[&quot;启动zygote服务 start()&quot;]; D --&gt; E[&quot;创建Zygote进程 fork()&quot;]; E --&gt; |execv|F[&quot;app_main.cpp - main()&quot;]; System Server进程启动123456789graph TD; A[&quot;app_main.cpp - main()&quot;] --&gt; B[&quot;AndroidRuntime.start()&quot;]; B --&gt; C[&quot;startVM()&quot;]; C --&gt; D[&quot;startReg()&quot;]; D --&gt; E[&quot;ZygoteInit.main()&quot;]; E --&gt; F[&quot;registerZygoteSocket()&quot;]; F --&gt; G[&quot;preload&quot;]; G --&gt; H[&quot;startSystemServer&quot;]; H --&gt; I[&quot;runSelectLoop&quot;]; SystemServer.java AMS启动流程ActivityManagerService.java 在SystemServer的startBootstrapServices方法中，开始了AMS的启动。 AMS启动过程中做了哪些事？与adb shell dumpsys相关的一些process服务，比如meminfo、gfxinfo、dbinfo等，具体请参考setSystemProcess方法。 Activity启动流程ActivityStactSupervisor 1234567891011121314151617flowchart LR;A[ActivityStactSupervisor] --&gt; B[mHomeStack];A --&gt; C[mFocusedStack];subgraph ActivityStack[&quot;ActivityStack&quot;] subgraph TaskRecord AR1[ActivityRecord] AR2[ActivityRecord] AR3[ActivityRecord] end subgraph TaskRecord2 AR4[ActivityRecord] AR5[ActivityRecord] AR6[ActivityRecord] endendB --&gt; ActivityStack;C --&gt; ActivityStack; Activity启动简图 面试题：Zygote为什么不采用Binder机制进行IPC通信。 Binder机制中存在Binder线程池，是多线程的，如果Zygote采用Binder的话，就存在了上面说的fork多线程死锁问题了。其实严格来说，Binder机制不一定要多线程，所谓的Binder线程只不过是在循环读取Binder驱动消息而已，只注册一个Binder线程也是可以工作的，比如ServiceManager，实际上Zygote尽管没有采用Binder机制，它也不是单线程的，但它在fork前主动停止了其他线程，fork后重新启动了。 1234567graph TD; A([Launcher]) --&gt; B{&quot;SystemServer - AMS&lt;br&gt;(app是否启动)&quot;}; B --&gt; |否, 请求创建app进程|C[Zygote]; B -.-&gt; |&quot;是, 1. ActivityManager.getService()&quot;|D(App):::app; C --&gt;|fork| D D --&gt;|&quot;2. mgr.attachApplication(mAppThread, startSeq)&quot;| B; classDef app fill:#5befb9 Activity启动细节图 Launcher到AMS阶段 123456789101112sequenceDiagram participant A as Launcher participant B as Activity participant C as Instrumentation participant D as IActivityManager participant E as AMS A -&gt;&gt; B: startActivity B --&gt; B: startActivityForResult B -&gt;&gt; C: execStartActivity C -&gt;&gt; D: startActivity D -&gt;&gt; E: startActivity AMS到ApplicationThread阶段 123456789101112sequenceDiagram participant A as AMS participant B as ActivityStart participant C as ActivityStackSupervisor participant D as ActivityStack participant E as ApplicationThread A -&gt;&gt; A: startActivityStarter A -&gt;&gt; B: startActivityMyWait B -&gt;&gt; B: startActivityLocked B -&gt;&gt; B: startActivity B -&gt;&gt; B: startActivityUnchecked B -&gt;&gt; C: startSpecificActivityLocked ApplicationThread到Activity","link":"/2020/10/21/2022-09-19-AMS%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"title":"ASM库介绍与使用","text":"原文 前面几篇文章介绍了 .class 文件的结构、JVM 如何加载 .class 文件、JVM 中如何执行方法的调用和访问者模式，其实前面几篇文章都是为这篇文章做铺垫的，如果不知道 .class 文件结构、也不知道在 JVM 中 .class 文件中的方法是如何被执行的，这篇文章中的有些部分可能会看不懂，所以推荐先看下前面几篇文章。 这篇文章主要介绍 ASM 库的结构、主要的 API，并且通过两个示例说明如何通过 ASM 修改 .class 文件中的方法和属性。 catalog.png 一. ASM 的结构ASM 库是一款基于 Java 字节码层面的代码分析和修改工具。ASM 可以直接生产二进制的 class 文件，也可以在类被加载入 JVM 之前动态修改类行为。 ASM 库的结构如下所示： asm_arch.png Core：为其他包提供基础的读、写、转化Java字节码和定义的API，并且可以生成Java字节码和实现大部分字节码的转换，在 访问者模式和 ASM 中介绍的几个重要的类就在 Core API 中：ClassReader、ClassVisitor 和 ClassWriter 类. Tree：提供了 Java 字节码在内存中的表现 Commons：提供了一些常用的简化字节码生成、转换的类和适配器 Util：包含一些帮助类和简单的字节码修改类，有利于在开发或者测试中使用 XML：提供一个适配器将XML和SAX-comliant转化成字节码结构，可以允许使用XSLT去定义字节码转化 二. Core API 介绍2.1 ClassVisitor 抽象类如下所示，在 ClassVisitor 中提供了和类结构同名的一些方法，这些方法会对类中相应的部分进行操作，而且是有顺序的：visit [ visitSource ] [ visitOuterClass ] ( visitAnnotation | visitAttribute )* (visitInnerClass | visitField | visitMethod )* visitEnd 123456789101112131415public abstract class ClassVisitor { ...... public void visit(int version, int access, String name, String signature, String superName, String[] interfaces); public void visitSource(String source, String debug); public void visitOuterClass(String owner, String name, String desc); public AnnotationVisitor visitAnnotation(String desc, boolean visible); public AnnotationVisitor visitTypeAnnotation(int typeRef, TypePath typePath, String desc, boolean visible); public void visitAttribute(Attribute attr); public void visitInnerClass(String name, String outerName, String innerName, int access); public FieldVisitor visitField(int access, String name, String desc, String signature, Object value); public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions); public void visitEnd();} void visit(int version, int access, String name, String signature, String superName, String[] interfaces) 该方法是当扫描类时第一个调用的方法，主要用于类声明使用。下面是对方法中各个参数的示意：visit( 类版本 , 修饰符 , 类名 , 泛型信息 , 继承的父类 , 实现的接口) AnnotationVisitor visitAnnotation(String desc, boolean visible) 该方法是当扫描器扫描到类注解声明时进行调用。下面是对方法中各个参数的示意：visitAnnotation(注解类型 , 注解是否可以在 JVM 中可见)。 FieldVisitor visitField(int access, String name, String desc, String signature, Object value) 该方法是当扫描器扫描到类中字段时进行调用。下面是对方法中各个参数的示意：visitField(修饰符 , 字段名 , 字段类型 , 泛型描述 , 默认值) MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) 该方法是当扫描器扫描到类的方法时进行调用。下面是对方法中各个参数的示意：visitMethod(修饰符 , 方法名 , 方法签名 , 泛型信息 , 抛出的异常) void visitEnd() 该方法是当扫描器完成类扫描时才会调用，如果想在类中追加某些方法 2.2 ClassReader 类这个类会将 .class 文件读入到 ClassReader 中的字节数组中，它的 accept 方法接受一个 ClassVisitor 实现类，并按照顺序调用 ClassVisitor 中的方法 2.3 ClassWriter 类ClassWriter 是一个 ClassVisitor 的子类，是和 ClassReader 对应的类，ClassReader 是将 .class 文件读入到一个字节数组中，ClassWriter 是将修改后的类的字节码内容以字节数组的形式输出。 2.4 MethodVisitor &amp; AdviceAdapterMethodVisitor 是一个抽象类，当 ASM 的 ClassReader 读取到 Method 时就转入 MethodVisitor 接口处理。 AdviceAdapter 是 MethodVisitor 的子类，使用 AdviceAdapter 可以更方便的修改方法的字节码。 AdviceAdapter 的方法如下所示： AdviceAdapter.png 其中比较重要的几个方法如下： void visitCode()：表示 ASM 开始扫描这个方法 void onMethodEnter()：进入这个方法 void onMethodExit()：即将从这个方法出去 void onVisitEnd()：表示方法扫码完毕 2.5 FieldVisitor 抽象类FieldVisitor 是一个抽象类，当 ASM 的 ClassReader 读取到 Field 时就转入 FieldVisitor 接口处理。和分析 MethodVisitor 的方法一样，也可以查看源码注释进行学习，这里不再详细介绍 2.6 操作流程 需要创建一个 ClassReader 对象，将 .class 文件的内容读入到一个字节数组中 然后需要一个 ClassWriter 的对象将操作之后的字节码的字节数组回写 需要事件过滤器 ClassVisitor。在调用 ClassVisitor 的某些方法时会产生一个新的 XXXVisitor 对象，当我们需要修改对应的内容时只要实现自己的 XXXVisitor 并返回就可以了 三. 示例3.1 修改类中方法的字节码假如现在我们有一个 HelloWorld 类，如下 123456789101112package com.lijiankun24.asmpractice.demo;public class HelloWorld { public void sayHello() { try { Thread.sleep(2 * 1000); } catch (InterruptedException e) { e.printStackTrace(); } }} 通过 javac HelloWorld.java 和 javap -verbose HelloWorld.class 可以查看到 sayName() 方法的字节码如下所示： 12345678910111213141516171819202122232425public void sayHello(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=1 0: ldc2_w #2 // long 2000l 3: invokestatic #4 // Method java/lang/Thread.sleep:(J)V 6: goto 14 9: astore_1 10: aload_1 11: invokevirtual #6 // Method java/lang/InterruptedException.printStackTrace:()V 14: return Exception table: from to target type 0 6 9 Class java/lang/InterruptedException LineNumberTable: line 5: 0 line 8: 6 line 6: 9 line 7: 10 line 9: 14 StackMapTable: number_of_entries = 2 frame_type = 73 /* same_locals_1_stack_item */ stack = [ class java/lang/InterruptedException ] frame_type = 4 /* same */ 我们通过 ASM 修改 HelloWorld.class 字节码文件，实现统计方法执行时间的功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class CostTime { public static void main(String[] args) { redefinePersonClass(); } private static void redefinePersonClass() { String className = &quot;com.lijiankun24.asmpractice.demo.HelloWorld&quot;; try { InputStream inputStream = new FileInputStream(&quot;/Users/lijiankun/Desktop/HelloWorld.class&quot;); ClassReader reader = new ClassReader(inputStream); // 1. 创建 ClassReader 读入 .class 文件到内存中 ClassWriter writer = new ClassWriter(reader, ClassWriter.COMPUTE_MAXS); // 2. 创建 ClassWriter 对象，将操作之后的字节码的字节数组回写 ClassVisitor change = new ChangeVisitor(writer); // 3. 创建自定义的 ClassVisitor 对象 reader.accept(change, ClassReader.EXPAND_FRAMES); // 4. 将 ClassVisitor 对象传入 ClassReader 中 Class clazz = new MyClassLoader().defineClass(className, writer.toByteArray()); Object personObj = clazz.newInstance(); Method nameMethod = clazz.getDeclaredMethod(&quot;sayHello&quot;, null); nameMethod.invoke(personObj, null); System.out.println(&quot;Success!&quot;); byte[] code = writer.toByteArray(); // 获取修改后的 class 文件对应的字节数组 try { FileOutputStream fos = new FileOutputStream(&quot;/Users/lijiankun/Desktop/HelloWorld2.class&quot;); // 将二进制流写到本地磁盘上 fos.write(code); fos.close(); } catch (IOException e) { e.printStackTrace(); } } catch (Exception e) { e.printStackTrace(); System.out.println(&quot;Failure!&quot;); } } static class ChangeVisitor extends ClassVisitor { ChangeVisitor(ClassVisitor classVisitor) { super(Opcodes.ASM5, classVisitor); } @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) { MethodVisitor methodVisitor = super.visitMethod(access, name, desc, signature, exceptions); if (name.equals(&quot;&lt;init&gt;&quot;)) { return methodVisitor; } return new ChangeAdapter(Opcodes.ASM4, methodVisitor, access, name, desc); } } static class ChangeAdapter extends AdviceAdapter { private int startTimeId = -1; private String methodName = null; ChangeAdapter(int api, MethodVisitor mv, int access, String name, String desc) { super(api, mv, access, name, desc); methodName = name; } @Override protected void onMethodEnter() { super.onMethodEnter(); startTimeId = newLocal(Type.LONG_TYPE); mv.visitMethodInsn(INVOKESTATIC, &quot;java/lang/System&quot;, &quot;currentTimeMillis&quot;, &quot;()J&quot;, false); mv.visitIntInsn(LSTORE, startTimeId); } @Override protected void onMethodExit(int opcode) { super.onMethodExit(opcode); int durationId = newLocal(Type.LONG_TYPE); mv.visitMethodInsn(INVOKESTATIC, &quot;java/lang/System&quot;, &quot;currentTimeMillis&quot;, &quot;()J&quot;, false); mv.visitVarInsn(LLOAD, startTimeId); mv.visitInsn(LSUB); mv.visitVarInsn(LSTORE, durationId); mv.visitFieldInsn(GETSTATIC, &quot;java/lang/System&quot;, &quot;out&quot;, &quot;Ljava/io/PrintStream;&quot;); mv.visitTypeInsn(NEW, &quot;java/lang/StringBuilder&quot;); mv.visitInsn(DUP); mv.visitMethodInsn(INVOKESPECIAL, &quot;java/lang/StringBuilder&quot;, &quot;&lt;init&gt;&quot;, &quot;()V&quot;, false); mv.visitLdcInsn(&quot;The cost time of &quot; + methodName + &quot; is &quot;); mv.visitMethodInsn(INVOKEVIRTUAL, &quot;java/lang/StringBuilder&quot;, &quot;append&quot;, &quot;(Ljava/lang/String;)Ljava/lang/StringBuilder;&quot;, false); mv.visitVarInsn(LLOAD, durationId); mv.visitMethodInsn(INVOKEVIRTUAL, &quot;java/lang/StringBuilder&quot;, &quot;append&quot;, &quot;(J)Ljava/lang/StringBuilder;&quot;, false); mv.visitMethodInsn(INVOKEVIRTUAL, &quot;java/lang/StringBuilder&quot;, &quot;toString&quot;, &quot;()Ljava/lang/String;&quot;, false); mv.visitMethodInsn(INVOKEVIRTUAL, &quot;java/io/PrintStream&quot;, &quot;println&quot;, &quot;(Ljava/lang/String;)V&quot;, false); } }} 执行结果如下图所示 Class.png 反编译 HelloWorld2.class 文件的内容如下所示 Class1.png 3.2 修改类中属性的字节码这一节中我们将展示一下如何使用 Core API 对类中的属性进行操作。 假如说，现在有一个 Person.java 类如下所示： 1234public class Person { public String name; public int sex;} 我们想为这个类，添加一个 ‘public int age’ 的属性该怎么添加呢？我们会面对两个问题： 该调用 ASM 的哪个 API 添加属性呢？ 在何时写添加属性的代码？ 接下来，我们就一一解决上面的两个问题？ 3.2.1 添加属性的 API按照我们分析的上述的 2.6 操作流程叙述，需要以下三个步骤： 需要创建一个 ClassReader 对象，将 .class 文件的内容读入到一个字节数组中 然后需要一个 ClassWriter 的对象将操作之后的字节码的字节数组回写 需要创建一个事件过滤器 ClassVisitor。事件过滤器中的某些方法可以产生一个新的XXXVisitor对象，当我们需要修改对应的内容时只要实现自己的XXXVisitor并返回就可以了 在上面三个步骤中，可以操作的就是 ClassVisitor 了。ClassVisitor 接口提供了和类结构同名的一些方法，这些方法可以对相应的类结构进行操作。 在使用 ClassVisitor 添加类属性的时候，只需要添加一句话就可以了： 1classVisitor.visitField(Opcodes.ACC_PUBLIC, &quot;age&quot;, Type.getDescriptor(int.class), null, null); visitField.png 3.2.2 添加属性的时机我们先暂且在 ClassVisitor 的 visitEnd() 方法中写入上面的代码，如下所示 1234567891011public class Transform extends ClassVisitor { public Transform(ClassVisitor cv) { super(cv); } @Override public void visitEnd() { cv.visitField(Opcodes.ACC_PUBLIC, &quot;age&quot;, Type.getDescriptor(int.class), null, null); } } 我们写如下的测试类，测试一下 12345678910111213141516171819202122232425262728public class FieldPractice { public static void main(String[] args) { addAgeField(); } private static void addAgeField() { try { InputStream inputStream = new FileInputStream(&quot;/Users/lijiankun/Desktop/Person.class&quot;); ClassReader reader = new ClassReader(inputStream); ClassWriter writer = new ClassWriter(ClassWriter.COMPUTE_MAXS); ClassVisitor visitor = new Transform(writer); reader.accept(visitor, ClassReader.SKIP_DEBUG); byte[] classFile = writer.toByteArray(); MyClassLoader classLoader = new MyClassLoader(); Class clazz = classLoader.defineClass(&quot;Person&quot;, classFile); Object obj = clazz.newInstance(); System.out.println(clazz.getDeclaredField(&quot;name&quot;).get(obj)); //----(1) System.out.println(clazz.getDeclaredField(&quot;age&quot;).get(obj)); //----(2) } catch (Exception e) { e.printStackTrace(); } }} 其输出入下所示： visitFieldResult.png 那如果我们尝试在 ClassVisitor#visitField() 方法中添加属性可以吗？我们可以修改 Transform 测试一下： 123456789101112public class Transform extends ClassVisitor { Transform(ClassVisitor classVisitor) { super(Opcodes.ASM5, classVisitor); } @Override public FieldVisitor visitField(int access, String name, String desc, String signature, Object value) { cv.visitField(Opcodes.ACC_PUBLIC, &quot;age&quot;, Type.getDescriptor(int.class), null, null); return super.visitField(access, name, desc, signature, value); }} 还是使用上面的测试代码测试一下，会有如下的测试结果 visitFieldError.png 在 Person 类中有重复的属性，为什么会报这个错误呢？ 分析 ClassVisitor#visitField() 方法可得知，只要访问类中的一个属性，visitField() 方法就会被调用一次，在 Person 类中有两个属性，所以 visitField() 方法就会被调用两次，也就添加了两次 ‘public int age’ 属性，就报了上述的错误，而 visitEnd() 方法只有在最后才会被调用且只调用一次，所以在 visitEnd() 方法中是添加属性的最佳时机 3.3 ASMifier可能有人会问，我刚开始学，上面例子中那些 ASM 的代码我还不会写，怎么办呢？ASM 官方为我们提供了 ASMifier，可以帮助我们生成这些晦涩难懂的 ASM 代码。 比如，我想通过 ASM 实现统计一个方法的执行时间，该怎么做呢？一般会有如下的代码： 1234567891011package com.lijiankun24.classpractice;public class Demo { public void costTime() { long startTime = System.currentTimeMillis(); // ...... long duration = System.currentTimeMillis() - startTime; System.out.println(&quot;The cost time of this method is &quot; + duration + &quot; ms&quot;); }} 那上面这段代码对应的 ASM 代码是什么呢？我们可以通过以下两个步骤，使用 ASMifier 自动生成： 通过 javac 编译该 Demo.java 文件生成对应的 Demo.class 文件，如下所示 1javac Demo.java 通过 ASMifier 自动生成对应的 ASM 代码。首先需要在ASM官网 下载 asm-all.jar 库，我下载的是最新的 asm-all-5.2.jar，然后使用如下命令，即可生成 1java -classpath asm-all-5.2.jar org.objectweb.asm.util.ASMifier Demo.class 截图如下： DemoDump.png 深入字节码 – 玩转 ASM-Bytecode 原 荐 美团热更方案ASM实践 43人点赞 Java 相关 作者：lijiankun24链接：https://www.jianshu.com/p/905be2a9a700来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","link":"/2020/11/23/2022-09-19-ASM/"},{"title":"Activity启动流程","text":"原文参考：Activity 启动流程分析(Android10) 12345678graph TD;A(启动Activity) --&gt; B[通过Binder调用AMS的startActivity方法] --&gt; C[通过Intent获取到目标Activity] --&gt; D{目标Activity是否启动} --&gt; |是|E[通过Instrumentation创建Activity] --&gt; F[回调Activity#attach] --&gt; G[回调Activity#onCreate] --&gt; H[准备显示Activity] --&gt; I[Activity#onResume];D --&gt; |否|J[通过Zygote进程fork一个App进程]:::zygote --&gt; K[创建Application并回调Application#onCreate]:::zygote --&gt; L[启动ActivityThread主线程消息队列]:::zygote --&gt; E;F --&gt; M[创建Window对象并设置Window.Callback接收事件]:::wms;G --&gt; N[Activity#setContentView] --&gt; O[Window#setContentView]:::wms;H --&gt; P[Window#addView]:::wms;classDef wms fill:#aaffffclassDef zygote fill:#ffaa99 途中浅蓝色部分为WMS关联部分，橙色部分为目标App未启动情况下的流程。 Intent 解析到 Activity调用 startActivity 之后，经过几步辗转最终会调用到 AMS 中，而 AMS 又会调用 ActivityStarter 来启动 Activity。解析 Intent 的任务将由PackageManagerService#resolveIntent方法来处理。Intent 匹配规则太负责了，我本意是想学习启动流程，所以就没深入进去看代码，就这样吧。","link":"/2020/10/22/2022-09-19-Activity%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"title":"Apk瘦身术","text":"Apk瘦身主要从三方面入手：资源文件、源代码和第三方类库。 一、资源文件1.1 删除无用资源文件1.1.1 Lint工具菜单 -&gt; Analyze -&gt; Run Inspection by Name，然后输入Unused resources便可以执行查找无用资源文件。自己根据需要进行删除。 1.1.2 shrinkResources123456789101112buildTypes { release { // 不显示Log buildConfigField &quot;boolean&quot;, &quot;LOG_DEBUG&quot;, &quot;false&quot; //混淆 minifyEnabled true // 移除无用的resource文件 shrinkResources true proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' signingConfig signingConfigs.release }} 使用shrinkResources的前提是，打开混淆minifyEnabled，建议只在release版本开启，不然会使得编译速度变慢。 1.2 图标类资源图片矢量化对于图标类资源，可以选择用vector-drawable来代替，通过AndroidStudio自带的转换工具可以将svg文件转换为vector-drawable文件。 具体操作为，在drawable相关文件夹上右键 -&gt; New -&gt; Vector Assert。 你也可以进行批量转换：工具地址 1.3 非图标类资源图片适当压缩与格式选择1.3.1 使用tinypng有损压缩png图片通过Tinypng官网上传压缩再下载，在保持alpha通道的情况下对png图片的压缩可达到1/3以内，且肉眼基本看不出差别。 1.3.2 使用jpg格式对于非透明的大图，jpg会比png的大小和内存都更有优势，虽然不是绝对的，但是通常会减少到一半不止。 1.3.3 使用webp格式webp格式支持透明度，压缩比比jpg高，但是显示效果却不输于jpg。缺点是在Android端的原生支持不好，从Android4.0+开始原生支持，但是不支持透明度，从Android4.3+开始支持带有透明度的webp。如果不需要兼容到这个版本，可以直接使用。 在Android studio中，在图片资源上右键可以转换为webp。详细参见创建 WebP 图片。 1.3.4 适当的压缩和尺寸无论以上哪种格式图片，都可以通过选择合适的尺寸和适当的提高压缩率的方式，来进一步减少文件大小，进而减小apk文件的体积。 1.3.5 帧动画尽可能使用lottieLottie是Aribnb开源的动画库，通过json文件来进行展示动画，动画文件可以通过Adobe AE来制作。 1.4 有限国际化12345android { defaultConfig { resConfigs &quot;zh&quot; }} 1.5 第三方库中大尺寸的无用资源同名替换如果在第三方类库中，存在用不到的图片资源文件，可以通过1x1像素的同名图片进行替换。 1.6 使用AndResGuardAndResGuard，在gradle文件中就可以直接使用，非常方便。 二、源代码2.1 开启混淆这是基本操作了，无需多言。 2.2 手动修改开源代码将开源代码中我们不需要的类或者方法等删除掉，但是这需要对开源代码非常了解，而且确保版本兼容性，将来开源库升级或者随着我们产品需求变更对开源库的要求也改变了，都会影响对开源库的修改，不建议使用。 三、第三方类库3.1 动态库3.1.1 删除非必要平台so库1234ndk { //设置支持的so库架构 abiFilters &quot;armeabi-v7a&quot;} 基本上，对于手机来说，支持armeabi-v7a就足够了。 3.1.2 动态加载so库如果不是一启动应用就需要初始化的so库，完全可以在需要的时候再下载这个so文件，再通过以下代码进行加载。 123static { System.loadLibrary(&quot;path/to/lib.so&quot;);} 其他插件化将不需要在启动就加载的功能模块，通过插件化，在用户使用的时候再从服务器加载。 删除class文件的debug items不建议使用，这种做法，事倍功半。","link":"/2020/12/13/2022-09-19-Apk%E7%98%A6%E8%BA%AB%E6%9C%AF/"},{"title":"App保活术","text":"为什么要保活？ 因为Android的Low memory killer机制，在系统内存不足的情况下，系统开始根据自身的一套进程回收机制结束一些进程，以便腾出内存给需要的进程。 如何判断内存不足？ 判断的阈值在不同手机上是不一样的，一旦低于该阈值，系统就会杀死对应优先级的进程。 在adb shell下，通过如下命令来查看阈值： 1cat /sys/module/lowmemorykiller/parameters/minfree 注意: 这可能需要root手机。 返回的结果如下示例： 118432, 23040, 27648, 32256, 55296, 80640 其单位为4kb，也就是内存1页大小。 该值表示的是剩余内存大小，优先级为从高到低，比如当内存小于18432*4kb时，杀死对应的优先级的进程。 123456789101112131415graph TD;style 关键优先级 fill:#5befb9style 高级优先级 fill:#6998c6style 低优先级 fill:#d38a49subgraph 关键优先级A(前台进程)endA(前台进程) --&gt; B(可见进程);subgraph 高级优先级B --&gt; C(服务进程);endC --&gt; D(后台进程);subgraph 低优先级D --&gt; E(空进程);end 优先级从高到低依次是，前台进程、可见进程、服务进程、后台进程、空进程。 阈值有6个数，而进程有5种优先级，是如何对应呢？ 实际上，第5个数是ContentProvider的阈值，其他的5个数与线程优先级对应。 如何判断线程的优先级？ 1cat /proc/&lt;pid&gt;/oom_adj 其中的应替换为对应的进程ID，从logcat中可以查看对应的pid。 取值范围绿色代表比较安全，红色代表比较容易被杀死，白色代表为系统进程。 1像素保活监听锁屏广播，当屏幕关闭，偷偷创建一个1像素的activity，当屏幕开启，关闭掉这个1像素activity。 关键代码如下: ScreenObserverService.java 12345//创建后台service，监听屏幕事件。IntentFilter filter = new IntentFilter(Intent.ACTION_SCREEN_ON);filter.addAction(Intent.ACTION_SCREEN_OFF);registerReceiver(theReceiver, filter);//别忘了在service结束时候，注销掉这个receiver。 OnePixelActivity.java 12345678Window window = getWindow();window.setGravity(Gravity.START | Gravity.TOP);WindowManager.LayoutParams params = window.getAttributes();params.width = 1;params.height = 1;params.x = 0;params.y = 0;window.setAttributes(params); 别忘了在Manifest文件中，为这个activity设置一个透明主题。 12345&lt;activity android:name=&quot;.onepixel.OnePixelActivity&quot; android:excludeFromRecents=&quot;true&quot; android:taskAffinity=&quot;com.github.boybeak.livestock.onepixel&quot; android:theme=&quot;@style/OnePixelTheme&quot; /&gt; android:excludeFromRecents=”true” //不会出现在任务管理器中 android:taskAffinity=”xxxx” //在新的任务栈中创建，不会将其他界面带到前台，配合启动OnePixelActivity时候的Intent.FLAG_ACTIVITY_NEW_TASK使用. 注意：经过实验，这个方案在真机上已经大概率失效了。 收到锁屏广播会有1~3秒延迟； 当OnePixelActivity设置了excludeFromRecents=&quot;true&quot;后，在锁屏下是启动不起来的； 屏幕重新点亮的广播会有十几秒延迟。 我在一架5T上实验的，其他机型不保证。 前台服务这一方案就是利用一个前台服务，配合Notification，来达到保活。弊端就是，当你的应用没有Notification需求的时候，对于一些敏感用户来说，这就容易引起方案。如下图。 所以当你的应用是音乐类播放器，可以将这个通知作为音乐播放控制来使用，但是如果你的应用没有这样的需求，就会引起敏感用户注意，反而有可能被手动杀死甚至卸载。在Android8.0以前，可以通过如下方案消除这个无意义的敏感通知。 12345678910111213141516public class OuterService extends Service { @Override public void onCreate() { startForground(1, new Notification()); startService(new Intent(this, InnerService.class)); } public static class InnerService extends Service { @Override public void onCreate() { startForground(1, new Notification()); stopSelf(); } } } 这是利用系统漏洞来消除的这个通知，但是在Android8.0以后，同一个ID下，不允许重复创建前台服务，所以使用该方法需要判断版本。 系统广播拉活系统拉活 比如开机广播，电量变化，信号变化，网络变化等。但是在Android7.0后增加了限制，在Android8.0后限制更加严格。所以，这类保活方案已经不可靠了。 Oreo: https://developer.android.google.cn/about/versions/oreo/background.html#Broadcasts Pie: https://developer.android.google.cn/guide/components/broadcast-exceptions.html 用户拉活 大厂的多个APP之间可以互相之间拉活。 Service系统机制拉活根据Service的onStartCommand方法的返回值，系统会执行不同的拉活方案。一般按照默认返回START_STICKY就可以。 优点是使用成本低，缺点是不稳定。 账户同步拉活优点：非常稳定。 JobScheduler拉活双进程守护WorkManager厂商推送播放无声音乐白名单Github示例代码Livestock 参考文章解读Android进程优先级ADJ算法 创建自定义账号类型","link":"/2020/10/21/2022-09-19-App%E4%BF%9D%E6%B4%BB%E6%9C%AF/"},{"title":"Binder机制分析","text":"参考文章：写给 Android 应用工程师的 Binder 原理剖析 实验代码：TheBinder Binder机制可以说是Android的核心。提到Binder，可能会让你想到，通过bindService与Service进行通信(也可能是跨进程的通信)，实际上，Android中Binder的使用可以说是无处不在的，包括Activity跳转，详情可以参考AMS启动流程。 为什么要用Binder?在Linux系统中，跨进程通信(IPC)方式有很多种，包括Socket、管道、共享内存等。可以Android为何最后选择Binder作为核心的跨进程通信的手段呢？ 这需要从两方面去分析——性能和安全性。 1. 性能首先说说性能上的优势。Socket 作为一款通用接口，其传输效率低，开销大，主要用在跨网络的进程间通信和本机上进程间的低速通信。消息队列和管道采用存储-转发方式，即数据先从发送方缓存区拷贝到内核开辟的缓存区中，然后再从内核缓存区拷贝到接收方缓存区，至少有两次拷贝过程。共享内存虽然无需拷贝，但控制复杂，难以使用。Binder 只需要一次数据拷贝，性能上仅次于共享内存。 2. 安全性另一方面就是安全性。Android 作为一个开放性的平台，市场上有各类海量的应用供用户选择安装，因此安全性对于 Android 平台而言极其重要。作为用户当然不希望我们下载的 APP 偷偷读取我的通信录，上传我的隐私数据，后台偷跑流量、消耗手机电量。传统的 IPC 没有任何安全措施，完全依赖上层协议来确保。首先传统的 IPC 接收方无法获得对方可靠的进程用户ID/进程ID（UID/PID），从而无法鉴别对方身份。Android 为每个安装好的 APP 分配了自己的 UID，故而进程的 UID 是鉴别进程身份的重要标志。传统的 IPC 只能由用户在数据包中填入 UID/PID，但这样不可靠，容易被恶意程序利用。可靠的身份标识只有由 IPC 机制在内核中添加。其次传统的 IPC 访问接入点是开放的，只要知道这些接入点的程序都可以和对端建立连接，不管怎样都无法阻止恶意程序通过猜测接收方地址获得连接。同时 Binder 既支持实名 Binder，又支持匿名 Binder，安全性高。 基于上述原因，Android 需要建立一套新的 IPC 机制来满足系统对稳定性、传输性能和安全性方面的要求，这就是 Binder。 用一张表格来总结与对比各种IPC方式。 IPC方式 性能(内存拷贝次数) 安全性 Binder 1 通过UID/PID来保证 共享内存 0 操作非常复杂，难以保证 Socket/管道/消息队列 2 依靠上层协议做身份识别，非常不可靠 传统IPC是什么样的？先要了解一些基本概念——进程隔离、用户空间、内核空间、用户态、内核态。 上图展示了 Liunx 中跨进程通信涉及到的一些基本概念： 进程隔离 进程空间划分：用户空间(User Space)/内核空间(Kernel Space) 系统调用：用户态/内核态 进程隔离顾名思义，就是进程之间内存是不共享的。进程间要进行数据交换，就得采用**进程间通信(IPC)**机制。 进程空间划分：用户空间(User Space)/内核空间(Kernel Space)现在操作系统都是采用的虚拟存储器，对于 32 位系统而言，它的寻址空间（虚拟存储空间）就是 2 的 32 次方，也就是 4GB。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也可以访问底层硬件设备的权限。为了保护用户进程不能直接操作内核，保证内核的安全，操作系统从逻辑上将虚拟空间划分为用户空间（User Space）和内核空间（Kernel Space）。针对 Linux 操作系统而言，将最高的 1GB 字节供内核使用，称为内核空间；较低的 3GB 字节供各进程使用，称为用户空间。 简单的说就是，内核空间（Kernel）是系统内核运行的空间，用户空间（User Space）是用户程序运行的空间。为了保证安全性，它们之间是隔离的。 系统调用：用户态/内核态虽然从逻辑上进行了用户空间和内核空间的划分，但不可避免的用户空间需要访问内核资源，比如文件操作、访问网络等等。为了突破隔离限制，就需要借助系统调用来实现。系统调用是用户空间访问内核空间的唯一方式，保证了所有的资源访问都是在内核的控制下进行的，避免了用户程序对系统资源的越权访问，提升了系统安全性和稳定性。 Linux 使用两级保护机制：0 级供系统内核使用，3 级供用户程序使用。 当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。 当进程在执行用户自己的代码的时候，我们称其处于用户运行态（用户态）。此时处理器在特权级最低的（3级）用户代码中运行。 系统调用主要通过如下两个函数来实现： 12copy_from_user() //将数据从用户空间拷贝到内核空间copy_to_user() //将数据从内核空间拷贝到用户空间 Linux下传统IPC通信 数据发送进程：开辟用户空间缓存区 -&gt; 系统调用，进入内核态 -&gt; 开辟内核空间缓存区 -&gt;通过copy_from_user()将数据拷贝到内核空间缓存区。 数据接收进程：开辟用户空间缓存区 -&gt; 调用copytouser()将数据从内核缓存区拷贝到用户空间缓存区。 这样，两个进程就完成了依次进程间通信。 这种传统的 IPC 通信方式有两个问题： 性能低下，一次数据传递需要经历：内存缓存区 –&gt; 内核缓存区 –&gt; 内存缓存区，需要 2 次数据拷贝； 接收数据的缓存区由数据接收进程提供，但是接收进程并不知道需要多大的空间来存放将要传递过来的数据，因此只能开辟尽可能大的内存空间或者先调用 API 接收消息头来获取消息体的大小，这两种做法不是浪费空间就是浪费时间。 Binder跨进程通信原理正如前面所说，跨进程通信是需要内核空间做支持的。传统的 IPC 机制如管道、Socket 都是内核的一部分，因此通过内核支持来实现进程间通信自然是没问题的。但是 Binder 并不是 Linux 系统内核的一部分，那怎么办呢？这就得益于 Linux 的动态内核可加载模块（Loadable Kernel Module，LKM）的机制；模块是具有独立功能的程序，它可以被单独编译，但是不能独立运行。它在运行时被链接到内核作为内核的一部分运行。这样，Android 系统就可以通过动态添加一个内核模块运行在内核空间，用户进程之间通过这个内核模块作为桥梁来实现通信。 在 Android 系统中，这个运行在内核空间，负责各个用户进程通过 Binder 实现通信的内核模块就叫 Binder 驱动（Binder Dirver）。 那么在 Android 系统中用户进程之间是如何通过这个内核模块（Binder 驱动）来实现通信的呢？难道是和前面说的传统 IPC 机制一样，先将数据从发送方进程拷贝到内核缓存区，然后再将数据从内核缓存区拷贝到接收方进程，通过两次拷贝来实现吗？显然不是，否则也不会有开篇所说的 Binder 在性能方面的优势了。 这就不得不通道 Linux 下的另一个概念：内存映射。 Binder IPC 机制中涉及到的内存映射通过 mmap() 来实现，mmap() 是操作系统中一种内存映射的方法。内存映射简单的讲就是将用户空间的一块内存区域映射到内核空间。映射关系建立后，用户对这块内存区域的修改可以直接反应到内核空间；反之内核空间对这段区域的修改也能直接反应到用户空间。 内存映射能减少数据拷贝次数，实现用户空间和内核空间的高效互动。两个空间各自的修改能直接反映在映射的内存区域，从而被对方空间及时感知。也正因为如此，内存映射能够提供对进程间通信的支持。 Binder IPC实现原理Binder IPC 正是基于内存映射（mmap）来实现的，但是 mmap() 通常是用在有物理介质的文件系统上的。 比如进程中的用户区域是不能直接和物理设备打交道的，如果想要把磁盘上的数据读取到进程的用户区域，需要两次拷贝（磁盘–&gt;内核空间–&gt;用户空间）；通常在这种场景下 mmap() 就能发挥作用，通过在物理介质和用户空间之间建立映射，减少数据的拷贝次数，用内存读写取代I/O读写，提高文件读取效率。 而 Binder 并不存在物理介质，因此 Binder 驱动使用 mmap() 并不是为了在物理介质和用户空间之间建立映射，而是用来在内核空间创建数据接收的缓存空间。 一次完整的 Binder IPC 通信过程通常是这样： 首先 Binder 驱动在内核空间创建一个数据接收缓存区； 接着在内核空间开辟一块内核缓存区，建立内核缓存区和内核中数据接收缓存区之间的映射关系，以及内核中数据接收缓存区和接收进程用户空间地址的映射关系； 发送方进程通过系统调用 copyfromuser() 将数据 copy 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在内存映射，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信。 如下图： 注意图中两个红色虚线。我们从图中可以看到，内核空间开辟了两个缓存区——内核缓存区和数据接收缓存区，这两个缓存区之间存在内存映射，然后数据接收缓存区与数据接收进程的用户空间缓存区同样有内存映射。当数据发送进程通过copy_from_user()将数据拷贝到内核缓存区的时候，存在映射关系的数据接收进程用户空间缓存区也就收到了数据。 Binder通信模型跨进程通讯至少包含两个进程，我们将数据发送进程称为Client，把数据接收方称为Server。 Client/Server/ServiceManager/驱动前面我们介绍过，Binder 是基于 C/S 架构的。由一系列的组件组成，包括 Client、Server、ServiceManager、Binder 驱动。其中 Client、Server、Service Manager 运行在用户空间，Binder 驱动运行在内核空间。其中 Service Manager 和 Binder 驱动由系统提供，而 Client、Server 由应用程序来实现。Client、Server 和 ServiceManager 均是通过系统调用 open、mmap 和 ioctl 来访问设备文件 /dev/binder，从而实现与 Binder 驱动的交互来间接的实现跨进程通信。 Android Binder 设计与实现一文中对 Client、Server、ServiceManager、Binder 驱动有很详细的描述，以下是部分摘录： Binder 驱动Binder 驱动就如同路由器一样，是整个通信的核心；驱动负责进程之间 Binder 通信的建立，Binder 在进程之间的传递，Binder 引用计数管理，数据包在进程之间的传递和交互等一系列底层支持。 ServiceManager 与实名 BinderServiceManager 和 DNS 类似，作用是将字符形式的 Binder 名字转化成 Client 中对该 Binder 的引用，使得 Client 能够通过 Binder 的名字获得对 Binder 实体的引用。注册了名字的 Binder 叫实名 Binder，就像网站一样除了除了有 IP 地址意外还有自己的网址。Server 创建了 Binder，并为它起一个字符形式，可读易记得名字，将这个 Binder 实体连同名字一起以数据包的形式通过 Binder 驱动发送给 ServiceManager ，通知 ServiceManager 注册一个名为“张三”的 Binder，它位于某个 Server 中。驱动为这个穿越进程边界的 Binder 创建位于内核中的实体节点以及 ServiceManager 对实体的引用，将名字以及新建的引用打包传给 ServiceManager。ServiceManger 收到数据后从中取出名字和引用填入查找表。 细心的读者可能会发现，ServierManager 是一个进程，Server 是另一个进程，Server 向 ServiceManager 中注册 Binder 必然涉及到进程间通信。当前实现进程间通信又要用到进程间通信，这就好像蛋可以孵出鸡的前提却是要先找只鸡下蛋！Binder 的实现比较巧妙，就是预先创造一只鸡来下蛋。ServiceManager 和其他进程同样采用 Bidner 通信，ServiceManager 是 Server 端，有自己的 Binder 实体，其他进程都是 Client，需要通过这个 Binder 的引用来实现 Binder 的注册，查询和获取。ServiceManager 提供的 Binder 比较特殊，它没有名字也不需要注册。当一个进程使用 BINDERSETCONTEXT_MGR 命令将自己注册成 ServiceManager 时 Binder 驱动会自动为它创建 Binder 实体（这就是那只预先造好的那只鸡）。其次这个 Binder 实体的引用在所有 Client 中都固定为 0 而无需通过其它手段获得。也就是说，一个 Server 想要向 ServiceManager 注册自己的 Binder 就必须通过这个 0 号引用和 ServiceManager 的 Binder 通信。类比互联网，0 号引用就好比是域名服务器的地址，你必须预先动态或者手工配置好。要注意的是，这里说的 Client 是相对于 ServiceManager 而言的，一个进程或者应用程序可能是提供服务的 Server，但对于 ServiceManager 来说它仍然是个 Client。 Client 获得实名 Binder 的引用Server 向 ServiceManager 中注册了 Binder 以后， Client 就能通过名字获得 Binder 的引用了。Client 也利用保留的 0 号引用向 ServiceManager 请求访问某个 Binder: 我申请访问名字叫张三的 Binder 引用。ServiceManager 收到这个请求后从请求数据包中取出 Binder 名称，在查找表里找到对应的条目，取出对应的 Binder 引用作为回复发送给发起请求的 Client。从面向对象的角度看，Server 中的 Binder 实体现在有两个引用：一个位于 ServiceManager 中，一个位于发起请求的 Client 中。如果接下来有更多的 Client 请求该 Binder，系统中就会有更多的引用指向该 Binder ，就像 Java 中一个对象有多个引用一样。 Binder通信过程至此，我们大致能总结出 Binder 通信过程： 首先，一个进程使用 BINDERSETCONTEXT_MGR 命令通过 Binder 驱动将自己注册成为 ServiceManager； Server 通过驱动向 ServiceManager 中注册 Binder（Server 中的 Binder 实体），表明可以对外提供服务。驱动为这个 Binder 创建位于内核中的实体节点以及 ServiceManager 对实体的引用，将名字以及新建的引用打包传给 ServiceManager，ServiceManger 将其填入查找表。 Client 通过名字，在 Binder 驱动的帮助下从 ServiceManager 中获取到对 Binder 实体的引用，通过这个引用就能实现和 Server 进程的通信。 我们看到整个通信过程都需要 Binder 驱动的接入。下图能更加直观的展现整个通信过程(为了进一步抽象通信过程以及呈现上的方便，下图我们忽略了 Binder 实体及其引用的概念)： Binder 通信中的代理模式我们已经解释清楚 Client、Server 借助 Binder 驱动完成跨进程通信的实现机制了，但是还有个问题会让我们困惑。A 进程想要 B 进程中某个对象（object）是如何实现的呢？毕竟它们分属不同的进程，A 进程 没法直接使用 B 进程中的 object。 前面我们介绍过跨进程通信的过程都有 Binder 驱动的参与，因此在数据流经 Binder 驱动的时候驱动会对数据做一层转换。当 A 进程想要获取 B 进程中的 object 时，驱动并不会真的把 object 返回给 A，而是返回了一个跟 object 看起来一模一样的代理对象 objectProxy，这个 objectProxy 具有和 object 一摸一样的方法，但是这些方法并没有 B 进程中 object 对象那些方法的能力，这些方法只需要把把请求参数交给驱动即可。对于 A 进程来说和直接调用 object 中的方法是一样的。 当 Binder 驱动接收到 A 进程的消息后，发现这是个 objectProxy 就去查询自己维护的表单，一查发现这是 B 进程 object 的代理对象。于是就会去通知 B 进程调用 object 的方法，并要求 B 进程把返回结果发给自己。当驱动拿到 B 进程的返回结果后就会转发给 A 进程，一次通信就完成了。 Binder的完整定义现在我们可以对 Binder 做个更加全面的定义了： 从进程间通信的角度看，Binder 是一种进程间通信的机制； 从 Server 进程的角度看，Binder 指的是 Server 中的 Binder 实体对象； 从 Client 进程的角度看，Binder 指的是对 Binder 代理对象，是 Binder 实体对象的一个远程代理 从传输过程的角度看，Binder 是一个可以跨进程传输的对象；Binder 驱动会对这个跨越进程边界的对象对一点点特殊处理，自动完成代理对象和本地对象之间的转换。 实现Binder跨进程通信一般Android上，使用**AIDL(Android Interface Definition Language)**来实现跨进程通信协议。AIDL主要是对接口进行描述的，包括定义Server为Client提供那些操作服务。通过AIDL文件，Android Studio在编译时候，会自动产生接口类以及代理类。 除了通过AIDL的方式，我们还可以自己手动编写接口类和代理类。 代码请参考TheBinder，这里展示了两种方式实现Binder IPC。 代码中涉及到了一些Java类。 IBinder : IBinder 是一个接口，代表了一种跨进程通信的能力。只要实现了这个借口，这个对象就能跨进程传输。 IInterface : IInterface 代表的就是 Server 进程对象具备什么样的能力（能提供哪些方法，其实对应的就是 AIDL 文件中定义的接口） Binder : Java 层的 Binder 类，代表的其实就是 Binder 本地对象。BinderProxy 类是 Binder 类的一个内部类，它代表远程进程的 Binder 对象的本地代理；这两个类都继承自 IBinder, 因而都具有跨进程传输的能力；实际上，在跨越进程的时候，Binder 驱动会自动完成这两个对象的转换。 Stub : AIDL 的时候，编译工具会给我们生成一个名为 Stub 的静态内部类；这个类继承了 Binder, 说明它是一个 Binder 本地对象，它实现了 IInterface 接口，表明它具有 Server 承诺给 Client 的能力；Stub 是一个抽象类，具体的 IInterface 的相关实现需要开发者自己实现。 自己实现代码请参考TheBinder 代码中有两个module: withAIDL和noAIDL，分别演示了使用AIDL的方式和不使用ADIL的方式进行Binder IPC。 NoAIDL相比WithAIDL有一个优点，就是可以在对应的IInterface文件中，添加一些自定义的代码，比如添加log代码；由于AIDL的方式是自动生成的代码，所以这些自定义代码是没法添加到对应的IInterface文件中。 我们重点关注noAIDL 12345678910111213//INoAIDL.ktinterface INoAIDL : IInterface { fun sayHi(name: String) fun showObjN(objN: ObjN): ObjN? companion object { private val TAG = INoAIDL::class.java.simpleName private val DESCRIPTOR = INoAIDL::class.java.name abstract class Stub : Binder(), INoAIDL {...} class Proxy(private val remote: IBinder) : INoAIDL {...} }} INoAIDL.kt文件的大体结构如上代码，我们可以看到，在这个IInterface类中： 定义两个Server端承诺的服务——sayHi和showObjN； 两个静态类——一个Stub类和一个Proxy类。 Stub类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768abstract class Stub : Binder(), INoAIDL { companion object { const val TRANSACTION_sayHi = IBinder.FIRST_CALL_TRANSACTION + 0 const val TRANSACTION_showObjN = IBinder.FIRST_CALL_TRANSACTION + 1 fun asInterface(binder: IBinder?): INoAIDL? { if (binder == null) { return null } val iin = binder.queryLocalInterface(DESCRIPTOR) if (iin != null &amp;&amp; iin is INoAIDL) { Log.v(TAG, &quot;Client and Server in the same Process&quot;) return iin } Log.v(TAG, &quot;Client and Server in different Processes&quot;) return Proxy(binder) } } init { attachInterface(this, DESCRIPTOR) } final override fun attachInterface(owner: IInterface?, descriptor: String?) { super.attachInterface(owner, descriptor) } override fun onTransact(code: Int, data: Parcel, reply: Parcel?, flags: Int): Boolean { val descriptor = DESCRIPTOR return when(code) { INTERFACE_TRANSACTION -&gt; { reply?.writeString(descriptor) true } TRANSACTION_sayHi -&gt; { data.enforceInterface(descriptor) val name = data.readString() ?: &quot;&quot; sayHi(name) reply?.writeNoException() true } TRANSACTION_showObjN -&gt; { data.enforceInterface(descriptor) var objN: ObjN? = null if (0 != data.readInt()) { objN = ObjN.CREATOR.createFromParcel(data) } val _result = showObjN(objN!!) reply?.writeNoException() if (_result != null) { reply?.writeInt(1) _result.writeToParcel(reply, Parcelable.PARCELABLE_WRITE_RETURN_VALUE) } else { reply?.writeInt(0) } true } else -&gt; { super.onTransact(code, data, reply, flags) } } } override fun asBinder(): IBinder { return this }} 在Manifest文件中我们定义对应Service 1234567&lt;service android:name=&quot;.NoAIDLService&quot; android:enabled=&quot;true&quot; android:exported=&quot;true&quot; /&gt; &lt;!--android:process=&quot;:noAIDL&quot;--&gt; &lt;!--把上述属性设置到service中，则是在不同进程中运行--&gt; 我们重点关注asInterface方法，在这个方法中，有一个代码片段： 1234567val iin = binder.queryLocalInterface(DESCRIPTOR)if (iin != null &amp;&amp; iin is INoAIDL) { Log.v(TAG, &quot;Client and Server in the same Process&quot;) return iin}Log.v(TAG, &quot;Client and Server in different Processes&quot;)return Proxy(binder) 通过这样的代码来进行Client和Server是否在不同进程的判断。 相同进程：返回queryLocalInterface出来的对象，这个对象是在Stub构造方法中通过attachInterface方法传入的。 不同进程：构造一个Proxy类返回。 MainActivity去bind一个Service，Service返回一个Binder。我们打印一下日志。 1234567class NoAIDLService : Service() { override fun onBind(intent: Intent): IBinder { return binder.also { Log.v(TAG, &quot;onBind=$it&quot;) } }} 1234567891011private var noAIDL: INoAIDL? = nullprivate val noConnection = object : ServiceConnection { override fun onServiceConnected(name: ComponentName?, service: IBinder?) { service ?: return Log.v(TAG, &quot;onServiceConnected service=$service&quot;) noAIDL = INoAIDL.Companion.Stub.asInterface(service) Toast.makeText(this@MainActivity, &quot;connected to NoAIDLService&quot;, Toast.LENGTH_SHORT).show() Log.v(TAG, &quot;onServiceConnected noAIDL=${noAIDL}&quot;) }} 当Client与Server在相同进程，有如下日志： 123456// NoAIDLServiceonBind=com.github.boybeak.noaidl.NoAIDLService$binder$1@84abbdc// MainActivityonServiceConnected service=com.github.boybeak.noaidl.NoAIDLService$binder$1@84abbdcnoAIDL=com.github.boybeak.noaidl.NoAIDLService$binder$1@84abbdc 当Client与Server在不同进程，有如下日志： 123456// NoAIDLServiceonBind=com.github.boybeak.noaidl.NoAIDLService$binder$1@2d32060// MainActivityonServiceConnected service=android.os.BinderProxy@99b42f6noAIDL=com.github.boybeak.noaidl.INoAIDL$Companion$Proxy@67e8964 我们看到，当Client与Server在相同进程时候，Service的onBind方法返回的是什么，MainActivity接收到的就是什么；而当Client与Server在不同进程的时候，则返回的是Binder驱动传递给我们的对象，通过这个对象，我们创造一个 Proxy代理对象。 我们接下来重点关注showObjN方法。 123456private val binder = object : INoAIDL.Companion.Stub() { override fun showObjN(objN: ObjN): ObjN? { Log.v(TAG, &quot;showObjN objN=$objN&quot;) return objN }} 这个方法中，直接返回传入的参数。 调用的地方这样来写： 12345678910fun showObjN(v: View) { if (noAIDL == null) { Toast.makeText(this, &quot;Click NOAIDL button first&quot;, Toast.LENGTH_SHORT).show() return } val objN = ObjN() Log.v(TAG, &quot;showObjN objN=$objN&quot;) val returnObjN = noAIDL?.showObjN(objN) Log.v(TAG, &quot;showObjN returnObjW=$returnObjN&quot;)} 我们来看打印的objN日志。 相同进程情况下： 123456// Client进程com.github.boybeak.binder V/MainActivity: showObjN objN=com.github.boybeak.noaidl.ObjN@4c7d499com.github.boybeak.binder V/MainActivity: showObjN returnObjW=com.github.boybeak.noaidl.ObjN@4c7d499// Server进程com.github.boybeak.binder V/NoAIDLService: showObjN objN=com.github.boybeak.noaidl.ObjN@4c7d499 不同进程情况下： 123456// Client进程com.github.boybeak.binder V/MainActivity: showObjN objN=com.github.boybeak.noaidl.ObjN@5ab3a61com.github.boybeak.binder V/MainActivity: showObjN returnObjW=com.github.boybeak.noaidl.ObjN@db79986// Server进程com.github.boybeak.binder V/NoAIDLService: showObjN objN=com.github.boybeak.noaidl.ObjN@1c5381d 我们可以看到，在相同进程情况下，就是普通的函数调用；在不同进程情况下，Client传入的参数，Server接收到的参数，Client接收到的返回结果，全是不同的对象，这是因为，通过Proxy对象，在跨进程通信时候，将Parcelable对象进行了序列化和反序列化。 本文是在阅读写给 Android 应用工程师的 Binder 原理剖析一文后，加上自己的理解与实验完成，其中部分段落直接复制了原文，因为我觉得，那部分原文已经足够容易理解且没有冗余的文字，感谢原作者张磊，同时附上原文参考资料： Android Binder 设计与实现 - 设计篇 Android 进程间通信（IPC）机制 Binder 简要介绍和学习计划、《Android 系统源代码情景分析》 Binder 学习指南 Binder 系列文章 Android 图文详解 Binder 跨进程通信原理 Android 深入浅出之 Binder 机制 用户空间与内核空间 认真分析 mmap ：是什么 为什么 怎么用","link":"/2020/10/20/2022-09-19-Binder%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"title":"LaunchMode","text":"此文是阅读《Android 面试黑洞——当我按下 Home 键再切回来，会发生什么？》一文后的总结，视频地址Bilibili、Youtube。 演示代码： 在正式讲解launchMode前，先要理解三个概念：ActivityStack, TaskRecord, ActivityRecord。 12345678910111213graph LR;style TaskRecord-A fill:#aaddff;style TaskRecord-B fill:#aaddff;subgraph ActivityStacksubgraph TaskRecord-AA[ActivityRecord-1]B[ActivityRecord-2]endsubgraph TaskRecord-BC[ActivityRecord-3]D[ActivityRecord-4]endend 他们的一般结构是这样的。 通过adb命令可以查看当前的ActivityStack、TaskRecord和ActivityRecord的结构。 1adb shell dumpsys activity 结果如下(搜索ACTIVITY MANAGER STARTER (dumpsys activity containers))： 1234567891011121314...ACTIVITY MANAGER STARTER (dumpsys activity containers)com.android.server.am.ActivityStackSupervisor@299f1c5 type=undefined mode=fullscreen #0 ActivityDisplay={0 numStacks=2} type=undefined mode=fullscreen #1 ActivityStack{694271a stackId=0 type=home mode=fullscreen visible=true translucent=false, 1 tasks} type=home mode=fullscreen #0 TaskRecord{e42980e #2 I=com.android.launcher3/.Launcher U=0 StackId=0 sz=1} type=home mode=fullscreen #0 ActivityRecord{5efeaf4 u0 com.android.launcher3/.Launcher t2} type=home mode=fullscreen #0 ActivityStack{91ac24b stackId=1 type=standard mode=fullscreen visible=false translucent=true, 1 tasks} type=standard mode=fullscreen #0 TaskRecord{583322f #72 A=com.github.boybeak.hellolaunchmode U=0 StackId=1 sz=1} type=standard mode=fullscreen #0 ActivityRecord{a126ec8 u0 com.github.boybeak.hellolaunchmode/.MainActivity t72} type=standard mode=fullscreen... 我们可以看到，此时有两个ActivityStack，索引为0的ActivityStack中，有一个TaskRecord，这个TaskRecord里有一个ActivityRecord，就是我们实验App的MainActivity；索引为1的ActivityStack为我们的Home界面。 四种launchMode的一般行为LaunchMode共有4个值可以选择：Standard、SingleTop、SingleTask、SingleInstance。接下来将分开讲这4个值的作用，实际上，由于Activity的跳转会涉及到两个Activity，比如ActivityA -&gt; ActivityB，ActivityB的跳转行为模式，不止受到自己launchMode的影响，还会受到ActivityA的launchMode的影响。除此以外，还会有其他属性的影响，比如taskAffinity、allowTaskReparenting、documentLaunchMode等。 Standard 这是launchMode的值。它的默认行为是：在当前TaskRecord下创建新Activity。 SingleTop SingleTop的行为是：如果有一个同类型的Activity在当前TaskRecord的栈顶，那么就直接使用这个栈顶的Activity并调用其onNewIntent()方法；如果栈顶没有同类型的Activity，则在栈顶创建一个对应的Activity。 SingleTask SingleTask的行为是：在对应taskAffinity的TaskRecord中，如果已经有了对应类型的Activity，则直接使用该Activity，并调用onNewIntent()方法，如果有其他Activity压在该Activity上，则这些Activity都将出栈，该Activity重回栈顶；如果对应taskAffinity的TaskRecord中没有对应类型的Activity，则创建对应类型的Activity并压入栈顶。 这里需要注意的是taskAffinity对该属性的影响，如果没有为android:launchMode=&quot;singleTask&quot;的Activity指定taskAffinity，则默认值为Application的taskAffinity，而Application的默认taskAffinity为包名。 SingleInstance SingleInstance的行为是：1，只允许有一个栈中有此Activity，并且这个栈只允许有这一个Activity；2，如果已经有一个栈中有对应的Activity，则直接使用该Activity，并调用onNewIntent()方法。 SingleInstance对其他三种launchMode的影响由于SingleInstance是如此的霸道，导致从一个SingleInstance的Activity启动其他类型Activity的话，会改变其他三种模式的一般行为。 SingleInstanceA -&gt; StandardB StandardActivityB将无法在当前栈中创建，会回到默认栈中创建。 SingleInstanceA -&gt; SingleTopB 这个行为就很复杂了，可以按照SingleTopB有无taskAffinity属性分为两种情况： 无taskAffinity：则直接在默认的栈中，创建新的SingleTopB或者使用已经存在的SingleTopB。 有taskAffinity：则在指定taskAffinity的栈中创建创建新的SingleTopB或者使用已经存在的SingleTopB。 这里实际上存在一个更为复杂的行为模式：StandardA -&gt; SingleTopB -&gt; SingleInstanceC -&gt; SingleTopB。 如果SingleTop有taskAffinity属性的话，情况就可以分为两个部分： StandardA -&gt; SingleTopB：在StandardA相同TaskRecord中创建SingleTopB的实例singleTopB1。 SingleInstanceC -&gt; SingleTopB：在指定taskAffinity的TaskRecord中，创建SingleTopB的实例singleTopB2。 也就是说，此时有两个SingleTopB对象——singleTopB1和singleTopB2，分别在两个TaskRecord中。 SingleInstanceA -&gt; SingleTaskB 比照SingleInstanceA -&gt; SingleTopB的例子，同样可以可以按照SingleTaskB有无taskAffinity属性分为两种情况： 无taskAffinity：则直接在默认的栈中，创建新的SingleTaskB或者使用已经存在的SingleTaskB。 有taskAffinity：则在指定taskAffinity的栈中创建创建新的SingleTaskB或者使用已经存在的SingleTaskB。 总结大体了解了不同launchMode的行为逻辑，他们的用途可以简单粗暴的归结如下规律： standard和singleTop：多用于App内部； singleInstance：多用于开放给外部App来共享使用； singleTask：内部交互和外部调用都会用得上。 当然，不能一概而论，还是要看具体需求。 看起来似乎很复杂，其实只要掌握了adb shell dumpsys activity这个命令工具，就能清晰的看到当前Activity的分布情况，就能分析出，你的Activity应该用什么launchMode，要不要设置taskAffinity。 参考文献ActivityRecord、TaskRecord、ActivityStack以及Activity启动模式详解","link":"/2020/10/25/2022-09-19-LaunchMode/"},{"title":"发布Android库到MavenCentral教程","text":"JCenter已经宣布，即将在2020年5月1日，停止新的库的提交，在2022年2月21号以前，连库的解析服务也停止，所以，把以前的库或者未来的新库替换到MavenCentral是当务之急了。 我参考的教程来自以下两篇文章： Publishing your first Android library to MavenCentral Android库发布到Maven Central全攻略 Demo项目地址： EasyPack 建议英文能力强的直接第一篇，我是在第二篇遇到问题时候，找到了第一篇文章解决了问题，因为第二篇里用的windows环境，我用的mac环境。 一、 Sonatype Jira相关设置首先，先去Sonatype Jira这个地址注册一个SonatypeJira的账号； 其次，账号创建后，登录，然后在这个页面https://issues.sonatype.org/projects 点击Create创建一个issue，如下图： 这里group id最好使用你的github地址，这样比较容易验证，如果你想用自己单独的域名，需要做更多的操作。很繁琐，不建议这样做。 创建以后，会有管理员处理你的这个issue，等待管理员回复你的issue，他会告诉你，要在你的github创建一个repo，repo的名字是这个issue的id，比如我的是OSSRH-66052。管理员回复我的如下图： 你创建好repo后，回复管理员就好了，等待这个issue的状态变成RESOLVED状态。 这样，你就创建好了一个issue，用来承接对应group id下所有的库。 二、Gradle的准备在你项目根目录下的build.gradle文件添加classpath。 1234567891011121314151617buildscript { ext { kotlin_version = &quot;1.4.31&quot; appcompat = &quot;1.2.0&quot; dokka_version = '1.4.10.2' } repositories { google() mavenCentral() } dependencies { classpath 'com.android.tools.build:gradle:4.1.3' classpath &quot;org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version&quot; classpath &quot;org.jetbrains.dokka:dokka-gradle-plugin:$dokka_version&quot; //新添加的这一classpath }} 在你要提交的module下的build.gradle文件中，尾部追加如下代码： 12345ext { PUBLISH_ARTIFACT_ID = &quot;你的artifact_id，一般是module的名字&quot;}apply from: '../publish.gradle' 在根目录下创建publish.gradle，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113apply plugin: 'maven-publish'apply plugin: 'signing'task androidSourcesJar(type: Jar) { classifier = 'sources' from android.sourceSets.main.java.source exclude &quot;**/R.class&quot; exclude &quot;**/BuildConfig.class&quot;}ext { PUBLISH_GROUP_ID = '你的group_id' PUBLISH_VERSION = '你的版本号'}ext[&quot;signing.keyId&quot;] = ''ext[&quot;signing.password&quot;] = ''ext[&quot;signing.secretKeyRingFile&quot;] = ''ext[&quot;ossrhUsername&quot;] = ''ext[&quot;ossrhPassword&quot;] = ''File secretPropsFile = project.rootProject.file('local.properties')if (secretPropsFile.exists()) { println &quot;Found secret props file, loading props&quot; Properties p = new Properties() p.load(new FileInputStream(secretPropsFile)) p.each { name, value -&gt; ext[name] = value }} else { println &quot;No props file, loading env vars&quot;}publishing { publications { release(MavenPublication) { // The coordinates of the library, being set from variables that // we'll set up in a moment groupId PUBLISH_GROUP_ID artifactId PUBLISH_ARTIFACT_ID version PUBLISH_VERSION // Two artifacts, the `aar` and the sources artifact(&quot;$buildDir/outputs/aar/${project.getName()}-release.aar&quot;) artifact androidSourcesJar // Self-explanatory metadata for the most part pom { name = PUBLISH_ARTIFACT_ID description = '你的项目描述' // If your project has a dedicated site, use its URL here url = 'https://github.com/boybeak/EasyPack' licenses { license { //协议类型，一般默认Apache License2.0的话不用改： name = 'The Apache License, Version 2.0' url = 'http://www.apache.org/licenses/LICENSE-2.0.txt' } } developers { developer { id = '你的sonatype用户名' name = '你的sonatype用户名' email = '你的sonatype注册邮箱' } } // Version control info, if you're using GitHub, follow the format as seen here scm { //修改成你的Git地址： connection = 'scm:git:github.com/你的github账号/你的项目名称.git' developerConnection = 'scm:git:ssh://github.com/你的github账号/你的项目名称.git' //分支地址： url = 'https://github.com/你的github账号/你的项目名称/tree/master' } // A slightly hacky fix so that your POM will include any transitive dependencies // that your library builds upon withXml { def dependenciesNode = asNode().appendNode('dependencies') project.configurations.implementation.allDependencies.each { def dependencyNode = dependenciesNode.appendNode('dependency') dependencyNode.appendNode('groupId', it.group) dependencyNode.appendNode('artifactId', it.name) dependencyNode.appendNode('version', it.version) } } } } } repositories { // The repository to publish to, Sonatype/MavenCentral maven { // This is an arbitrary name, you may also use &quot;mavencentral&quot; or // any other name that's descriptive for you name = &quot;mavencentral&quot; def releasesRepoUrl = &quot;https://oss.sonatype.org/service/local/staging/deploy/maven2/&quot; def snapshotsRepoUrl = &quot;https://oss.sonatype.org/content/repositories/snapshots/&quot; // You only need this if you want to publish snapshots, otherwise just set the URL // to the release repo directly url = version.endsWith('SNAPSHOT') ? snapshotsRepoUrl : releasesRepoUrl // The username and password we've fetched earlier credentials { username ossrhUsername password ossrhPassword } } }}signing { sign publishing.publications} 三、创建GPG秘钥 https://www.gnupg.org/download/，从这里下载并安装GPG客户端。 在命令行中执行命令gpg --full-gen-key，注意，一定要在命令行中执行命令，不能在客户端界面做。 加密方式选择RSA and RSA，长度输入4096，过期时间直接回车不用管，然后输入一个user ID并且提供一个邮箱，我直接用的我sonatype的用户名和邮箱。最后一步输入’O’，表示OK。 之后会弹出一个对话框，让输入密码。 1234567gpg: revocation certificate stored as '~/.gnupg/openpgp-revocs.d/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXE478F7CC.rev'public and secret key created and signed.pub rsa4096 2021-03-22 [SC] XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXEE478F7CCuid boybeak &lt;boybeak@gmail.com&gt;sub rsa4096 2021-03-22 [E] 这会为你在~/.gnupg/openpgp-revocs.d/目录下创建一个.rev文件，记住pub的末尾8位。 接下来创建secring.gpg文件，命令行执行gpg --export-secret-keys -o secring.gpg，这会要求你输入在步骤4中设置的密码，在你用户根目录下会出现secring.gpg文件。 回到gpg客户端，选择我们刚生成的秘钥条目，右键，选择Send Public Key to Key Server。 四、设置local.properties12345signing.keyId=刚才获取的秘钥后8位signing.password=步骤4中设置的密码signing.secretKeyRingFile=刚才生成的secring.gpg文件目录ossrhUsername=sonatype用户名ossrhPassword=sonatype密码 五、执行打包和上传设置完这些后，在AndroidStudio右侧的gradle tasks中找到你想提交的module，先后执行以下两个任务。 上传成功后，打开Nexus Repository Manager，登录你的sonatype账号，在左侧Staging Repositories页面找到你的group id，选中，点击上边的close，等待几分钟十几分钟后刷新状态，等其状态变为closed后，再点击Release，则所有人都用使用你的库了。 。","link":"/2021/03/23/2022-09-19-Mavencentral/"},{"title":"难忘的bug","text":"此贴是为了记录日常开发过程中，遇到的一些让人难忘的bug。 MediaPlayer: surface has already been released kotlin ?.的陷阱与缺陷 surface has already been released场景：MediaPlayer做跨进程的视频播放发现的，由于有无画面的后台播放场景，所以，MediaPlayer的相关操作放在独立进程的Service中，通过跨进程的调度，进行相关媒体操作，包括设置用于展示画面的Surface，Surface是一个Parcable类，所以是可以通过跨进程传输的。归因：在播放进程中，用成员变量缓存了通过setSurface设置的surface变量，以便于从后台恢复前台播放时候，可以直接使用，而不需要再次传入surface参数。但是这样做是不可以的，会爆出surface has already been released的错误。IPlayer.aidl如下： 123interface IPlayer { void setSurface(inout Surface surface);} 需要注意的是，此处surface的修饰符包括一个inout。这样设置，是为了适配IjkMediaPlayer切换全屏的场景。如果把这个修饰符改成in，则IjkMediaPlayer在通过setSurface多次修改surface时候，也会爆出surface has already been released这样的问题。 kotlin ?.的陷阱与缺陷?.是kotlin的空安全语法。相比Java的if语句判断，这样做要简洁的多，但是这里边有一种“陷阱”，这并不是kotlin本身的问题，而是使用者容易疏忽的问题。展示逻辑的伪代码如下： 12345方法A(回调) { 结果1 = 动作1 结果2 = 动作2 回调(结果1, 结果2)} 简单解释一下，一个方法A，带有一个Nullable的回调，需要执行动作1和动作2，分别返回了结果1和结果2，并且在回调中返回结果。上述逻辑用kotlin实现如下： 12345678// 方案一fun action1(): Int = 1fun action2(): Int = 2fun methodA(block: ((Int, Int) -&gt; Unit)? = null) { val result1 = action1() val result2 = action2() block?.invoke(result1, result2)} 或者 123456// 方案二fun action1(): Int = 1fun action2(): Int = 2fun methodA(block: ((Int, Int) -&gt; Unit)? = null) { block?.invoke(action1(), action2())} 如果你选择了方案二，那么你就掉入”陷阱”了。因为方法内执行的逻辑，不应该收到回调的影响。如果在methodA中传入了null作为参数，或者直接调用methodA()，这样参数block就为null，那么方案二是不等价于方案一的，我只是不需要知道方法的执行结果，不是让你不执行方法。","link":"/2022/09/22/2022-09-22-%E9%9A%BE%E5%BF%98%E7%9A%84bug/"},{"title":"Kotlin Native从初识到放弃","text":"此贴用于记录对Kotlin Native从初识到放弃的过程，因为还不清楚这一平台的开发能力上限多高，不排除用的好，会一直用下去。以下Kotlin Native会用KN来代替。 开始首先，下载IDEA，我这里用的是社区版，社区版已经足以应对大多数情况了。然后，新建一个KN的项目。IDE会自动生成hello world代码，直接点运行，如果工具栏的运行按钮没有可执行的配置，那就直接在Main.kt文件上右键运行。相比直接用Clion写**C/C++*代码的运行速度，KN项目运行要慢得多，因为要先执行gradle脚本。即便是这样，你也很可能第一次运行不成功，在macOs上，要安装XCode command line tools*工具，我这里直接安装了完整版的XCode。然后继续尝试运行，你很可能会发现，依然执行不成功，报如下错误： 1The /usr/bin/xcrun command returned non-zero exit code: 72 这时候，你需要打开XCode，执行一系列同意操作后，进入Preferences -&gt; Locations，选中一个版本。如下：如果你没有安装完整XCode，可以尝试xcode select这个命令，这里具体不做详述。经过这个设置后，再次尝试运行，这次终于运行成功。 123456789101112131415161718192021222324252627282930313233343521:41:11: Executing 'runDebugExecutableNative'...Starting Gradle Daemon...Gradle Daemon started in 3 s 569 ms&gt; Configure project :Kotlin Multiplatform Projects are an Alpha feature. See: https://kotlinlang.org/docs/reference/evolution/components-stability.html. To hide this message, add 'kotlin.mpp.stability.nowarn=true' to the Gradle properties.The property 'kotlin.mpp.enableGranularSourceSetsMetadata=true' has no effect in this and future Kotlin versions, as Hierarchical Structures support is now enabled by default. It is safe to remove the property.The property 'kotlin.native.enableDependencyPropagation=false' has no effect in this and future Kotlin versions, as Kotlin/Native dependency commonization is now enabled by default. It is safe to remove the property.&gt; Task :wrapperBUILD SUCCESSFUL in 21s1 actionable task: 1 executed&gt; Configure project :Kotlin Multiplatform Projects are an Alpha feature. See: https://kotlinlang.org/docs/reference/evolution/components-stability.html. To hide this message, add 'kotlin.mpp.stability.nowarn=true' to the Gradle properties.The property 'kotlin.mpp.enableGranularSourceSetsMetadata=true' has no effect in this and future Kotlin versions, as Hierarchical Structures support is now enabled by default. It is safe to remove the property.The property 'kotlin.native.enableDependencyPropagation=false' has no effect in this and future Kotlin versions, as Kotlin/Native dependency commonization is now enabled by default. It is safe to remove the property.&gt; Task :compileKotlinNative UP-TO-DATE&gt; Task :linkDebugExecutableNative UP-TO-DATE&gt; Task :runDebugExecutableNativeHello, Kotlin/Native!BUILD SUCCESSFUL in 3s3 actionable tasks: 1 executed, 2 up-to-date21:41:44: Execution finished 'runDebugExecutableNative'. 请在上述输出日志中寻找Hello, Kotlin/Native字符串，很不起眼。","link":"/2022/09/23/2022-09-23-Kotlin%20Native/"},{"title":"Android的clipToXXX","text":"最近处理工作bug的过程中，有一个需求是这样的，两层view，父view包含着子view，然后子view能显示出的区域，要以父view的背景来过滤。没看懂是不是？参考下图：简单说，就是子view的背景显示区域，不能超过父view的背景区域。 clipToOutline经过一番搜索尝试，终于查到，可以通过clipToOutline + outlineProvider来实现，说来惭愧，做了将近20年android开发，竟然到现在才知道这样的特性。具体代码如下： 123456789101112131415&lt;FrameLayout android:id=&quot;@+id/togetherParent&quot; android:layout_width=&quot;100dp&quot; android:layout_height=&quot;100dp&quot; android:layout_margin=&quot;8dp&quot; android:background=&quot;@drawable/bg_parent&quot; android:clipToOutline=&quot;true&quot; android:outlineProvider=&quot;background&quot; &gt; &lt;View android:id=&quot;@+id/togetherChild&quot; android:layout_width=&quot;100dp&quot; android:layout_height=&quot;100dp&quot; android:background=&quot;@drawable/bg_child&quot;/&gt;&lt;/FrameLayout&gt; 但是以上代码只可以在API Level 31及以上使用，要增大适用版本范围，可以用以下代码，在kotlin中实现： 12parent.clipToOutline = trueparent.outlineProvider = ViewOutlineProvider.BACKGROUND kotlin中代码，就可以实现，低至API Level 21及以上使用。 除了clipToOutline，我还发现了其他clipToXXX有关的API。 clipChildren","link":"/2022/10/13/2022-10-13-clipToXXX/"},{"title":"Translator","text":"Translator Translator is a simple translation app based on Tencent Machine Translation API. Only macOs version is available at this moment. Releases","link":"/2022/11/02/2022-11-02-Translator/"},{"title":"Intent.FLAG_ACTIVITY_***解密","text":"最好先看这一篇[Launch Mode](/android/LaunchMode.html)。 我们将重点针对FLAG_ACTIVITY_NEW_TASK、FLAG_ACTIVITY_CLEAR_TASK、FLAG_ACTIVITY_CLEAR_TOP、FLAG_ACTIVITY_SINGLE_TOP四个flag进行讲解。 FLAG_ACTIVITY_NEW_TASK： 通过非Activity的Context启动一个Activity时候，要使用此flag，比如：ApplicationContext、Service等； 用于Launcher类应用启动其他应用的时候； 当试图通过这个flag启动一个activity的时候，如果后台已经有一个任务栈中有运行的一个此类activity实例，将不会创建一个新的activity，而是将整个栈置于前台，并保持上次的状态。比如从另一个应用启动这种场景，或者Notification中。 如果你想使用startActivityForResult，则千万不要在启动的intent添加这个flag。因为onActivityResult回调方法，不会在目标activity执行finish后调用，而是在启动目标activity的时候直接调用，并且收r到resultCode = RESULT_CANCELED。 FLAG_ACTIVITY_CLEAR_TOP： 如果在当前任务栈中已经有了目标类型activity，则再次通过添加了此flag的intent去启动此类型activity，会有两种情况。 比如有如下图示结构的任务栈: 1234567graph LR;subgraph Task;D;C;B;A;end; 此时D通过一个添加了FLAG_ACTIVITY_CLEAR_TOP的intent去启动了B类型Activity，则C、D执行onDestroy出栈（不会执行finish，触发onDestroy），现在B在栈顶，有如下图示： 12345graph LR;subgraph Task;B;A;end; 接下来就有两种情况了。 情况一：intent中没有同时设置FLAG_ACTIVITY_SINGLE_TOP，并且B的launchMode是默认值。 B会finish掉再re-create一个新的B’放在B的位置上。 情况二：intent中设置了FLAG_ACTIVITY_SINGLE_TOP或者是其他类型的launchMode。 B不会finish（调用finish方法，onDestroy会被触发）掉，而是直接调用其onNewIntent()方法。 或许你认为情况二这与launchMode中的singleTop或者singleTask类似，实则不然，其一，singleTop没有清空压在它上边activity的能力；其二，singleTask收到taskAffinity影响。 与FLAG_ACTIVITY_NEW_TASK配合使用。如果想启动一个任务栈的root位置的activity，也就是栈低activity，同时设置这两个值，它会将整个任务栈放置于前台，并且清空其他activit，适用于从Notification启动Activity。 FLAG_ACTIVITY_CLEAR_TASK：这个flag很特殊，只能于FLAG_ACTIVITY_NEW_TASK配合使用。要启动的目标activity的任务栈如果已经存在并且不为空，则将所有activity出栈（不会调用finish方法，onDestroy会被触发），然后创建一个目标类型activity作为这个栈的root。 FLAG_ACTIVITY_SINGLE_TOP：这个flag与launchMode中的singleTop几乎一样，当要启动一个activity时候，如果栈顶就是目标类型activity，则不会创建一个新的activity，而是直接调用栈顶的这个activity的onNewIntent()方法。","link":"/2022/09/19/2022-09-19-Intent.FLAG_ACTIVITY_XXX%E5%88%B0%E5%BA%95%E8%83%BD%E5%B9%B2%E5%95%A5/"},{"title":"Jitpack托管库","text":"以前只是用过别人托管在Jitpack上的库，自己的库都是托管在MavenCentral上，但是MavenCentral使用起来，相比Jitpack还是有些麻烦。经过简单尝试和学习，了解了Jitpack的使用，做一下简单记录。 我第一个托管在Jitpack上的库——J2V8Helper Step 1: 在library module中使用maven-publish插件在库目录下的build.gradle文件中，应用maven-publish插件，修改后的build.gradle文件入下： 123456plugins { id 'com.android.library' id 'org.jetbrains.kotlin.android' id 'maven-publish'}// Other code 然后检查此插件是否引入成功，在AndroidStudio的右侧，Gradle面板中，library module下查看有无publishing的任务组。 如果找不到，有可能是AndroidStudio配置的问题，在AndroidStudio的设置中，进入Experimental选项卡中，找到Gradle分组，找到Only include test tasks in the Gradle task list generated during Gradle Sync，如果勾选了，请不要勾选此选项。 在library module下的build.gradle结尾，添加如下代码： 12345678910111213141516171819202122232425afterEvaluate { publishing { publications { // Creates a Maven publication called &quot;release&quot;. release(MavenPublication) { // Applies the component for the release build variant. from components.release // You can then customize attributes of the publication as shown below. groupId = 'com.github.xyz' artifactId = 'abc' version = '0.0.1' } // Creates a Maven publication called “debug”. debug(MavenPublication) { // Applies the component for the debug build variant. from components.debug groupId = 'com.github.xyz' artifactId = 'abc' version = '0.0.1' } } }} 需要注意的是，此配置，在Jitpack的编译中，并不会生效，Jitpack中你的库的引用，永远都是com.github.{你github用户名}:{此项目在gitHub上repository的名字}:{创建release的tag名字}。此处配置，只为检查你的maven-publish是否生效。 然后执行Gradle任务中的publishReleasePublicationToMavenLocal，待执行完毕，查看$HOME/.m2/responsitory路径下，有无你的库存在。如果成功，请执行下一步骤。 Step 2: 将代码push到github并新建release在你Github对于的repository下，新建一个tag和release。 Step 3: 在jitpack.io搜索你的库，并执行打包打开https://jitpack.io/ 点击Get it，然后等待编译结束，如果编译失败，会有日志记录，可以查看对应的日志来处理。 需要注意的是，Jitpack默认的java版本为java8，如果你的Gradle版本比较高的话，比如我项目的Gradle版本为7.4.0，需要修改java版本，在项目的根目录下，创建一个jitpack.yml文件，增加配置脚本如下： 12jdk: - openjdk11 Gradle版本7.4.0对应最低编译版本为java11，则我修改为openjdk11。 参考文章Publish an Android Library [使用 Maven Publish 插件](使用 Maven Publish 插件 &amp;nbsp;|&amp;nbsp; Android 开发者 &amp;nbsp;|&amp;nbsp; Android Developers) Maven Publish Plugin Android发布AAR至JitPack.io [Guide to publishing libraries](Building - JitPack.io)","link":"/2023/03/04/2023-03-04-Jitpack%E6%89%98%E7%AE%A1%E5%BA%93/"},{"title":"难忘的调试技巧","text":"这里用于总结一些在工作中发现的调试技巧。 Handler是否繁忙？这一技巧来自于最近工作中，做子线程渲染时，发现有卡顿、手势操作延迟过大的情况，而渲染的子线程是一个HandlerThread，为了判断此线程是否有大量耗时操作，探索出一些技巧。 ##判断HandlerThread是否繁忙##可以通过对应的Handler执行一个post操作，在看其中执行的延迟，代码如下： 123456val handler = Handler(renderThread.looper)val postAt = System.currentTimeMillis()handler.post { val delay = System.currentTimeMillis() - postAt Log.d(TAG, &quot;renderThread.delay=$delay&quot;)} 在正常情况下，delay的值是很小的，大概率为0，但是，如果renderThread异常繁忙，则这个值会很大，说明等了很久来轮到一个需要立马执行的操作执行到，具体这个阈值怎么来定，要看你的实际场景，一般做ui渲染的话，超过17ms就可以认为是比较耗时了。这个操作可以定时执行用于检测是否繁忙，也可以用于在怀疑的操作后添加此行为，判断是否是之前的操作耗时过长引起了操作延迟过大。 ##如何找到导致繁忙的操作？##上述操作，一般是用于常规检测和重点怀疑，如果要做“普筛”，则需要通过代理的方式。方法如下： 1234567891011121314class DebugThread(val task: Runnable, val postDelayed: Long) : Runnable { private val pendingRunAt = System.currentTimeMillis() + postDelayed override fun run() { val now = System.currentTimeMillis() task.run() val cost = System.currentTimeMillis() - now val delay = now - pendingRunAt if (delay &lt; 10 &amp;&amp; cost &gt; 160) { Log.w(TAG, &quot;Oops!!!&quot;) } }} 需要将所有handler.post与handler.postDelayed中的Runnable换成上面的代理类，在代理类中观察是否有耗时操作，一般delay比较小，说明此操作前没有耗时操作导致当前操作延迟，而cost值比较大，说明会引起之后操作延迟过大，可以在打印出具体的delay与cost值进行操作前后比较。不过这种方式的缺点是不够灵活，需要将大量的，甚至是所有的post操作进行代理。","link":"/2023/05/04/2023-05-04-%E9%9A%BE%E5%BF%98%E7%9A%84%E8%B0%83%E8%AF%95%E6%8A%80%E5%B7%A7/"},{"title":"软键盘高度监测最佳实践","text":"最近终于总结出最佳的软键盘高度监测方案了，特此分享出来。源码在此：KeyboardObserver.kt 视觉效果当开启showDebug时候，可以看到这样的可视化的键盘高度监测。 源码分析简单来说，这里说通过两个PopupWindow来实现的键盘高度测量。一个用于测量当前屏幕状态可绘制区域的最大高度，一个用于跟随键盘移动，进而通过高度差，算出键盘的高度。我们这里将前者称为RulerPopWin, 后者称为CursorPopWin。他们的代码分别如下： 1234567891011121314151617181920212223// RulerPopWinprivate val rulerPopWin by lazy { makeRulerPopWin(activity) }private fun makeRulerPopWin(activity: Activity) = PopupWindow(activity).apply { contentView = if (showDebug) { TextView(activity).apply { background = GradientDrawable().apply { this.setStroke(1.dp, Color.LTGRAY) } gravity = Gravity.BOTTOM or Gravity.CENTER_HORIZONTAL setTextColor(Color.RED) } } else { View(activity) } setBackgroundDrawable(null) width = if (showDebug) 80.dp else 1 height = WindowManager.LayoutParams.MATCH_PARENT elevation = 0F isFocusable = false isTouchable = false isOutsideTouchable = false} 1234567891011121314151617181920212223242526272829303132// CursorPopWinprivate val cursorPopWin by lazy { makeCursorPopWin(activity) }private fun makeCursorPopWin(activity: Activity) = PopupWindow(activity).apply { contentView = if (showDebug) { FrameLayout(activity).apply { addView( View(activity).apply { background = ColorDrawable(Color.RED) }, FrameLayout.LayoutParams( FrameLayout.LayoutParams.MATCH_PARENT, 1.dp, Gravity.BOTTOM ) ) } } else { View(activity) } setBackgroundDrawable(null) width = if (showDebug) 80.dp else 1 height = WindowManager.LayoutParams.MATCH_PARENT elevation = 0F softInputMode = WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZE inputMethodMode = PopupWindow.INPUT_METHOD_NEEDED isFocusable = false isTouchable = false isOutsideTouchable = false} 这两个PopupWindow，除了contentView不同以外，还有两个属性不同，cursorPopWin多了两个属性 12softInputMode = WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZEinputMethodMode = PopupWindow.INPUT_METHOD_NEEDED 这两个属性，使得cursorPopWin高度会随着软键盘的弹出而变化。 当开启监听时，为cursorPopWin.contentView设置一个OnLayoutChangeListener，用于监听其布局变化。 123456fun watch() { if (!cursorPopWin.isShowing) { cursorPopWin.showAtLocation(decorView, Gravity.BOTTOM or Gravity.END, 0, 0) cursorPopWin.contentView.addOnLayoutChangeListener(cursorLayoutChangeListener) }} 1234567private val cursorLayoutChangeListener = OnLayoutChangeListener { _, _, _, _, _, _, _, _, _ -&gt; if (rulerPopWin.isShowing) { rulerPopWin.dismiss() } rulerPopWin.showAtLocation(decorView, Gravity.BOTTOM or Gravity.END, 0, 0) rulerPopWin.contentView.addOnLayoutChangeListener(rulerLayoutChangeListener)} 在cursorLayoutChangeListener中，监听到cursotPopWin的变化后，再显示rulerPopWin。为什么要这么做呢？ 因为在实践中，软键盘的变化，触发了onLayoutChange方法，如果是在这之前就把rulerPopWin显示出来，在某些机型或者系统版本中，也会出现rulerPopWin跟随键盘改变尺寸的情况。所以要将rulerPopWin显示在键盘弹出之后。 真实的键盘高度监听，实际上说在rulerLayoutChangeListener中。 123456789101112131415161718192021222324252627282930313233343536private val rulerLayoutChangeListener = object : OnLayoutChangeListener { override fun onLayoutChange( v: View?, left: Int, top: Int, right: Int, bottom: Int, oldLeft: Int, oldTop: Int, oldRight: Int, oldBottom: Int ) { rulerPopWin.contentView.removeOnLayoutChangeListener(this) rulerPopWin.contentView.getGlobalVisibleRect(rulerRect) cursorPopWin.contentView.getGlobalVisibleRect(cursorRect) val keyboardHeight = rulerRect.bottom - cursorRect.bottom if (callbacks.isNotEmpty()) { val cbs = ArrayList&lt;Callback&gt;(callbacks) cbs.forEach { it.onKeyboardHeightChanged(keyboardHeight) } cbs.clear() } if (showDebug) { (v as TextView).run { text = &quot;$keyboardHeight&quot; setPadding(0, 0, 0, max(keyboardHeight - this.lineHeight, 0)) } } }} OK，这就是全部关键逻辑了。 Q&amp;A 为什么要通过rulerPopWin来获取高度，用其他获取屏幕高度的方法不好吗？ 不可以，这里rulerPopWin，实际上是测量当前状态下，键盘收起时的最底部。这个状态受到很多其他方面的影响，比如横竖屏切换、底部导航条的显示或者隐藏。如果通过直接获取屏幕高度的方式，并不能与状态严格对其。尤其说底部导航条的各种显示模式，导致键盘收起的0线也是变化的。 为什么不只用一个cursorPopWin的软键盘弹起前后进行差值计算高度呢？ 这样做在实践中也是不可行的。同样跟问题1中的场景类似，由于底部导航条各种显示模式的影响，导致软键盘0线是不确定的，而软键盘的弹起与收回，可能对应着不同的导航条显示模式，也就对应着不同的0线，这样计算出来的软键盘高度，很容易把导航条的高度也算进去。 由问题2想到，把导航条的高度减掉不就是键盘的高度了吗？ 这样做理论上可行，但是实践上问题会很多。首先，你要针对不同的导航条模式做不同策略；其次，不同系统的导航条的高度不同，包括说传统3键导航条还是全面屏手势；再次，目前获取导航条高度，并没有一个完美的方案，有些系统下获取到的高度，跟实际高度是不相符的。","link":"/2023/07/29/2023-07-29-%E8%BD%AF%E9%94%AE%E7%9B%98%E9%AB%98%E5%BA%A6%E7%9B%91%E6%B5%8B%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"title":"J2V8深度绑定机制分享","text":"一、问题背景在小游戏开发中，常见的一种操作就是设置绘制属性，比如lineWidth、fillStyle这种，这在WebView方案中，因为全跑在JS环境中，没有任何问题。但是在J2V8方案中，因为绘制逻辑在JS层，绘制实现在Java层，这就导致JS层的属性设置，无法传达到Java层。 1234const ctx = canvas.getContext('2d'); // 这里的ctx是Java层返回的V8Object对象ctx.lineWidth = 10;...ctx.stroke(); 上述代码中，ctx.lineWidth = 10;修改后，在Java层是无法感知的。 1.1 以往方案以往方案中，是通过JS层，为ctx对象做代理，拦截到属性变化，再通过调用J2V8的绑定方法，告知Java层，某个属性变化的了。 这样做，有以下几个缺点： 有这种需求的类可能很多，每一个都要JS层做相应的适配，这会增加工作量和调试沟通成本； 并不是所有属性的变化都是Java层关心的； JS层并不知道Java层的属性与类的关系，容易错乱，导致通知了属性变化，却不知道是哪个对象的属性变化了； 后期Java层类做了变动，需要JS层做相应修改，一旦遗漏，就会产生bug； 基于解决以上问题的目的，开发出新的方案——J2V8Binding。 二、J2V8BindingJ2V8Binding的目标是，将JS层属性的变更感知，全部控制在Java层内，无需JS层参与额外代码。 2.1 基本原理与旧方案类似的，我们仍然需要一个JS层的代理，而与旧方案不同的，新方案的代理是由Java层“生成”。 1234567891011private const val CREATE_PROXY_JS = &quot;&quot;&quot;function v8CreateProxy(obj) { return new Proxy(obj, { set: function(target, key, value) { // 在此拦截需要的值变化，并发送给Java层 } })}&quot;&quot;&quot;// ... 初始化V8时 ...v8.executeScript(CREATE_PROXY_JS) 这里我们声明一段JS代码，这里用于创建JS层的代理对象。在初始化V8时，将此段JS代码注入到V8环境中，当我们需要一个JS层代理对象时，就可以执行此JS函数v8CreateProxy创建一个JS层的代理对象。 123private fun createJSProxy(v8obj: V8Object): V8Object { return v8.executeObjectFunction(&quot;v8CreateProxy&quot;, V8Array(v8).apply { push(v8obj) })} 2.2 封装对以上基本逻辑进行封装，有关键类V8Binding、V8Manager、V8Field和V8Method。 2.2.1 V8Binding一个需要绑定的类，需要实现V8Binding接口。 123456789101112131415161718192021222324252627282930313233interface V8Binding { companion object { private const val TAG = &quot;V8Binding&quot; } // V8Binding类的唯一id，用于将JS层对象与Java层对象进行一一对应 // 默认实现为该对象的hashCodeo().toString() fun getBindingId(): String { return hashCode().toString() } // 获取或者创建一个与其对应的代理V8Object fun getMyBinding(v8: V8): V8Object { return V8Manager.obtain(v8).run { if (!isBound(getBindingId())) { createBinding(this@V8Binding) } else { getBinding(getBindingId()) } } } // 没有绑定，但是仍然关心的属性，获取关心的属性名称 fun getCareForFieldKeys(): Array&lt;String&gt; { return emptyArray() } // 关心的属性值变更时 fun onCareForFieldChanged(key: String, newValue: Any?, oldValue: Any?) {} // 绑定的属性值由null变为非null值时触发，只针对非基本数据类型(数值与String)的属性触发 fun onBindingCreated(target: V8Object, fieldInfo: Key, value: V8Object): V8Binding { throw NotImplementedError(&quot;onCreateBinding must be implement when new binding created&quot;) } // 绑定的属性值由非null变为null值时触发，只针对非基本数据类型(数值与String)的属性触发 fun onBindingDestroyed(target: V8Object, fieldInfo: Key) { throw NotImplementedError(&quot;onBindingDestroyed must be implement when binding destroyed&quot;) } // 绑定的属性值发生变化时触发 fun onBindingChanged(target: V8Object, fieldInfo: Key, newValue: Any?, oldValue: Any?)} 在getMyBinding方法中，我们使用V8Manager来创建或者获取一个与当前对象绑定的V8Object对象。 2.2.2 V8ManagerV8Manager是一个针对某个V8环境的管理类，主要是用于维护JS层对象与Java层的绑定关系，执行创建绑定关系、删除绑定关系，分发属性变更事件等作用，J2V8Binding的主要核心逻辑的所在。 由于此处涉及到大量代码细节，故不在此罗列代码具体分析。 2.2.3 V8Field和V8Method这两个类是注解类，用于标记类内属性和方法。 @V8Field(binding=?): 标记属性，其中有一个binding属性，标记此属性是否需要绑定，如果需要绑定，则会有事件回调，默认值为false。 @V8Method(jsFuncName=?): 标记方法，其中有一个jsFuncName属性，用于标识对应的JS函数的名称。 2.3 基本使用方法一个简单的示例类如下： 123456789101112131415161718192021222324252627282930313233class User : V8Binding { // 不需要绑定的属性，值会传递到对应的JS对象，但该值在JS层发生变化，Java层不会知道 @V8Field val name = &quot;John&quot; // 需要绑定的属性，初始值会传递到JS对象，该值在JS层发生变化，会传递到Java层 @V8Field(binding = true) var age = 15 // 需要绑定的V8Binding类型属性，与之对应的V8Object会传递到JS对象， // 在JS层，如果变更为其他JS层内部的对象，会解绑之前的关系，与新的JS对象建立新的绑定关系 @V8Binding(binding = true) val location: V8Binding = ... // 在此方法中 override fun onBindingChanged(target: V8Object, fieldInfo: Key, newValue: Any?, oldValue: Any?){ when(fieldInfo.name) { &quot;age&quot; -&gt; {} } } @V8Method(jsFuncName = &quot;js层对应的名称，默认值与当前方法名一致&quot;) fun sayHello(helloTo: String) { } fun getCareForFieldKeys(): Array&lt;String&gt; { return arrayOf(&quot;introduction&quot;) } fun onCareForFieldChanged(key: String, newValue: Any?, oldValue: Any?) { when(key) { &quot;introduction&quot; -&gt; {} } }} 当使用这个User类的一个对象user时候，可以按照如下方式使用。 123val v8 = V8.createRuntime()val user = ...v8.add(&quot;user&quot;, user.getMyBinding(v8)) 这里，我们在JS环境中，增加了一个user变量。 然后在JS层，执行以下代码。 1234user.name = &quot;Smith&quot;; // Java层不会感知到user.age = 16; // Java层可以在onBindingChanged感知到user.location = {}; // Java层可以在onBindingChanged感知到，并解绑旧location值，与新值建立绑定关系user.introduction = &quot;Hi&quot;; // Java层可以在onCareForFieldChanged感知到 在修改name属性时，由于此属性是被V8Field标记binding为false，则不会通知Java层此值的修改事件。 在修改age属性时，由于此值被V8Field标记binding为true，会通知Java层此值的修改事件。 在修改location属性时，虽然此值为一个对象，但是被V8Field标记binding为true，会通知Java层此值的修改事件。注意：用V8Field标记的对象类型，必须为V8可以接受的数据类型或者V8Binding类型。 在修改introduction时，虽然此值没有被V8Field标记，但是由于在getCareForFieldKeys返回的数组中，同样会有事件通知。 有了这种机制，小游戏开发中，就可以很方便的感知到绘制属性的变化。 2.4 仍然存在的问题目前仍然有一种问题是无法解决的，那就是数组中某个数据发生变化时，Java层是无法得知的。 如下代码： 12345const image = ...;image.pixelBytes[0] = 0; // 修改R值image.pixelBytes[1] = 0; // 修改G值image.pixelBytes[2] = 0; // 修改B值image.pixelBytes[3] = 0; // 修改A值 目前这种场景较少，只在部分demo中见到直接修改图像像素数据的情况。 三、总结以上代码片段只为展示逻辑主脉络，省略了大量细节，需要看细节部分，可以从V8Manager这里作为入口。源码链接：v8x","link":"/2023/08/12/2023-08-12-J2V8%E6%B7%B1%E5%BA%A6%E7%BB%91%E5%AE%9A%E6%9C%BA%E5%88%B6%E5%88%86%E4%BA%AB/"},{"title":"Camera无变形任意尺寸预览","text":"在以往做Camera应用开发时，遇到一个问题，就是相机的预览如何做到在任意尺寸完全无变形的画面预览与视频录制。做过相机应用开发的朋友都知道，相机的预览尺寸并不是可以随意设置的，而是需要在支持的预览尺寸中选择一个，你的预览的view大小必须与选择的尺寸相匹配，才能保证画面不变形，但是这在实际开发中是无法应对各种各样的需求的，而且每个手机，支持的预览尺寸并不是完全一致的，而视频的大小往往是需要做到一致的，不然录制出来的视频，在其他手机上播放，就需要做大量的UI适配工作，也没有平台的统一性。 最初让我有这样的想法，是想做方形的视频，如最初Ins一样，那已经是7年前了，但是当时技术有限，并没有探索出最佳的方案，当时最多可以先录制再通过ffmpeg进行裁剪，这样效率太低了，用户是不能接受的，而且预览画面需要做遮罩，录制做不到所见即所得。 经过其他工作的积累，在OpenGL与Surface搭配工作这方便，点了新的技能点。终于探索出最佳的技术方案。 最终示例代码可以参考我的Github: iCamera。 一、技术背景在阅读接下来的内容前，你最好有以下技术储备： Camera1相关API的使用经验； 对Android的surface有一定了解； 对OpenGL最好有所了解； 当然，如果没有以上相关的知识储备，也不妨碍定性的理解整体流程。 二、基本思路在一般的Camera应用开发时，通常需要有一个预览画面的控件，一般时SurfaceView或者TextureView，然后把Surface或者SurfaceTexture设置给Camera进行预览。 而在我们的方案中，这个过程，要增加一些步骤。具体的步骤如下： 从SurfaceView或者TextureView获得Surface对象，比如holder.surface或者Surface(surfaceTexture)； 由此Surface对象，我们创建EGL环境，并重新创建一个SurfaceTexture对象，这个新的SurfaceTexture对象，最后需要设置给Camera进行预览； 监听步骤2中创建的SurfaceTexture对象的帧数据，通过OpenGL对画面消除形变并进行渲染。 以上就是基本思路，是不是还是一头雾水？没关系，下面进行具体实现的讲解。 三、具体实现在上述的步骤中，第1步很简单，这里不再进行赘述，直接从步骤2开始。 3.1 通过Surface创建EGL环境一般代码示例如下： 1234567891011121314151617181920212223242526272829303132333435363738private val display: EGLDisplay by lazy { EGL14.eglGetDisplay(EGL14.EGL_DEFAULT_DISPLAY) }private var eglSurface: EGLSurface? = nullvar eglContext: EGLContext? = null private setprivate fun createEGL(surface: Surface) { val version = IntArray(2) EGL14.eglInitialize(display, version, 0, version, 1) val attributes = intArrayOf( EGL14.EGL_RED_SIZE, 8, EGL14.EGL_GREEN_SIZE, 8, EGL14.EGL_BLUE_SIZE, 8, EGL14.EGL_ALPHA_SIZE, 8, EGL14.EGL_RENDERABLE_TYPE, EGL14.EGL_OPENGL_ES2_BIT, EGL14.EGL_NONE, 0, // placeholder for recordable [@-3] EGL14.EGL_NONE ) val configs = arrayOfNulls&lt;EGLConfig&gt;(1) val numConfigs = IntArray(1) EGL14.eglChooseConfig(display, attributes, 0, configs, 0, configs.size, numConfigs, 0) val config = configs[0] eglSurface = EGL14.eglCreateWindowSurface( display, config, surface, intArrayOf( EGL14.EGL_NONE ), 0 ) eglContext = EGL14.eglCreateContext( display, config, sharedContext ?: EGL14.EGL_NO_CONTEXT, intArrayOf( EGL14.EGL_CONTEXT_CLIENT_VERSION, 2, EGL14.EGL_NONE ), 0 ) EGL14.eglMakeCurrent(display, eglSurface, eglSurface, eglContext)} 这里需要注意的是，这个方法调用需要在一个独立的线程中，最后一句代码是与当前线程绑定，相关的OpenGL的操作，只能在对应的线程中进行。有了这个OpenGL环境以后，就可以创建对应的SurfaceTexture了，简单的代码如下： 123val textureIds = IntArray(1)GLES20.glGenTextures(1, textureIds, 0)val texture = SurfaceTexture(textureIds[0]) 同样的，这里的代码也要运行在之前的创建EGL环境相同的线程之下，之后便可以将这里创建的texture设置给camera对象用于预览。 3.2 监听预览-消除形变-绘制画面给上一步中创建的texture设置一个画面监听。 12345678910111213val matrix = FloatArray(16)texture.setOnFrameAvailableListener { queue { texture.updateTexImage() texture.getTransformMatrix(matrix) drawFrame(textureIds[0], matrix) }}fun drawFrame(textureId: Int, matrix: FloatArray) { // ....} 简单解释一下这里代码： 先创建一个浮点数组，用于接收预览画面的坐标数据，用于OpenGL绘制画面使用； 然后设置画面监听，这里在相机开启预览后会触发一次； 在画面监听回调中，切换到EGL线程中，调用updateTexImage，只有这样，画面监听回调才会持续的被执行； 最后调用getTransformMatrix获取画面坐标数据，为之后的画面绘制做准备。 接下来，便是执行画面的绘制，在画面绘制关键的一步就是消除形变，这里需要先获得camera对象的预览尺寸，从支持的预览尺寸中，挑选最佳匹配尺寸以及消除方形问题的相关代码，这里不再赘述，只提供消除形变的关键代码。 1234567891011121314151617val inputSize: Size // 相机输出的预览画面尺寸，因为要作为绘制的输入，所以称为inputSize，注意消除屏幕方向旋转的问题val outputSize: Size // 输出画面的尺寸val viewport: Rect // 计算出预览画面要消除形变，需要做的位置与尺寸变更private fun calculateBestViewPort() { if (inputSize.isEmpty || outputSize.isEmpty) { return } val scale = max(outputSize.width.toFloat() / inputSize.width, outputSize.height.toFloat() / inputSize.height) val srcWidth = (inputSize.width * scale).toInt() val srcHeight = (inputSize.height * scale).toInt() val left = (outputSize.width - srcWidth) / 2 val top = (outputSize.height - srcHeight) / 2 viewport.set(left, top, left + srcWidth, top + srcHeight)} 在绘制画面前，执行OpenGL的glViewport方法，就可以消除形变了。 123456fun drawFrame(textureId: Int, texMatrix: FloatArray?) { if (!viewport.isEmpty) { GLES20.glViewport(viewport.left, viewport.top, viewport.width(), viewport.height()) } // 绘制画面代码有大量的OpenGL操作，具体不再赘述} 四、总结到这里，主要的消除形变预览相机画面的主要逻辑流程，就基本结束了，重点是梳理思路，在具体的实践中，还是有很多细碎的问题的，就比如相机预览尺寸的选取与方向设置问题。 另外，为这里只是为了说明逻辑，临时写了代码逻辑部分，实际项目中，我直接使用了Grafika项目中的egl包下代码，这个项目给了我很多灵感，真心推荐给各位看一下这个项目中的代码。 也许同样做过消除形变的朋友，会认为为什么不直接使用TextureView，然后通过setTransform的方式消除形变呢？ 实际上，如果只是为了消除预览的形变，这样做是没有问题的，也是非常便捷的，但是做相机应用的开发，难免会有拍照、录像、帧数据回调(主要是扫码)相关的功能性逻辑，在这类逻辑中，通过这种方式，就无法做到可见即所得式的效果了，就比如拍照，你必须在拍照后，对图片做一次按照预览框尺寸crop的操作了，如果只是拍照还比较简单，如果是录像的话，没有录像期间切换摄像头的需求，使用MediaRecorder或许可以，我没有试过，但是有这样的需求，MediaRecorder就无法满足需求了，面对这样的需求，我之前是通过获取帧数据，然后用libYuv缩放、剪裁反转旋转帧数据等操作，最后喂给MediaCodec的方式，我当前的这个方案，是可以通过共享OpenGL上下文的方式，实现所见即所得的录像，不需要繁琐的操作帧数据了，减少了额外库的引入。 对于上述录像相关的逻辑，我将用新的文章来阐述。","link":"/2023/11/12/2023-11-12-Camera%E6%97%A0%E5%8F%98%E5%BD%A2%E4%BB%BB%E6%84%8F%E5%B0%BA%E5%AF%B8%E9%A2%84%E8%A7%88/"},{"title":"相机录像新姿势-OpenGL共享上下文+MediaCodec","text":"一、前言承接上一文章Camera无变形任意尺寸预览，我们已经实现了无形变的任意尺寸的相机画面预览。接下来要完成相机的相关录像、拍照、扫码等功能，最重要也是最难的就是录像部分。 最终示例代码可以参考我的Github: iCamera。 二、技术要求我们要实现的录像功能技术要求如下： 所见即所得，预览画面什么样，最终结果就是什么样，不能经过二次裁剪与变换； 允许过程中，切换摄像头而不中断录制； 效率尽可能高，不许按下停止键后，有长时间的等待最终结果的过程； 不要引入额外的库； 三、基本思路在讲解基本思路以前，我们先看一下共享OpenGL上下文，能够达到怎样的效果。share_preview查看视频，最上方是相机的预览画面，下方左侧为通过共享OpenGL上下文获得的共享画面，也就是说，我们可以把相机画面，共享给另外一个Surface，既然有了这个思路，那么通过共享画面进行录像，也就可以了。那么基本思路如下： 实现相机的OpenGL预览，保留相关上下文实例； 创建并配置MediaCodec，通过createInputSurface，创建共享画面； 以预览的OpenGL上下文与MediaCodec的surface，创建另外一个共享的OpenGL环境； MediaCodec开始编码录制； 四、具体实现4.1 实现OpenGL画面预览这里我们通过已经封装好的PreviewSurface实现。 1234567891011121314151617181920fun open(id: Int, surfaceView: SurfaceView) { if (id == cameraId) { return } if (camera != null) { close() } previewSurface = PreviewSurface(surfaceView.holder.surface) previewSurfaceView = surfaceView previewSurface?.start { surfaceTexture -&gt; previewSurfaceTexture = surfaceTexture val previewSize = openCameraOnly(id, surfaceTexture) when(display.rotation) { Surface.ROTATION_0, Surface.ROTATION_180 -&gt; previewSurface?.setInputSize(previewSize.height, previewSize.width) Surface.ROTATION_90, Surface.ROTATION_270 -&gt; previewSurface?.setInputSize(previewSize.width, previewSize.height) } }} previewSurface可以提供SurfaceTexture进行预览，同时也保存了OpenGL上下文。 4.2 MediaCodec创建Surface我们的视频编码是通过MediaCodec实现的，之所以不直接用MediaRecorder实现，是因为MediaRecorder不支持录制期间翻转摄像头。 一个简单的MediaCodec实现如下： 123456789videoCodec = MediaCodec.createEncoderByType(MIME_TYPE)val codecInfo = videoCodec!!.codecInfoval capabilities = codecInfo.getCapabilitiesForType(MIME_TYPE)val mediaFormat = onConfig.onConfig(capabilities.videoCapabilities).toMediaFormat( MIME_TYPE)videoCodec?.configure(mediaFormat, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE)val inputSurface = videoCodec?.createInputSurface()!! 这样，我们就获得了一个用于共享的surface。 4.3 创建共享OpenGL环境以前两步中获得到OpenGL上下文与共享surface，创建一个新的共享OpenGL环境，这里我们已经封装成了SharedSurface，只要直接调用其attach方法即可直接共享预览Surface的画面。 1234567891011121314151617181920212223242526private val avEncoder = AVEncoder()private var recordSurface: SharedSurface? = nullprivate val timeSynchronizer = object : TimeSynchronizer { private var startAt = 0L override fun reset() { startAt = System.currentTimeMillis() * 1000 } override fun getTimestamp(): Long { return System.currentTimeMillis() * 1000 - startAt }}fun startRecord(output: File) { if (isRecording()) { return } avEncoder.prepare(SimpleAudioConfigAdapter(), SimpleVideoConfigAdapter(Size(previewSurfaceView!!.width, previewSurfaceView!!.height)), timeSynchronizer) { avEncoder.start(output) { inputSurface -&gt; recordSurface = SharedSurface(inputSurface) recordSurface?.attach(previewSurface!!) } }} 上述代码中，AVEncoder为一个同时录制画面与声音的逻辑集合类，当开始录像时，会提供一个inputSurface对象，利用此对象，创建SharedSurface，就可以直接利用预览画面的共享纹理进行绘制，这些会绘制到共享surface上，MediaCodec会直接对画面进行编码。 当然，这里会有很多MediaCodec相关的问题，这里的兼容性也是非常头疼的，需要处理高通/海思/联发科处理器的编码器的大量兼容性问题，但是这不是本文的重点。 4.4 编码录制这部分请直接参考代码吧 五、思路发散我们从录制上，可以看出，实际上连接预览与录制的，就是一个surface，只要有了surface，那我们就可以做很多操作了。比如拍照和扫码。 当然，我们可以通过直接调用相机实例的接口进行拍照，只不过需要拍照后再做裁剪等操作，这里耗时不高。 说一下拍照的逻辑，就是利用ImageReader，这种方式，就与Camera2的api差异不大了，简单代码实现如下： 123456789101112private var photoSurface: SharedSurface? = nullprivate val photoHandler = ...fun takePhoto(callback: (Bitmap) -&gt; Unit) { val imageReader = ImageReader.newInstance(previewSurfaceView!!.width, previewSurfaceView!!.height, PixelFormat.RGBA_8888, 1) photoSurface = SharedSurface(imageReader.surface) imageReader.setOnImageAvailableListener({ val image = imageReader.acquireNextImage() // convert image to bitmap callback.invoke(bitmap) }, photoHandler) photoSurface?.attach(previewSurface!!)} 同样的，扫码功能也类似，不过这里要借助zxing这个二维码解析库，同时做一个RGBA的转换，因为当前方案下，ImageReader只允许PixelFormat.RGBA_8888的颜色编码，好处就是，可以比较容易实现扫码预览大小的自定义，并且在预览范围内的都可以扫到，不会出现以前那种预览区域与扫码感知区域不一致的问题。 既然有Surface就可以连接预览画面，那实际上就可以做到边录像，边扫码，边拍照了，只要你的手机性能足够，更多的使用方式，你可以自由去发散。 总结具体的代码可以参考我的iCamera，但是我的代码只是做简单的逻辑演示，并不能保证在所有机型上的兼容性，了解了基本思路后，你可以在此基础上做兼容性处理。 实际上我个人在生产环境的代码，做的兼容性处理要多得多。","link":"/2023/11/20/2023-11-20-%E7%9B%B8%E6%9C%BA%E5%BD%95%E5%83%8F%E6%96%B0%E5%A7%BF%E5%8A%BF-OpenGL%E5%85%B1%E4%BA%AB%E4%B8%8A%E4%B8%8B%E6%96%87+MediaCodec/"},{"title":"macOS项目中引入c静态库","text":"最近在写一款多平台的文件传输工具，Android平台已经写的差不多了，现在正在写macOS端，为了多端共享同一套底层协议代码，通讯协议部分，使用了c语言开发，对于Android通过jni调用c的相关代码，我已经驾轻就熟了，但是在macOS项目里，添加静态库并成功调试，我还是有一些懵逼。好在通过ChatGPT的各种帮助，还是跌跌撞撞的调通了。为了防止遗忘，记录一下过程。 相关的c/swift代码，均以示例项目作为演示，目的是说明过程。 一、C语言库c库的相关代码结构如下： 123456789demo├── bc│ ├── bc.h│ ├── bc.c│ └── build/libbc.a│ └── CMakeLists.txt├── main.c│── CMakeLists.txt 根目录的main.c与CMakeLists.txt不重要，重要的是bc文件夹下。bc.h为头文件，bc.c为代码文件，其内容比较简单，定义了一个名为getNumber的函数，函数返回值为42，build为编译生成文件夹，主要是为了生成libbc.a，bc目录下的CMakeLists.txt内容如下： 1234567891011cmake_minimum_required(VERSION 3.5)project(bc VERSION 0.0.1)# 添加库add_library( bc STATIC bc.c bc.h)# 将库的目录添加到include路径target_include_directories(bc PUBLIC ${CMAKE_CURRENT_SOURCE_DIR}) 这里主要关注add_library这个指令中的，STATIC关键字，有这个关键字，在编译时，才会被编译成静态库。在bc目录下，执行相关的指令，生成静态库文件。 1234mkdir buildcd buildcmake ..make 执行完相关指令以后，在build目录下，会多一个libbc.a文件。 二、macOS swiftUI项目macOS的演示项目名称为TestA，其基本目录结构如下： 12345678TestA├── TestA│ ├── main.swift│ ├── TestA-Bridging-Header.h│ └── ...├── TestA.xcodeproj|── include/bc.h└── libbc.a TestA为项目根目录，其内部的TestA为同名Target目录。在根目录下，你可以看到一个libbc.a文件，实际上这个文件本身并不存在于该路径下，而是在上一段中提到的build目录下，当然，你也可以把文件本身拷贝到该目录下。 2.1 添加libbc.a在根目录上，右键-&gt;Add Files to “TestA”，然后选择libbc.a，这样libbc.a就会显示在根目录下了。左键点击项目根目录，弹出配置选项卡，点击Build Settings选项卡，在Filter中，输入”Other Linker Flags”，找到该配置项，然后增加配置值-lbc（这里的“bc”应该是你的库文件名去掉前缀“lib”和后缀“.a”，因为我的库名称叫bc，生成的文件上libbc.a，所以值为-lbc，如果你的库名称为xyz，则应该配置为-lxyz），这里需要注意，该配置项下有Debug和Release两个，都要配置，下同。 2.2 引入头文件在根目录下，创建include目录，将头文件bc.h拷贝进来。然后在刚才的Build Settings选项卡中，搜索”Header Search Paths”，并设置值为$(SRCROOT)/include，注意，如果include下有子目录，同样需要添加到该配置中。添加了该配置后，在接下来的TestA-Bridging-Header.h中，才能引入相关头文件。 2.3 TestA-Bridging-Header.h注意，是TestA-Bridging-Header.h，不是TestA-Bridge-Header.h。因为是桥接文件，所以好几次，我都想当然的认为是Bridge了，导致很多次配置都失败了。文件内容如下： 123456#ifndef TestA_Bridging_Header_h#define TestA_Bridging_Header_h#include &quot;bc.h&quot;#endif 在此文件中，可以使用bc.h文件了。 此时，在Swfit代码中还不能使用TestA-Bridge-Header.h中引入头文件的相关函数，需要设置Objective-C Bridging Header，同样在Build Settings中搜索”Objective-C Bridging Header”，设置值为TestA/TestA-Bridging-Header.h。 三、运行在Swift代码的UI配置文件中，使用c语言中的getNumber方法。 12345678910111213import SwiftUIstruct ContentView: View { var body: some View { VStack { Image(systemName: &quot;globe&quot;) .imageScale(.large) .foregroundStyle(.tint) Text(&quot;Hello, world!\\(getNumber())&quot;) } .padding() }} 将该数字显示在Text中，效果如下：","link":"/2024/04/26/2024-04-26-MacOS%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%BC%95%E5%85%A5c%E9%9D%99%E6%80%81%E5%BA%93/"},{"title":"MacOS项目引入c语言源码","text":"在上一篇文章macOS项目中引入c静态库中，为阐述了如何在macOS项目中引入c语言的静态库，但是这样做有一个问题，就是静态库中的代码报错，会无法定义报错的位置，进而不利于排查问题。为了解决这个问题，我修改为源码引入c语言库。很多教程中都提到，要引入c语言库的源码，需要将源码和头文件都拷贝到macOS项目的目录中，这样做，有一个弊病，就是对于需要引入c语言库的项目，通常都是想底层多平台支持，底层代码就需要独立于任何一个平台代码，如果要拷贝到macOS项目中，那后续修改和维护都会比较麻烦，实际上这是不需要的，接下来就阐述一下我这两天的实践。 一、项目结构我们准备两个示例项目，其中项目A是基于swift构建的macOS项目，项目B是基于cmake构建的c语言项目。其目录树如下： 123456A/├── A // macOS中的同名target│ └── AApp.swift│ └── ContentView.swift│ └── Assets│ └── .... // Other files 123456B/├── CMakeLists.txt├── src/│ └── library.c└── include/ └── library.h library的头文件和代码文件如下： 123#include &lt;stdio.h&gt;int get_id(); 123456789#include &quot;../include/library.h&quot;int get_id(){ int *ptr = NULL; *ptr = 10; // 这里会导致空指针解引用崩溃 return 100;} 这里c代码文件中，故意制造了一个空指针崩溃，以便于测试定位崩溃位置。 二、macOS项目引入c语言源代码项目在XCode中，A项目的根目录下，右键-Add Files to “A”，然后选择项目B的根目录选择的时候，千万不要勾选“Copy items if needed”，然后点击Add，如此操作之后，你会在XCode的项目目录中，看到在根目录下多了一个名为B的Group，但是这个Group并不会出现在实际的文件目录下。那在XCode中，项目A的目录结构变成了如下这样： 12345678910111213A/├── A // macOS中的同名target│ └── AApp.swift│ └── ContentView.swift│ └── Assets│ └── .... // Other files│├── B // 引入的c源码库，只在XCode视图中可见│ └── CMakeLists.txt│ └──src/│ │ └── library.c│ └──include/ └── library.h 三、创建桥接文件与静态库方案类似，也需要创建一个桥接文件，名为A-Bridging-Header.h，放置在根目录下，然后在Build Settings下搜索Header Search Paths设置项，在Debug和Release下，设置B库的include目录，注意：因为B库并未实际在A项目的文件目录下，所以，你不能设置一个A项目下的目录。我设置的值为：$(SRCROOT)/../B/include。增加此配置后，在桥接文件中，增加头文件的引入，内容如下： 123456#ifndef A_Bridging_Header_h#define A_Bridging_Header_h#include &quot;library.h&quot;#endif 还差最后一步，把桥接文件设置到Objective-C Bridging Header配置中，由于桥接文件在根目录下，所以我设置的值为A-Bridging-Header.h。 四、运行在AApp.swift代码中，我们创建一个Application Delegate，代码如下： 123456789101112131415161718import SwiftUI@mainstruct AApp: App { @NSApplicationDelegateAdaptor var delegate: AppDelegate var body: some Scene { WindowGroup { ContentView() } }}class AppDelegate: NSObject, NSApplicationDelegate { func applicationDidFinishLaunching(_ notification: Notification) { print(&quot;applicationDidFinishLaunching&quot;) print(&quot;\\(get_id())&quot;) }} 当应用启动时，调用一下c语言中get_id这个方法，由于方法中有一个空指针错误，会触发崩溃，并指向崩溃位置。 后记在现实项目中，c源码项目可能远比demo中的要复杂的多，引入源码后，可能会引起类似于如下的编译错误： 12345xcode macOS项目中，引入了第三方的c语言库后，出现了这样的错误，似乎是因为不能识别这些文件造成的，我把这些文件的引用从xcode删除后，就没有这些错误了，请问情况是这样的吗？以下是错误的内容：Showing All IssuesMultiple commands produce '/Users/xxx/Library/Developer/Xcode/DerivedData/Test-gkhgciuuhcjhzjayrjomcyvjrhgq/Build/Products/Debug/Test.app/Contents/Resources/CI.yml'Target 'Test' (project 'Test') has copy command from '/Users/xxx/byte-cat/ByteCat/native/bytecat-native/cJSON/.github/workflows/CI.yml' to '/Users/xxx/Library/Developer/Xcode/DerivedData/Test-gkhgciuuhcjhzjayrjomcyvjrhgq/Build/Products/Debug/Test.app/Contents/Resources/CI.yml'Target 'Test' (project 'Test') has copy command from '/Users/xxx/byte-cat/ByteCat/native/bytecat-native/libhv/.github/workflows/CI.yml' to '/Users/xxx/Library/Developer/Xcode/DerivedData/Test-gkhgciuuhcjhzjayrjomcyvjrhgq/Build/Products/Debug/Test.app/Contents/Resources/CI.yml' 如果发生了这个错误，需要在Build Phases中，找到Copy Bundle Resources选项，点击底部”-“号按钮，删除掉重复的项，如果重复的项过多，这个按钮会被顶到列表最下边。","link":"/2024/04/29/2024-04-29-MacOS%E9%A1%B9%E7%9B%AE%E5%BC%95%E5%85%A5c%E8%AF%AD%E8%A8%80%E6%BA%90%E7%A0%81/"},{"title":"MacOS SwiftUI托盘应用开发","text":"最近想利用闲暇时间，做一些托盘工具类app的开发，主要是方便自己在Mac上的部分操作。在遇到各种问题后，总结了一下实现托盘SwiftUI应用的两种方式。 小声吐槽：swiftUI在macOS上的适配真的是很烂，相当多的组件可以说是不完善甚至是不可用的状态，似乎苹果也没有完善的意思，这已经是swift迭代到5.10了啊，竟然还有这么多问题存在。 方案一：NSApplicationDelegateAdaptor这种方式，应该是从Objective-C时代承袭过来的，我没有做过Objective-C的应用，这只是我的猜测。新建一个项目，通常会生成一个XXXApp.swift的文件，文件的内容如下： 12345678@mainstruct XXXApp: App { var body: some Scene { WindowGroup { ContentView() } }} 我们要添加一行代码，变成如下这样： 123456789@mainstruct ByteCatApp: App { @NSApplicationDelegateAdaptor(AppDelegate.self) var appDelegate var body: some Scene { WindowGroup { ContentView() } }} 加入了@NSApplicationDelegateAdaptor(AppDelegate.self) var appDelegate这一行，现在开始写AppDelegate的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class AppDelegate: NSObject, NSApplicationDelegate { var statusItem: NSStatusItem! var popover: NSPopover! override init() {} func applicationDidFinishLaunching(_ notification: Notification) { setupStatusBarItem() setupPopover() } func setupStatusBarItem() { statusItem = NSStatusBar.system.statusItem(withLength: NSStatusItem.squareLength) if let button = statusItem.button { let imageSize = NSSize(width: 22, height: 22) button.image = NSImage(named: &quot;TrayIcon&quot;) button.image?.size = imageSize button.action = #selector(togglePopover(_:)) } } func setupPopover() { popover = NSPopover() popover.behavior = .transient popover.contentViewController = PopoverViewController().makeNSViewController() } @objc func togglePopover(_ sender: AnyObject?) { if popover.isShown { closePopover(sender) } else { showPopover(sender) } } func showPopover(_ sender: AnyObject?) { if let button = statusItem.button { popover.show(relativeTo: button.bounds, of: button, preferredEdge: NSRectEdge.minY) } } func closePopover(_ sender: AnyObject?) { popover.performClose(sender) } }struct PopoverViewController: NSViewControllerRepresentable { func makeNSViewController(context: Context) -&gt; NSViewController { return makeNSViewController() } func makeNSViewController() -&gt; NSViewController { let viewController = NSViewController() viewController.view = NSHostingView(rootView: ContentView()) return viewController } func updateNSViewController(_ nsViewController: NSViewController, context: Context) { // Update code if needed }} 方案二：MenuBarExtra12345678910@mainstruct XXXApp: App { var body: some Scene { return MenuBarExtra { ContentView() } label: { Image(systemName: &quot;tray.2.fill&quot;) }.menuBarExtraStyle(.window) }} 这个方案就是这么简单，几行代码就搞定，缺点是，弹出的窗口位置不可调整，也不会有一个三角形指向托盘图标的位置，而且窗口位置一直与托盘图标左对齐。 问题List导致UI异常方案一，当弹出窗口UI中包含了List组件，会使得弹出的窗口显示异常。正常情况是这样的：异常的情况如下：代码的差别，只是把其中的红色布局换成了List组件而已，顶端的三角指向消失了，而且窗口整体上移了。 MenuBarExtra的显示不同使用方案二，窗口弹出是这样的：同样没有顶部三角指向，固定与托盘图标左对齐。 横向滑动列表不支持鼠标滚轮这并不是某个方案中的问题，而是二者都有的问题，这个应该是SwiftUI的相关组件没有适配macOS所致，这个并没有找到解决办法，似乎苹果也不想解决，毕竟大多数做桌面端app的，都是使用Electron方案，使用原生开发，而且只开发托盘应用的实在是少数。 一点小改进如果你想让托盘应用启动后，只有在托盘中有图标，而在dock栏中没有图标，则需要在Info.plist中，设置一个属性**Application is agent(UIElement)**为YES。 总结swiftUI真的不适合在macOS端开发稍微复杂一点的应用，之前开发过一个翻译的应用，只能说勉强够用而已，前提是足够简单。对于托盘应用这个极小的领域来说，尤其不能使用，electron不支持自定义UI的弹出窗口，只支持菜单，而swiftUI支持的情况更糟糕，可能只有原始的Objective-C方案可行了，原始人方案。","link":"/2024/05/08/2024-05-08-MacOS%20SwiftUI%E6%89%98%E7%9B%98%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/"},{"title":"MyTodo开发(一) 项目初始化","text":"正如很多开发者一样，进入一个新平台开发连带学习，通常都会开发一个极简的应用，很多人都会开发Todo类应用，这类应用一般来说比较简单容易上手。我也打算开发一个，一来是练手，二来是写一个自己用的极简Todo类应用。目前市面上的Todo类应用，一般来说，都比较复杂，太多我不需要的功能了，而且还有一些增值付费，对于我来说，根本没有那么多的复杂需求，只需要一个随手打开和关闭的记录而已，放在托盘上就非常的方便。所以，需求如下： macOS托盘应用，随手打开和关闭； 带有分页标签，以便标记不同类型的todo； 最好有利用iCloud的数据云同步，方便未来与其他平台同步数据； 基于以上需求，做一个技术选型： 由于SwiftUI在macOS上表现实在是不敢恭维，所以选用传统的AppKit进行开发； 基于个人写Android应用的习惯，更倾向于使用代码或者XML的方式构建界面，所以在使用AppKit时，不使用Storyboard或者XIB的方式构建界面。 一、创建项目打开Xcode，创建一个新的macOS项目，语言选择swift，Interface暂时选storyboard，先创建项目，在稍后删除相关的storyboard文件和配置。 二、项目配置2.1 删除Main.storyboard首先，删除自动创建的storyboard文件Main.storyboard，此时再构建项目会出现错误，先不用着急，接下来进行修改。 2.2 替换应用程序入口其次，在target目录下，创建一个main.swift文件，然后把AppDelegate.swift中的@main注解删除掉，main.swift文件内容如下： 123456789import Cocoaclass MyApplication: NSApplication {}let app = MyApplication.sharedlet delegate = AppDelegate()app.delegate = delegateapp.run() 2.3 创建托盘应用的基本框架在AppDelegate.swift文件中，添加相关代码以实现点击托盘图标，主窗口的显示/隐藏。创建一个Tray类，用于管理托盘图标的创建和窗口的弹出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Tray { public static let POPOVER_SIZE = NSSize(width: 320, height: 400) private let iconName: String private var statusItem: NSStatusItem! private var popover: NSPopover! private var viewController: NSViewController init(iconName: String, viewController: NSViewController) { self.iconName = iconName self.viewController = viewController } func install() { statusItem = NSStatusBar.system.statusItem(withLength: NSStatusItem.variableLength) if let trayBtn: NSStatusBarButton = statusItem.button { trayBtn.image = NSImage(systemSymbolName: iconName, accessibilityDescription: nil) trayBtn.target = self; trayBtn.action = #selector(togglePopover(_:)) } viewController.loadViewIfNeeded() viewController.view.frame = NSRect(x: 0, y: 0, width: Tray.POPOVER_SIZE.width, height: Tray.POPOVER_SIZE.height) popover = NSPopover() popover.contentViewController = viewController } @objc private func togglePopover(_ sender: Any?) { if popover.isShown { closePopover(sender: sender) } else { showPopover(sender: sender) } } private func showPopover(sender: Any?) { if let button = statusItem.button { popover.show(relativeTo: button.bounds, of: button, preferredEdge: NSRectEdge.minY) } } private func closePopover(sender: Any?) { popover.performClose(sender) } } 此类中，接收两个构造参数，一个是图标名称，对应着资源名称或者是SF Symbols图标名称，另外一个参数就是ViewController的具体实现。在AppDelegate中的applicationDidFinishLaunching方法中，执行Tray.install()，就添加了一个系统图标。 123456789class AppDelegate: NSObject, NSApplicationDelegate { private let tray = Tray(iconName: &quot;text.badge.checkmark&quot;, viewController: ViewController()) func applicationDidFinishLaunching(_ aNotification: Notification) { tray.install() } } 此处需要注意的是，必须要声明一个Tray的成员变量，如果不声明成员变量，则系统图标不会添加成功。 现在在ViewController中，显示一个Hello World。 1234567891011121314151617181920class ViewController: NSViewController { override func viewDidLoad() { super.viewDidLoad() let text = NSTextView() text.translatesAutoresizingMaskIntoConstraints = false text.alignment = .center text.string = &quot;Hello World&quot; self.view.addSubview(text) NSLayoutConstraint.activate([ text.leadingAnchor.constraint(equalTo: self.view.leadingAnchor), text.trailingAnchor.constraint(equalTo: self.view.trailingAnchor), text.topAnchor.constraint(equalTo: self.view.topAnchor), text.bottomAnchor.constraint(equalTo: self.view.bottomAnchor) ]) }} 注意此处的text.translatesAutoresizingMaskIntoConstraints = false，这里如果不设置的话，弹出窗口是不会填满整个父布局的。translatesAutoresizingMaskIntoConstraints 是一个布尔属性，用于指示是否启用自动布局中的自动转换。 在 iOS 和 macOS 开发中，通常使用自动布局来管理界面的布局。自动布局系统使用约束（constraints）来描述视图之间的关系和布局规则。当你通过 Interface Builder 或代码创建视图时，默认情况下，视图的 translatesAutoresizingMaskIntoConstraints 属性是设置为 true 的。这意味着视图会根据其 frame 和 autoresizingMask 属性自动转换为相应的约束。 但是，在使用自动布局时，通常推荐将 translatesAutoresizingMaskIntoConstraints 设置为 false。这样做的原因是，如果你手动创建约束来布局视图，那么这些约束将会和自动转换的约束发生冲突，导致布局问题。通过将 translatesAutoresizingMaskIntoConstraints 设置为 false，你可以明确地告诉系统不要自动转换视图的 autoresizingMask 为约束，从而避免这种冲突。 最终的效果如下： 另外，若要应用图标不显示在Docker栏上，需要在Info.plist上设置 Application is agent (UIEelement) 为YES。","link":"/2024/05/11/2024-05-11-MyTodo%E5%BC%80%E5%8F%91(%E4%B8%80)%20%E9%A1%B9%E7%9B%AE%E5%88%9D%E5%A7%8B%E5%8C%96/"},{"title":"MyTodo开发(二) 界面初始化","text":"一、界面布局一个简单的界面布局描述如下： 12345678910---------------------| | || | || | || 1 | 2 || | || | || |---------------|| | 3 |--------------------- 简单分为3个区域： 导航 - 用于做Todo Item的分类导航，是一个列表； 内容 - 展示当前分类下的Todo Items； 输入 - 在当前分类下创建新的Todo。 这实际上是一个妥协方案，我的理想方案是简单的上中下三部分，上部分上导航，类似于chrome浏览器顶部页面管理那种，但是macOS对于列表横向滑动的滚轮支持实在是太差了，没有找到成熟的方式实现，妥协成当前这样了 二、页面构建上一章中，我们有一个用于展示界面的ViewController类，这次要在其中填充上述的布局内容。代码可参考MyTodo，最终实现效果如下：","link":"/2024/05/12/2024-05-12-MyTodo%E5%BC%80%E5%8F%91(%E4%BA%8C)%20%E7%95%8C%E9%9D%A2%E5%88%9D%E5%A7%8B%E5%8C%96/"},{"title":"MyTodo开发(三) 更换技术路线，跑步前进","text":"在尝试使用AppKit原生开发界面几天后，我还是放弃了这种尝试了，其羸弱UI表现力，真的是让搭建界面的我心力交瘁。转而，我尝试使用web的形式来开发，即NSPopover中嵌套WKWebView的方式，配合原生层提供一些数据库接口。 经过一番查找，终于找到了一个Material Design风格的Web UI框架SoberJS，作为一个android开发者，对这一套UI相对来说很熟悉了，用起来也驾轻就熟。 经过两天的开发时间，效果图如下：这样既实现了最初的顶部导航设想，又能加快开发速度。 再次吐槽苹果的原生开发在macOS上真的好吃力。","link":"/2024/05/17/2024-05-17-MyTodo%E5%BC%80%E5%8F%91(%E4%B8%89)%20%E6%9B%B4%E6%8D%A2%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF%EF%BC%8C%E8%B7%91%E6%AD%A5%E5%89%8D%E8%BF%9B/"},{"title":"MyTodo开发(四) 初版完成","text":"初版已经完成，从切换到SoberJS，基本上只用了一周，便写出来了，如果是使用macOS的原生开发方案，可能现在还困在各种不兼容中。 基本功能 创建/删除 Tab； 创建/标记/删除 Todo笔记； 右键菜单，关于/退出； 源码地址: JustTodo下载地址: JustTodo-Releases","link":"/2024/05/17/2024-05-17-MyTodo%E5%BC%80%E5%8F%91(%E5%9B%9B)%20%E5%88%9D%E7%89%88%E5%AE%8C%E6%88%90/"}],"tags":[{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"陷阱与缺陷","slug":"陷阱与缺陷","link":"/tags/%E9%99%B7%E9%98%B1%E4%B8%8E%E7%BC%BA%E9%99%B7/"},{"name":"Kotlin","slug":"Kotlin","link":"/tags/Kotlin/"},{"name":"Translator","slug":"Translator","link":"/tags/Translator/"},{"name":"J2V8","slug":"J2V8","link":"/tags/J2V8/"},{"name":"Camera","slug":"Camera","link":"/tags/Camera/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"静态库","slug":"静态库","link":"/tags/%E9%9D%99%E6%80%81%E5%BA%93/"},{"name":"JustTodo","slug":"JustTodo","link":"/tags/JustTodo/"}],"categories":[{"name":"源码分析","slug":"源码分析","link":"/categories/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"Android技巧","slug":"Android技巧","link":"/categories/Android%E6%8A%80%E5%B7%A7/"},{"name":"陷阱与缺陷","slug":"陷阱与缺陷","link":"/categories/%E9%99%B7%E9%98%B1%E4%B8%8E%E7%BC%BA%E9%99%B7/"},{"name":"Kotlin Native","slug":"Kotlin-Native","link":"/categories/Kotlin-Native/"},{"name":"Translator","slug":"Translator","link":"/categories/Translator/"},{"name":"独立开发笔记","slug":"独立开发笔记","link":"/categories/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}]}